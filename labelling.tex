\documentclass[kpfonts]{patmorin}
\usepackage{pat}
\usepackage{paralist}
\usepackage{dsfont}  % for \mathds{A}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}
\usepackage[noend]{algorithmic}

\newcommand{\snote}[1]{\fcolorbox{red}{yellow}{#1}}
\newcommand{\pnote}[1]{\ \newline\noindent\fcolorbox{red}{yellow}{\begin{minipage}{\textwidth}#1\end{minipage}}}
\setlength{\parskip}{1ex}

\DeclareMathOperator{\A}{\mathds{A}}
\DeclareMathOperator{\sn}{sn}
\DeclareMathOperator{\qn}{qn}

\renewcommand{\SS}{\mathcal{S}}


\newcommand{\aref}[1]{(X\ref{a:#1})}
\newcommand{\alabel}[1]{\label{a:#1}}

\title{\MakeUppercase{Refactoring: Optimal Adjacency-Labelling Schemes for Planar Graphs}}
\author{Barbados Folks}

\begin{document}
\begin{titlepage}
\maketitle

\begin{abstract}
  We show that there exists an adjacency labelling scheme for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(n))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  This is optimal up to the lower order term and is the first such optimal result.  An alternative, but equivalent, interpretation of this result is that, for every $n$, there exists a graph $U_n$ with $n^{1+o(1)}$ vertices such that every $n$-vertex planar graph is an induced subgraph of $U$.  Again, this is the first near-linear upper bound on the size of $U_n$.
\end{abstract}
\end{titlepage}
\pagenumbering{roman}
\tableofcontents

\newpage

\setcounter{page}{0}
\pagenumbering{arabic}
\section{Introduction}

In this paper, which is concerned with binary encodings, $\log x:=\log_2 x$ denotes the binary logarithm of $x$ and, for convenience, $\lg x = \log\max\{1,x\}$.  All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The size of a graph $G$ is denoted by $|G|:=|V(G)|$.

A family $\mathcal{G}$ of graphs has an \emph{$f(n)$-bit adjacency-labelling scheme} if there exists a function $A:(\{0,1\}^*)^2\to \{0,1\}$ such that for every $n$-vertex graph $G\in \mathcal{G}$ thre exists $\ell:V(G)\to\{0,1\}^*$ such that $\ell(v)\le f(n)$ for each $v\in V(G)$ and such that, for any two vertices $v,w\in V(G)$,
\[  A(\ell(v),\ell(w)) = 
      \begin{cases} 
        0 & \text{if $vw\not\in E(G)$} \\
        1 & \text{if $vw\in E(G)$}
      \end{cases}
\]

We prove the following:
\begin{thm}\thmlabel{main}
  Planar graphs have $(1+o(1))\log n$-bit labelling scheme.
\end{thm}

% We show that there exists an \emph{adjacency labelling scheme} for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  

\thmref{main} is optimal up to the lower order term.  An alternative, but equivalent, interpretation of \thmref{main} is that, for every integer $n\ge 1$, there exists a graph $U_n$ with $n^{1+o(1)}$  vertices such that every $n$-vertex planar graph is isomorphic to some vertex-induced subgraph of $U_n$.\footnote{There is a small technicality that the equivalence between adjacency-labelling schemes and universal graphs requires that $\ell:V(G)\to\{0,1\}^*$ be injective.  The labelling schemes we discuss satisfy this requirement.  For more details about the connection between labelling schemes and universal graphs, the reader is directed to Spinrad's monograph \cite[Section~2.1]{spinrad:efficient}.} 

\subsection{Previous Work}

The current paper is the latest in a series of results dating back to Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit0,kannan.naor.ea:implicit} and Muller \cite{muller:local} who defined adjacency-labelling schemes\footnote{There are some small technical differences between the two definitions that have to do with the computability of $\ell:=\ell(G)$ of $A(\cdot,\cdot)$.} and described adjacency labelling schemes for several classes of graphs, including planar graphs, that use labels of length $O(\log n)$.  Since this initial work, adjacency labelling schemes and, more generally, informative labelling schemes have remained a very active area of research \cite{alstrup.kaplan.ea:adjacency,abrahamsen.alstrup.ea:near-optimal,alstrup.dahlgaard.ea:sublinear,alstrup.gortz.ea:distance,alstrup.gavoille.ea:simpler,alstrup.rauhe:improved,X,X,X,X,X}. Here we review results most relevant to the current work, namely results on planar graphs and their supporting results on trees and bounded-treewidth graphs.

Muller's scheme for planar graphs \cite{muller:local} is based on the fact that planar graphs are 5-degenerate uses labels of length $6\lceil\log n\rceil$.  Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit} use the fact that planar graphs have arboricity 3 (so their edges can be partitioned into three forests \cite{nash-williams:edge-disjoint}) to devise an adjacency labelling scheme for planar graphs whose labels have length at most $4\lceil\log n\rceil$.  

A number of adjacency-labelling schemes for $n$-vertex forests that use labels of length $(1+o(1))\log n$ have been devised \cite{chung:universal, alstrup.rauhe:improved,alstrup.dahlgaard.ea:optimal}, culminating with a recent scheme that uses labels of length $\log n + O(1)$ \cite{alstrup.dahlgaard.ea:optimal}.  Combined with the fact that planar graphs have arboricity 3, these schemes imply adjacency labelling schemes for $n$-vertex planar graphs whose labels have length $(3+o(1))\log n$.   (Schnyder's representation of planar graphs in terms of dimension-3 posets \cite{schnyder:planar} also implies a $3\lceil\log n\rceil$-bit labelling scheme for planar graphs.)

A further improvement, also based on the idea of partitioning the edges of a planar graph into simpler graphs was obtained by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  They describe an adjacency labelling scheme for $n$-vertex graphs of bounded treewidth that use labels of length $(1+o(1))\log n$.  The edges of a planar graph can be partitioned into two sets, each of which induces a bounded treewidth graph.  This results in a $(2+o(1))\log n$-bit labelling scheme for $n$-vertex planar graphs.

Very recently, Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter} described a $(4/3+o(1))\log n$-bit labelling scheme for planar graphs based on a recent \emph{graph product structure theorem} of DujmoviÄ‡ \etal\ \cite{dujmovic.joret.ea:planar}.  This product structure theorem states that any planar graph is a subgraph of the strong product $H\boxtimes P$ where $H$ is a bounded-treewidth graph and $P$ is a path. See \figref{product}. It is helpful to think of $H\boxtimes P$ as a graph whose vertices can be partitioned into $h:=|V(P)|$ \emph{rows} $H_1,\ldots,H_{h}$, each of which induces a copy of $H$ and with vertical and diagonal edges joining corresponding and adjacent vertices between consecutive rows.  
% We now quickly sketch the construction of Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter}.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics{figs/product}
  \end{center}
  \caption{The strong product $H\boxtimes P$ of a binary tree $H$ and a path $P$.}
  \figlabel{product}
\end{figure}  
% In the following two paragraphs we omit $o(\log n)$ terms.

The product structure theorem quickly leads to a $(1+o(1))\log(mh)$-bit labelling scheme where $m:=|V(H)|$ and $h:=|V(P)|$ by using a $(1+o(1))\log m$-bit labelling scheme for $H$ (a bounded treewidth graph) and a $(1+o(1))\log h$-labelling scheme for $P$ (a path).  However, in the worst case $m$ and $h$ are each $\Omega(n)$, so this offers no immediate improvement over the existing $(2+o(1))\log n$-bit scheme.

Bonamy, Gavoille, and Pilipczuk improve upon this by cutting $P$ (and hence $G$) into subpaths of length $n^{1/3}$ by removing $O(n^{2/3})$ vertices of $G$ that have a neighbourhood of size $O(n^{2/3})$. The resulting (cut) graph is a subgraph of $H'\boxtimes P'$ where $H'$ has bounded treewidth, $|H'|=O(n)$, and $P'$ is a path of length $O(n^{1/3})$ so it has a labelling scheme in which each vertex has a label of length $(1+o(1))\log (|H'|n^{1/3})\le (4/3+o(1))\log n$.  A slight modification of this scheme allows for the $O(n^{2/3})$ \emph{boundary} vertices adjacent to the cuts to have shorter labels, of length only $(2/3+o(1))\log n$.  The cut vertices and the boundary vertices induce a bounded-treewidth graph of size $O(n^{2/3})$.  The vertices in this graph receive secondary labels of length $(2/3+o(1))\log n$.  In this way, every vertex receives a label of length at most $(4/3 + o(1))\log n$.

\subsection{The New Result}

The adjacency labelling scheme described in the current paper is also based on the product structure theorem for planar graphs, but it avoids cutting the path $P$, and thus avoids boundary vertices that take part in two different labelling schemes.  Instead, it uses a weighted labelling scheme on the rows of $H\boxtimes P$ in which vertices that belong to $H_i$ receives a label of length $(1+o(1))\log n-\log W_i$ where $W_i$ is related to the number of vertices of $G$ contained in $H_i$ and $H_{i-1}$.  The vertices of $G$ in row $i$ participate in a secondary labelling scheme for the subgraph of $G$ contained in $H_i$ and $H_{i-1}$ and the labels in this scheme have length $\log W_i + o(\log n)$. Thus every vertex receives two labels, one of length $(1+o(1))\log n-\log W_i$ and another of length $\log W_i + o(\log n)$ for a total label length of $(1+o(1))\log n$.  

The key new technique that allows all of this to work is that the labelling schemes of the rows are not independent.  All of these labelling schemes are based on a single balanced binary search tree $T$ that undergoes insertions and deletions resulting in a sequence of related binary search trees $T_1,\ldots,T_h$ where each $T_i$ contains all vertices of $G$ in $H_{i}$ and $H_{i-1}$ and the label assigned to a vertex of $H_i$ is (essentially) based on a path from the root of $T_i$ to some vertex of $T_i$.  By carefully designing these trees, the tree $T_{i-1}$ and $T_{i}$ can be similar enough so that the labels for $v$ in $H_i$ can be obtained, with $o(\log n)$ additional bits from the label for $v$ in $H_{i-1}$.

The product structure theorem has been generalized to a number of additional graph families including bounded-genus graphs, apex minor free graphs, $k$-planar graphs, powers of bounded-degree bounded genus graphs, and $k$-nearest neighbour graphs of points in $\R^2$. As a side-effect of designing a labelling scheme to work directly on subgraphs of a strong product, we obtain labelling schemes for all of these classes of graphs in which vertices in any $n$-vertex member of this graph are assigned labels of length $(1+o(1))\log n$.  All of these results are optimal up to the lower order term.

\subsection{Outline}

The remainder of the paper is organized as follows. \Secref{preliminaries} reviews some preliminary definitions and easy results.  \Secref{pxp} solves a special case, where $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1$ and $P_2$ are both paths.  \Secref{hxp} extends this solution to the case where $G$ is an $n$-vertex subgraph of $H\boxtimes P$.  \Secref{conclusion} summarizes and concludes with directions for future work.

% \subsection{Proof Overview}
% 
% Like Bonamy \etal\ \cite{bonamy.gavoille.ea:shorter}.  Our starting point is a recent result that characterizes planar graphs in terms of the strong product of two simpler graphs.  The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
% \begin{enumerate}
%   \item  $v_1\neq v_2$; and
%   \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
%   \item $y_1=y_2$ or $y_1y_2\in E(B)$.
% \end{enumerate}
% 
% \begin{thm}[DujmoviÄ‡ \etal \cite{dujmovic.joret.ea:planar}]
%   Every planar graph $G$ is the subgraph of a strong product $G^+:=H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
% \end{thm}
% 
% \ldots

% \snote{TODO: Gwen and Piotr's comments.}

% For graph products like $G^+$, there is a natural labelling scheme: Computer a labelling scheme $\alpha:V(H)\to\{0,1\}^*$ for $H$ and a labelling scheme $\beta:V(P)\to\{0,1\}^*$ for $P$ and assign each vertex $v:=(x,y)\in V(G^*)$ the label $\mu(v):=\alpha(x),\beta(y)$.  Given two labels $\ell_1=\alpha(x_1),\beta(y_1)$ and $\ell_2=\alpha(x_2),\beta(y_2)$ for vertices $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ adjacency testing is done using the following formula whose three clauses follow from definition of strong product:
% \[
%     L(\ell_1,\ell_2):= (\ell_1\neq \ell_2) \wedge \A(\alpha(x_1),\alpha(x_2)) \wedge \A(\beta(y_1),\beta(y_2)) \enspace .
% \]
% 
% \ldots



\section{Preliminaries}
\seclabel{preliminaries}

For a graph $G$, we use $V(G)$ and $E(G)$ to denote the vertex and edge sets of $G$.  We use $|G|$ as a shorthand for $|V(G)|$. For a vertex $v\in V(G)$, let $N_G(v):=\{w\in V(G): vw\in E(G)\}$ and $B_G(v):=N_G(v)\cup\{v\}$ denote the open neighbourhood and closed neighbourhood of $v$ in $G$, respectively.

\subsection{Prefix-Free Codes}

For a string $s=s_1,\ldots,s_k$, we use $|s|:=k$ to denote the length of $s$. A string $s_1,\ldots,s_k$ is \emph{prefix} of a string $t_1,\ldots,t_\ell$ if $k\le \ell$ and $s_1,\ldots,s_k=t_1,\ldots,t_k$.  A \emph{prefix-free code} $c:X\to\{0,1\}^*$ is a one-to-one function in which $c(x)$ is not a prefix of $c(y)$ for any two distinct $x,y\in X$.  Let $\N$ denote the set of non-negative integers.  The following is an old result of Elias:

\begin{lem}[Elias \cite{elias:universal}]\lemlabel{elias}
    There exist a prefix-free code $\gamma:\N\to\{0,1\}^*$ such that, for each $i\in\N$, $|\gamma(i)|\le 2\lfloor\log(i+1)\rfloor + 1\in O(\log(i+1))$.
\end{lem}

\subsection{Labelling Schemes Based on Binary Trees}

A \emph{binary tree} $T$ is a rooted binary tree in which each node except the root is either the \emph{left} or \emph{right} child of its parent and each node has at most one left and at most one right child.  For any node $v$ in $T$, $P_T(v)$ denotes the path from the root of $T$ to $v$.  The \emph{length} of a path $P$ is the number of edges in $P$.  The \emph{depth}, $d_T(v)$ of $v$ is the length of $P_T(v)$.  The \emph{height} of $T$ is $h(T):=\max_{v\in V(T)} d_T(v)$.  A \emph{perfectly balanced} binary tree is any binary tree $T$ with $h(T)=\lfloor\log|T|\rfloor$.

A binary tree is \emph{full} if each non-leaf node has exactly two children. For a binary tree $T$, we let $T^+$ denote the full binary tree obtained by attaching $2-c$ leaves to each node of $T$ with $c$ children.  We call the leaves in $V(T^+)\setminus V(T)$ the \emph{external nodes} of $T$.  (Note that the external nodes of $T$ are leaves of $T^+$ that are not actually in $T$.)

A node $a\in V(T)$ is an \emph{ancestor} of $v\in V(T)$ if the path in $T$ from the root of $T$ to $v$ includes $a$.  (Note that $v$ is an ancestor of itself.) For a node subset $X\subseteq V(T)$, the \emph{lowest common ancestor} of $X$ is the maximum-depth node $a\in V(T)$ such that $a$ is an ancestor of $v$ for each $v\in X$.

Let $v_0,\ldots,v_{r}$ be a path from the root $v_0$ of $T$ to some node $v_r$ (possibly $r=0$).  Then the \emph{signature} of $v_r$ in $T$, denoted $\sigma_T(v_r)$ is a binary string $b_1,\ldots,b_r$ where $b_i=0$ if and only if $v_{i}$ is the left child of $v_{i-1}$.  (Note that the signature of the root $v_0$ of $T$ is the empty string,  $\sigma_T(v_0)=\varepsilon$.)

A \emph{binary search tree (BST)} $T$ is a binary tree  whose node set $V(T)\subset\R$ consists of real numbers and that has the \emph{BST property}:  For each node $x$, $z<x$ for each node $z$ in $x$'s left subtree and $z>x$ for each node $z$ in $x$'s right subtree. For any $x\in\R\setminus V(T)$, the \emph{search path} $P_T(x)$ in $T$ is the unique root-to-leaf path $v_0,\ldots,v_r$ in $T^+$ such that adding $x$ as a (left or right, as appropriate) leaf child of $v_{r-1}$ in $T$ would result in a binary search tree $T'$ with $V(T')=V(T)\cup\{x\}$.

The following observation allows us to replace (possibly large) numbers with (potentially shorter) binary strings:

\begin{obs}\obslabel{lexicographic}
  For any binary search tree $T$ and any $x,y\in V(T)$, $x<y$ if and only if $\sigma_T(x)$ is lexicographically less than $\sigma_T(y)$.
\end{obs}

Let $\R^+$ denote the set of positive real numbers. The following is an easy and often-used result about biased binary search trees:

\begin{lem}\lemlabel{biased-bst}
  For any function $w:\{1,\ldots,n\}\to\R^+$, there exists a binary search tree $T$ containing $\{1,\ldots,n\}$ such that, for each $i\in\{1,\ldots,n\}$, $d_T(i)\le\log(W/w(i))$, where $W:=\sum_{i=1}^n w(i)$.
\end{lem}

To construct the tree in \lemref{biased-bst}, choose the root of $T$ to be the unique node $x\in\{1,\ldots,n\}$ such that $\sum_{z=1}^{x-1} w(z)\le W/2$ and $\sum_{z=x+1}^{n} w(z)< W/2$.  Then recurse on $\{1,\ldots,x-1\}$ and $\{x+1,\ldots,n\}$ to obtain the left and right subtrees, respectively.

The following fact about binary search trees is useful, for example, in the deletion algorithms for several types of balanced binary search trees \cite[Section~6.2.3]{morin:open}:

\begin{lem}\lemlabel{predecessor-encoding}
  Let $T$ be a binary search tree and let $x,y\in V(T)$ be such that $x<y$ and there is no node $z\in V(T)$ such that $x<z<y$ (i.e., $x$ and $y$ are consecutive in the sorted order of $V(T)$).  Then
  \begin{enumerate}
    \item (if $y$ has no left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by removing all trailing 0's and the last 1; or
    \item (if $y$ has a left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by appending a 0 followed by $s:=d_T(y)-d_T(x)-1$ 1's.
  \end{enumerate}
\end{lem}

Putting some of the preceding results together we obtain the following useful coding result:

\begin{lem}\lemlabel{row-code}
  The exists a function $A:(\{0,1\}^*)^2\to\{-1,1,\perp\}$ such that, for any $h\in\N$, and any $w:\{1,\ldots,h\}\to\R^+$ there is a prefix-free code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that 
  \begin{compactenum}
    \item for each $i\in\{1,\ldots,h\}$, $|\alpha(i)|=\log W -\log w(i) + O(\lg\lg h)$; and
    \item for each distinct $i,j\in\{1,\ldots,h\}$, 
    \[   A(\alpha(i),\alpha(j)) 
    = \begin{cases}
       1 & \text{if $j=i+1$} \\
       -1 & \text{if $j=i-1$} \\
       \perp & \text{otherwise}
      \end{cases}
      \]
    \end{compactenum}
\end{lem}


\begin{proof}
  Define $w':\{1,\ldots,h\}\to \R^+$ as $w'(i)=w(i)+W/h$ and let $W':=\sum_{i=1}^h w'(i)=2W$.
  Using \lemref{biased-bst}, construct a biased binary search tree $T$ on $\{1,\ldots,h\}$ using $w'$ so that 
  \[   
    d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log w(i)+1 \enspace .
  \]
  Also
  \[
  d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log (W/h)+1 \le \log h + 1\enspace .
  \]
  for each $i\in\{1,\ldots,h\}$.  The code $\alpha(i$) for $i$ consists of three parts.  The first part, $\gamma(|\sigma_T(i)|)$, encodes the length of the path from the root to $i$ in $T$. The second part $\sigma_T(i)$ encodes the left/right turns along this path.  
  
  The third part $\delta(i)$ of $\alpha(i)$ is the encoding implicit in \lemref{predecessor-encoding}.  That is $\delta(i)$ consists of
  a single bit indicating whether $i$ has a left-child in $T$ and, in case $i$ does have a left-child, an Elias encoding $\gamma(s)$ of the value $s:=d_T(i-i)-d_T(i)-1$.  More precisely, $\delta(i)=0$ or $\delta(i)=1,\gamma(s)$.  The length of $\delta(i)$ is at most $1+O(\log(s+1))=O(\lg\lg h)$.

  The function $A$ is now given by a simple algorithm: Given $\alpha(i)$ and $\alpha(j)$ we extract and lexicographically compare $\sigma_T(i)$ and $\sigma_T(j)$.  Assume, for now that $\sigma_T(i)$ is lexicographically less than $\sigma_T(j)$ so that, by \obsref{lexicographic}, $i < j$.  Now using $\sigma_T(j)$ and $\delta(j)$, compute $\sigma_T(j-1)$.  If $\sigma_T(j-1)=\sigma_T(i)$ then output $1$, otherwise output $\perp$.
  In the case where $\sigma_T(i)$ is lexicographically greater than $\sigma_T(j)$ we proceed in the same manner, but reversing the roles of $i$ and $j$ and outputting $-1$ in the case where $\sigma_T(i-1)=\sigma_T(j)$.
\end{proof}

\subsection{Chunked Sets and Fractional Cascading}

For non-empty sets $X,Y\subset \R$ and an integer $a$, we say that $X$ \emph{$a$-chunks} $Y$ if, for any $a+1$-element subset $S\subseteq Y$, there exists $x\in X$, such that $\min(S)\le x\le \max(S)$. Observe that, if $X$ $a$-chunks $Y$, then $|Y|\le a(|X|+1)\le 2a|X|$.

\begin{lem}\lemlabel{fractional}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exists sets $V_0,\ldots,V_{h+1}$ such that
  \begin{compactenum}
    \item for each $y\in\{1,\ldots,h\}$, $V_y\supseteq SS_y$;
    \item for each $y\in\{1,\ldots,h\}$, $V_{y-1}$ 3-chunks $V_y$ and $V_{y+1}$ 3-chunks $V_y$;
    \item $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|$.
  \end{compactenum}
\end{lem}

A proof of a much more general version of \lemref{fractional} (with larger constants) is implicit in the iterated search structure of Chazelle and Guibas \cite{chazelle.guibas:fractional1}.   For the sake of completeness, \appref{fractional-proof} includes a proof that borrows heavily from the amortized analysis of partially persistent data structures \cite[Section~2.3]{driscoll.sarnak.ea:making}.


\subsection{Product Structure Theorems}

The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
\begin{enumerate}
  \item  $v_1\neq v_2$; and
  \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
  \item $y_1=y_2$ or $y_1y_2\in E(B)$.
\end{enumerate}

\begin{thm}[DujmoviÄ‡ \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure}
  Every planar graph $G$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
\end{thm}

\thmref{product-structure} has a number of generalizations to other minor-closed families of graphs including bounded genus graphs.  The most general of these applies to apex-minor free graphs:

\begin{thm}[DujmoviÄ‡ \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure-apex-minor-free}
  Let $\mathcal{G}$ be a minor-closed family of graphs that excludes some fixed apex graph.  Then every $G\in\mathcal{G}$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of bounded treewidth and $P$ is a path.
\end{thm}

DujmoviÄ‡, Morin, and Wood \cite{dujmovic.morin.ea:structure} give analogous product structure theorems for some non-minor closed families of graphs based on so-called $(k,d)$-shortcut systems.  Such graphs include $k$-planar graphs, map graphs, powers of bounded-degree planar graphs, and $k$-nearest-neighbour graphs in 2 dimensions.

Our main result, which is a labelling scheme for subgraphs of $H\boxtimes P$ where $H$ has bounded treewidth and $P$ is a path holds for all these classes of graphs.\snote{Todo: Write a monstrous corollary}


\section{Bulk Trees}

The labelling scheme for planar graphs uses labels whose largest part comes from paths in a special type of balanced binary search tree that we call a \emph{bulk tree}.

The operations in a bulk tree proceed in \emph{rounds} where, in each round, two types of bulk operations are performed: \emph{bulk insertion}, in which a set $I\subset \R\setminus V(T)$ of new values are inserted into $T$, and \emph{bulk deletion}, in which a set $D\subseteq V(T)$ of values are removed from $T$.  

The sets $I$ and $D$ inserted into and deleted from $T$ in a single round must satisfy the following two restrictions: (i)~$V(T)$ $3$-chunks $I$; and (ii)~$V(T)\setminus D$ 3-chunks $D$.\footnote{There is nothing special about the constant $3$ here.  The data structure and its analysis work with $3$ replaced by any constant $a$.}  Note that (ii) implies that $|D|\le 6|V(T)|-|D|$, so $|D|\le (6/7)|V(T)|$.

\subsection{Phases}

A bulk tree is parameterized by an integer $k\ge 1$.  The rounds of a bulk tree are broken up into \emph{phases} that are kept track of using two integer values.  At the beginning of a phase, a counter $y$ is initialized to $0$ and a value $y^*$ is computed:
\[  
  y^* := \left\lceil \frac{\log|T|}{k-\log 7}\right\rceil 
\]
After each round, the value $y$ is incremented.  When $y=y^*$, a new phase begins, so $y$ is reset to 0 and a new value of $y^*$ is computed using the current size of $T$.

\subsection{Bulk Insertion}

The bulk insertion operation is implemented as follows: Let $z_0,\ldots,z_{|T||}$ denote the external nodes of $T$.  For each $i\in\{0,\ldots,|T|\}$, let $I_i:=\{x\in I: P_T(x)=z_i\}$. Since $V(T)$ $3$-chunks $I$, $|I_i|\le 3$ for each $i\in\{0,\ldots,|T|\}$. For each $i\in\{0,\ldots,|T|\}$, construct a perfectly balanced binary search tree $T_i$. For each $i\in\{1,\ldots,|T|\}$, replace $z_i$ with $T_i$ in $T^+$.

\begin{lem}\lemlabel{insertion-depth}
  Let $T$ be any binary tree and perform a bulk insertion on $T$ to obtain a new tree $T'$.  Then $T'$ is a supergraph of $T$ and $h(T')\le h(T)+2$.
\end{lem}

\begin{proof}
  That $T'$ is a supergraph of $T$ is obvious.  That $h(T')\le h(T)+2$ comes from the fact that, for each $i\in\{0,\ldots,|T|\}$, $|T_i|=|I_i|\le 3$ and $T_i$ is perfectly balanced, so $h(T_i)\le\lfloor\log 3\rfloor = 1$. Recall that $h(T')$ is the length of the longest root-to-leaf in $T'$. Any root-to-leaf path in $T'$ consists of a root-to-leaf path in $T$ followed by at most 2 elements of $T_i$ for some $i\in\{1,\ldots,|T|\}$.  Therefore the length of any root-to-leaf path in $T'$ and there $h(T')$ is at most $h(T)+2$.
\end{proof}

\subsection{Bulk Deletion}

The bulk deletion operation is implemented as a series of $|D|$ individual deletions, performed in any order, each implemented by running the following recursive algorithm for each $x\in D$:  If $x$ is a leaf, then simply remove $x$ from $T$.  Otherwise, $x$ has at least one child.  If $x$ has a left child, then recursively delete the largest value $x'$ in the subtree of $T$ rooted at the left child of $x$ and then replace $x$ with $x'$.  Otherwise $x$ has a right child, so recursively delete the smallest value $x'$ in the subtree of $T$ rooted at the right child of $x$ and then replace $x$ with $x'$.


\begin{lem}\lemlabel{deletion-signature}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, for any $x\in V(T')$, $\sigma_{T'}(x)$ is prefix of $\sigma_T(x)$.
\end{lem}

\begin{proof}
  This follows immediately from the fact the only operations performed during a bulk deletion are (i)~deletion of leaves and (ii)~using a value $x'$ to replace the value of one of its ancestors $x$.  The deletion of a leaf has no effect on $\sigma_{T'}(x)$ for any $x\in V(T')$ since the deleted leaf is not in $V(T')$.  For any node $z$ other than $x'$, (ii) has no effect on $\sigma_T(z)$.  For the node $x'$, (ii) has the effect of replacing $\sigma_T(x')$ by its length-$d_T(x)$ prefix.  Therefore, for any node $z\in v(T)$, $\sigma_{T'}(z)$ is obtained by truncating $\sigma_{T}(z)$ zero or more times, so $\sigma_{T'}(x)$ is a prefix of $\sigma_T(z)$.
\end{proof}

The following consequence of \lemref{deletion-signature} follows immediately from the fact, for any node $z$ in a binary search tree $T$, $d_T(z)=|\sigma_T(z)|$.

\begin{lem}\lemlabel{deletion-depth}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, $h(T')\le h(T)$.
\end{lem}


\subsection{Rebalancing}

At the beginning of a round, before bulk insertion and bulk deletion, a rebalancing operation is performed.  This operation uses several subroutines that we now discuss, beginning with the most fundamental one:  $\mathrm{split}(x)$.

\subsubsection{The $\mathrm{split}(x)$ Subroutine}

The argument of $\mathrm{split}(x)$ is a node $x\in V(T)$ and the end result of the subroutine is to split $T$ into two subtrees $T_{<x}$ and $T_{>x}$ where $V(T_{<x})=\{z\in V(T): z<x\}$ and $V(T_{>x})=\{z\in V(T): z>x\}$. Refer to \figref{split}.  Let $x_0,\ldots,x_r$ be the path in $T$ from the root $x_0$ of $T$ to $x=x_r$.  Partition $x_0,\ldots,x_{r-1}$ into two subsequences $a:=a_0,\ldots,a_\iota$ and $b:=b_0,\ldots,b_\kappa$ where the elements of $a$ are less than $x$ and the elements of $b$ are greater than $x$.

\begin{figure}
  \begin{center}
    \includegraphics{figs/split-1} \\[1ex]
    $\Downarrow$ \\[1ex]
    \includegraphics{figs/split-2}
  \end{center}
  \caption{The operation of $\mathrm{split}(x)$.}
  \figlabel{split}
\end{figure}

Make a binary search tree $T_0$ that has $x$ as root, the path $a_0,\ldots,a_t$ as the left subtree of $x$ and the path $b_0,\ldots,b_s$ as the right subtree of $x$.  Note that $a_{i+1}$ is the right child of $a_i$ for each $i\in\{1,\ldots,\iota-1\}$ and $b_{i+1}$ is the left child of $b_i$ for each $i\in\{1,\ldots,\kappa-1\}$. 

Next, consider the forest $F:=T-\{x_0,\ldots,x_r\}$. This forest consist of $r+2$ (possibly empty) trees $A_1,\ldots,A_{r-1},L,R$ where $L$ and $R$ are the subtrees of $T$ rooted at the left and right child of $x$ and, for each $i\in\{1,\ldots,r-1\}$, $A_i$ is the subtree of $T$ rooted at the child $c_i\neq x_{i+1}$ of $x_i$.  Make a binary search tree $T_x$ by replacing each of the $r+2$ external nodes of $T_0^+$ with the appropriate tree in $F$.  Finally, let $T_{<x}$ be the subtree of $T_x$ rooted at the left child of $x$ and let $T_{>x}$ be the subtree of $T_x$ rooted at the right child of $x$.

\begin{lem}\lemlabel{split-height}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\mathrm{split}(x)$ to obtain a new tree $T_{<x}$ and $T_{>x}$.  
  Then $h(T_{<x})\le h(T)$ and $h(T_{>x})\le h(T)$.
\end{lem}

\begin{proof}
  We consider only $T_{<x}$ since the argument for $T_{>x}$ is the same.
  Recall that $h(T_{<x})=\max_{z\in V(T_{<x})} d_{T_{<x}}(z)$.  For each node $z\in V(T_{<x})$, $V(P_{T_{<x}}(z))\subseteq V(P_T(z))$, so $d_{T_{<x}}(z)\le d_T(z)$.
\end{proof}

\subsubsection{The $\textrm{multisplit}(x_1,\ldots,x_c)$ Operation}

From the $\mathrm{split}(x)$ operation we build the $\textrm{multisplit}(x_1,\ldots,x_c)$ operation that takes as input a sequence of nodes $x_1<\cdots<x_c$ of $T$.  For convenience, define $x_0=-\infty$ and $x_{c+1}=\infty$.  The effect of $\textrm{multisplit}(x_1,\ldots,x_c)$ is to split $T$ into a sequence of trees $T_0,\ldots,T_{c}$ where, for each $i\in\{0,\ldots,c\}$, $V(T_i)=\{z\in V(T): x_i< z<x_{i+1}\}$.

The implementation of $\textrm{multisplit}(x_1,\ldots,x_c)$ is straightforward divide-and-conquer:  If $c=0$, then there is nothing to do.  Otherwise, call $\mathrm{split}(x_{\lceil c/2\rceil})$ to obtain $T_{<x_{\lceil c/2\rceil}}$ and $T_{>x_{\lceil c/2\rceil}}$.  Next, apply $\textrm{multisplit}(x_1,\ldots,x_{\lceil c/2\rceil-1})$ to $T_{<x_{\lceil c/2\rceil}}$ to obtain $T_0,\ldots,T_{\lceil c/2\rceil-1}$ and then apply $\textrm{multisplit}(x_{\lceil c/2\rceil+1},\ldots,x_c)$ to $T_{>x_{\lceil c/2\rceil}}$ to obtain $T_{\lceil c/2\rceil},\ldots,T_c$.

The following lemma is immediate from \lemref{split-height} 
\begin{lem}\lemlabel{multisplit-height}
  Let $T$ be any binary search tree and apply the $\textrm{multisplit}(x_1,\ldots,x_c)$ to $T$ to obtain $T_0,\ldots,T_c$.  Then $h(T_i)\le h(T)$ for each $i\in\{0,\ldots,c\}$.
\end{lem}

\subsubsection{The $\mathrm{balance}(x)$ Operation}

The $\mathrm{balance}(T_*)$ operation operates on the subtree $T_x$ of $T$ rooted at some node $x\in V(T)$.  If $|V(T_x)|< 2^k$, then this operation is simply replaces $T_x$ with a perfectly balanced binary search tree containing $V(T_x)$.  

If $|V(T_x)|\ge 2^k$, let $Z\subset V(T_x)$ be the set of at most $2^k-1$ nodes of $T_x$ of depth less than $k$.  Then $T_x-Z$ is a forest consisting of $m\le 2^{k}$ trees $T_1,\ldots,T_m$.  
% Each such tree $T_i$ has height at most $h(T)-k$.

Select the nodes $X:=\{x_1,\ldots,x_{2^k}-1\}$ of $T$ where each $x_j$ has rank $\lfloor j|T_x|/2^k\rfloor$ in the set $V(T_x)$.\footnote{For a finite $X\subset\R$, and $x\in\R$, the \emph{rank} of $x$ in $S$ is $|\{x'\in S: x'<x\}|$.}  For each $j\in\{1,\ldots,m\}$, apply $\textsc{multisplit}(K)$ to the subtree $T_j$ with with the values $K=Y\cap V(T_j)$.  The end result of doing this for each $j\in\{1,\ldots,m\}$ is a collection $T^@_0,\ldots,T^@_\rho$ of subtrees where, for each $i\in\{0,\ldots,\rho\}$, $Z\cup X$ is disjoint from $[\min(V(T^@_i)), \max(V(T^@_i))]$.

Now construct a perfectly balanced tree $T_0$ on $Z\cup X$, for each $i\in\{0,\ldots,\rho\}$ replace the appropriate external node $T_0$ with $T^@_i$ to obtain the new binary search tree $T_x'$.  In $T$, replace $T_x$ with $T_x'$.

\begin{lem}\lemlabel{multisplit-depth}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\mathrm{rebalance}(x)$ to $T$ to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{proof}
  Since $\mathrm{rebalance}(x)$ only affects the subtree $T_x$ rooted at $x$, it suffices to show that $h(T_x')\le h(T_x)+1$.  For each $i\in\{1,\ldots, m\}$,$T_i$ is rooted at a depth-$k$ node of $T$, so $h(T_i)\le h(T)-k$. For each $j\in\{0,\ldots,\rho\}$, $T^@_j$ is obtained by an application of the multisplit operation to $T_i$ for some $i\in\{1,\ldots,m\}$ so, by \lemref{multisplit-height}, $h(T^@_j)\le h(T_i)\le h(T)-k$.  Next, $|Z\cup Y|\le |Z|+|Y| \le 2^k-1 + 2^k-1 < 2^{k+1}-1$.  Therefore $h(T_0)\le k$.  Finally, $h(T')\le h(T_0)+1 +\max\{h(T^@_j):j\in\{1,\ldots,\rho\} \le h(T)+1$.  
\end{proof}

\begin{lem}\lemlabel{balance-x-weight}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\mathrm{rebalance}(x)$ to $T$ to obtain a new tree $T'$.  Then every subtree of $T_x$ rooted at a node of depth $k+1$ has size at most $|T_x|/2^k$.
\end{lem}

\begin{proof}
  Each such subtree is a subtree of $T^@_\iota$ for some $\iota\in\{0,\ldots,\rho\}$. Now, $V(T^@_\iota)\subset (x_j,x_{j+1})$ for some $j\in\{1,\ldots,2^{k-1}\}$.  The values $x_j$ and $x_{j+1}$ have ranks $\lfloor j|T_x|/2^k\rfloor$ and $\lfloor (j+1)|T_x|/2^k\rfloor$ in the set $V(T_x)$.  Therefore, $|T^@_\iota|\le \lfloor (j+1)|T_x|/2^k\rfloor- \lfloor j|T_x|/2^k\rfloor -1 < |T_x|/2^k$.
\end{proof}

\subsubsection{The $\mathrm{bulkbalance}()$ Operation}

Finally, recall that a bulk tree works in phases and, within a phase, maintain a counter $y$ that counts the rounds of a phase from $0$ to $y^*$.  The $\mathrm{balance}()$ operation, described here, executes once, at the beginning of each round, before bulk insertions and deletions are done.  The operation of the $\mathrm{balance}()$ operation is simple to describe.  It calls $\mathrm{balance}(z)$ for each node $z$ of depth $y(k+1)$ in $T$.

The following two lemma are immediate consequences of \lemref{multsplit-depth} and \lemref{balance-x-weight}, respectively.

\begin{lem}\lemlabel{balance-depth}
  Let $T$ be a bulk tree and apply the $\mathrm{bulkbalance}()$ operation to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{lem}\lemlabel{balance-weight}
  Let $T$ be a bulk tree and apply the $\mathrm{bulkbalance}()$ operation to obtain a new tree $T'$.  Then every subtree $T_z$ of $T'$ rooted at a node $z$ of depth $(y+1)(k+1)$ has size at most $|T_x|/2^k$, where $x$ is the depth-$y(k+1)$ ancestor of $z$ and $T_x$ is the subtree of $T$ rooted at $x$.
\end{lem}


\subsection{Analysis of Height}

In this section we show that a bulk deletion tree always has a height that is close to optimal.

\begin{lem}\lemlabel{bulktree-height-i}
  Let $T$ be a bulk deletion tree and let $T_0,\ldots,T_{y^*}$ be the states of $T$ before the first round ($T_0$) and after each round ($T_1,\ldots,T_{y^*}$) of a phase, and let $r_0=h(T_0)-\log|T_0|$.  Then,
  \begin{compactenum}[(i)]
    \item $h(T_{y^*}) = \log|T_{y^*}|+O(k+k^{-1}\log|T_{y^*}|)$; and 
    \item for each $y\in\{0,\ldots,y^*\}$, $h(T_y)\le (1+O(1/k))\log|T_y| + r_0$.
  \end{compactenum}
\end{lem}

\begin{proof}
  Let $I_0,\ldots,I_{y^*-1}$ and $D_0,\ldots,D_{y^*-1}$ be the sets inserted and deleted so that $I_y$ and $D_y$ are the bulk insertions and bulk deletions performed in round $y$.  First, recall that $|D_y|\le (6/7)|T_y|$, which implies that $|T_{y+1}|\ge |T_y|-|D_y|\ge |T_y|/7$.  Iterating this beginning with $T_0$ implies that 
  \[
    |T_y|\ge |T_0|/7^y \quad \Leftrightarrow \quad \log|T_0| \le \log|T_y| + y\log 7 \enspace .
  \] 
  for each $y\in\{0,\ldots,y^*\}$. 


  We will prove the lemma by establishing the following two invariants:
  \begin{enumerate}[(B1)]
    \item $h(T_y)\le h(T_0) + 3y$;
    \item each subtree of $T_y$ rooted at a node of depth $y(k+1)$ has size at most $|T_0|(6/2^k)^{y}$.
  \end{enumerate}

  First we show (B2) implies (i).  Recall that $y^*=\lceil\log|T_0|/(\log(2^k/6))\rceil$ so
  $|T_{0}|(6/2^k)^{y^*} \le 1$.  Therefore, by (B2) every subtree of $T_{y^*}$ of depth $y^*(k+1)$ has size at most 1.  A subtree of size 1 has height 0.  Therefore,
  \begin{align*}
    h(T_{y^*}) & \le (k+1)y^* \\
    & = (k+1)\left\lceil \frac{\log|T_1|}{k-\log 6}\right\rceil \\
    & \le (k+1)\left(\frac{\log|T_1|}{k-\log 6 } + 1\right)\\
    & = \left(\frac{k+1}{k-\log 6}\right)\left(\log|T_1|\right) + (k+1)\\
    & = (1+O(1/k))\cdot(\log|T_1|) + (k+1) \\
    & \le (1+O(1/k))\cdot(\log|T_{y^*}| + y^*\log 7) + (k+1) \\
    & = \log|T_{y^*}| + O(k+k^{-1}\log |T_{y^*}|) \enspace .
  \end{align*}
  for sufficiently large $k$.  \snote{I say this here and later. Should quantify.}

  Next we show that (B1) implies (ii). For each  $y\in\{0,\ldots,y^*\}$, (B1) gives the upper bound
  \begin{align}
       h(T_y) & \le h(T_1) + 3y \nonumber \\
              &= \log|T_1| + 3y + r_0 \nonumber \\
              &\le \log |T_y| + (3+\log 7)y + r_1 \nonumber \\
              &\le \log |T_y| + (3+\log 7)y^* + r_1 \nonumber \\
              &\le \log |T_y| + O(k^{-1}\log|T_y|) + r_1 \enspace .
  \end{align}

  All that remains is to show that invariants (B1) and (B2) are indeed satisfied for all $y\in\{0,\ldots,y^*\}$.  The proof is by induction on $y$.  For the base case $y=0$, both properties are trivial: (B1) asserts that $h(T_0)\le h(T_0)$ and (B2) asserts that the subtree of $T_0$ rooted at the root of $T_0$ has size at most $|T_0|$.

  For the inductive step, assume $y\ge 1$ and invariants (B1) and (B2) hold for $T_{y-1}$.  First we establish invariant (B1) as follows:
  Lemmas~\ref{lem:insertion-depth}, \ref{lem:deletion-depth}, and \ref{lem:balance-depth} imply that $h(T_y)\le h(T_{y-1})+3$.  
  By the inductive hypothesis (B1) is satisfied for $T_{y-1}$, $h(T_{y-1})\le 3(y-1) + r_0$.  Thus $h(T_y)\le h(T_{y-1}) + 3 \le 3y+r_0$.
  
  Next we establish (B2).  By (B2) applied to $T_{y-1}$, every subtree of $T_{y-1}$ rooted at a node of depth $(y+1)(k+1)$ has size at most $|T_{1}|(2a/2^k)^{y-1}$.  The first step in round $y-1$ is to execute $\mathrm{bulkbalance}(y-1)$.  By \lemref{balance-weight}, this results in a tree $T_{y-1}'$ in which every subtree rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(6/2^k)^{y-1}/2^k$.  The second step in round $y-1$ is perform a bulk insertion on $T_{y-1}'$ to obtain a new tree $T_{y-1}''$.  The fact that $V(T_{y-1})$ 3-chunks the newly inserted set $I_{y-1}$ ensures that the size of any subtree increases by a factor of at most $6$.  Therefore, every subtree of $T_{y-1}''$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(6/2^k)^{y}$.  Finally, third step in round $y-1$ is to perform a bulk deletion on $T_{y-1}''$ to obtain $T_{y}$.  Bulk deletion does not increase the size of any subtree, so every subtree of $T_{y}$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(6/2^k)^{y}$, as required.
\end{proof}

A \emph{bulk tree sequence} $T_0,\ldots,T_h$ is a sequence of binary search trees where $T_y$ is a perfectly balanced binary search tree and for each $y\in\{2,\ldots,h\}$, $T_y$ is obtained from $T_{y-1}$ by a round of bulk tree operations (rebalance, bulk insert, bulk delete).  Note that any bulk tree sequence also defines sequences $I_0,\ldots,I_{h-1}$ and $D_0,\ldots,D_{h-1}$ of insertion and deletion sequences, respectively, where $I_y:=T_{y+1}\setminus T_y$ and $D_y:=T_{y}\setminus T_{y+1}$ for each $y\in\{0,\ldots,h-1\}$. 
Our final lemma shows that bulk trees are balanced at all times:
\begin{lem}\lemlabel{bulk-tree-height}
  For each bulk tree sequence $T_0,\ldots,T_h$ and each $y\in\{0,\ldots,h\}$,  $h(T_y)\le \log|T_y| + O(k+k^{-1}\log|T_y|)$.
\end{lem}

\begin{proof}
  % This lemma follows almost immediately from \lemref{bulktree-height-i}(ii) except for the additional $r_0$ term. 
  Let $Y\subseteq\{0,\ldots,h\}$ be the set of indices containing exactly those indices $y$ where $T_y$ begins a new phase. By definition $0\in Y$ and, since $T_0$ is a perfectly balanced binary tree it certainly satisfies the conditions of the lemma.  For $y\in Y\setminus\{0\}$, 
  \lemref{bulktree-height-i}(i) implies that $T_y$ satisfies the conditions of the lemma.  
  
  All that remains is to show that the conditions of the lemma are satisfied for every $y\in\{0,\ldots,h\}\setminus Y$. To show this, let $y_0=\max\{ y'\in Y: y'<y\}$.  That is, $T_{y_0}$ is the tree that began the phase in which $T_y$ takes part.  In this case \lemref{bulktree-height-i}(ii) implies that
  \[  h(T_j) \le (1+O(1/k))\log |T_j| + h(T_{y_0})-\log|T_{y_0}| \]  
  Thus, all all that is required is to show that $r_0:=h(T_{y_0})-\log|T_{y_0}|\in O(k^{-1}\log|T_y|)$ so that is what we do:
  \begin{align*}
    r_0 &= h(T_{y_0})-\log|T_{y_0}| \\
       &\le O(k + k^{-1}\log|T_{y_0}|) \\
       &\le O(k + k^{-1}\log|T_{y}| + (y-y_0)) \\
       &\le O(k + k^{-1}\log|T_{y}| + k^{-2}\log|T_0|) \\
       &= O(k + k^{-1}\log|T_{y}|) \enspace , \qedhere
  \end{align*}
  for sufficiently large $k$. \snote{Again: quantify}
\end{proof}

Definition: A \emph{bulk tree sequence} is a sequence of trees $T_0,\ldots,T_h$ such that $T_0$ is a perfectly balanced binary search tree and, for each $y\in\{1,\ldots,h\}$, $I_y:=V(T_y)\setminus V(T_{y-1})$ and $D_y:= V(T_{y-1})\setminus V(T_y)$.  ....

\subsection{Making Bulk Tree Sequences}




\begin{lem}\lemlabel{chunked-bulk-trees}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exists a bulk tree sequence $T_1,\ldots,T_h$ such that $\sum_{y=1}^h |T_y|\le 2\sum_{y=1}^h |S_i|$ and, for each $y\in\{1,\ldots,h\}$, $V(T_y)\supseteq S_y$.
\end{lem}

\begin{proof}
  For any finite sets
\end{proof}

The proof of \lemref{chunked-bulk-trees} follows immediately from 







  
%   $V(T_y)\supseteq S_i$
%   \begin{compactenum}
%     \item $T_1$ is a perfectly balanced search tree.  with $\sum_{y=1}^h |S_y|$.   be any sequence of number
% \end{lem}



\section{Transition Codes for Nodes}
\seclabel{node-transitions}

\begin{lem}\lemlabel{node-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each bulk tree sequence $T_0,\ldots,T_h$, each $y\in\{0,\ldots,h-1\}$, and each $z\in V(T_y)\cap V(T_{y+1})$, there exists $\nu_y(z)\in\{0,1\}^*$, $|\nu_y(z)| = O(k\lg h(T_y))$ such that $B(\sigma_{T_y}(z), \nu_y(z)) = \sigma_{T_{y+1}}(z)$.  
\end{lem}

\begin{proof}
  The transformation that $T_{y}$ to $T_{y+1}$ occur in three steps: rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion, which takes $T_y''$ onto $T_{y+1}$.
  
  The transition from $T_y''$ to $T_{y+1}$ is simple.  By \lemref{deletion-signature}, the effect of each individual deletion on $\sigma_T(z)$ is to remove a suffix.  Therefore, the net effect of all deletions is to remove a suffix.  The length of this suffix can be included in $\nu_y(x)$ using $O(\lg h(T))$ bits.
  
  The transition from $T_y'$ to $T_y''$ is even simpler: For every node $z\in V(T_y')\cap V_(T_y'')$, $\sigma_{T_y'}(z)=\sigma_{T_y''}(z)$.  A bulk addition does not require any changes to encode.
  
  The most elaborate transition is from $T_y$ to $T_y'$.  We will show how to obtain $\sigma_{T_y'}(z)$ by starting with $b:=\sigma_{T_y}(z)$ and performing the following operations:
  \begin{enumerate}[($\nu_1$)]
    \item Splitting $b$ into two strings $b^-$ and $b'$ at some index that can be specified using $O(\lg h(T))$ bits.
    \item Deleting a prefix of $b'$ whose length can be described using $O(\lg h(T))$ bits.
    \item Repeatedly (up to $k$ times) deleting a prefix of $b'$ and replacing it with a string in the set $\Pi:=\{\varepsilon\}\cup\bigcup_{j=0}^{h(T_y)}\{0^j, 1^j, 0^j1, 1^j0\}$. The length of each deleted prefix and its replacement can be described with $O(\lg h(T))$ bits for a total of $O(k\lg h(T))$ bits.
    \item Adding a specific $O(k)$-bit prefix to $b'$, which can be described with $O(k)$ bits.
    \item appending $b^-$ and $b'$ to obtain $\sigma_{T_y'}(z)$.
  \end{enumerate}
  To verify this we have to dig into the details of the rebalancing operations:
  The $\textrm{bulkbalance}()$ operation calls $\textrm{balance}(x)$ on all the nodes $x$ of a given depth $\theta$.    
  For a node $z\in V(T)$, a call to $\textrm{balance}(x)$ does not affect $\sigma_T(z)$ unless $x$ is an ancestor of $z$ in $T$.  Thus, for each $z\in V(T)$, we can focus on the changes to $\sigma_T(z)$ caused by the at most one call to $\textrm{balance}(x)$ where $x$ is an ancestor of $z$. Note that, if $d_{T_y}(z)<\theta$, then $\sigma_{T_y}(z)=\sigma_{T_y'}(z)$, in which case $\nu(z)$ has $O(1)$ bits indicating that this is the case.
  
  Otherwise, $z$ has some ancestor $x$ on which $\textrm{balance}(x)$ executes. In this case $\nu_{1}(z)=\theta$, indicating that $b$ should be split into $b^-$ and $b'$ at position $\theta$.  
  The $\textrm{balance}(x)$ operation first identifies two sets of nodes $Z$ and $X$ that will eventually form the perfectly balanced top tree $T_0$ to which the subtrees $T^@_0,\ldots,T^@_\rho$ are attached.  For each node $z\in Z\cup X$, $\nu_{2}(z):=|b'|$ is the instruction to delete all of $b'$ and replace it with $\nu_{4}(z):=\sigma_{T_0}(z)$.
  
  Any $z\not\in Z\cup X$ is contained in some tree $T_*$ in the forest $F:=T_y-Z$.  In this case, the $\textsc{multisplit}(x_1,\ldots,x_c)$ operation may be called on $T_*$.  If this occurs, then $z$ may be involved in at most $1+\log c\le 1+k$ subtrees that are split by calls to $\mathrm{split}(x)$.  Any call to $\mathrm{split}(x)$ on a subtree $A$ that contains $z$ leaves $z$ in one of the two resulting subtrees $A'$.  When this happens $\sigma_{A'}(z)$ can be obtained from $b':=\sigma_{A}(z)$ by deleting a prefix and replacing it with a string from $\Pi$ (see \figref{split}).  This happens at most $k+1$ times and each of these can be recorded with $O(\lg h(T_y))$ bits that are included in $\sigma_{3}(z)$.
  
  At the end of this process, $z\in V(T^@_j)$ for some $j\in\{1,\ldots,m\}$, and $b'=\sigma_{T^@_j}(z)$.  The tree $T^@_j$ is a subtree of $T_y'$.  The final piece of information then is $\nu_4(z):=\sigma_{T_0}(z')$, where $z'$ is the root of $T^@_j$.  This is a bitstring of length $h(T_0)+1\le k+1$.
\end{proof}





\section{Subgraphs of $P\boxtimes P$}
\seclabel{pxp}

We begin with the special case in which $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1=1,\ldots,m$ and $P_2=1,\ldots,h$ are paths. Each vertex of $G$ is a point $(x,y)\in\{1,\ldots,m\}\times \{1,\ldots,h\}$ in the $m\times h$ grid-with diagonals.  


\subsection{The Labels}

For each $y\in\{1,\ldots,h\}$, we let $L_y=\{x\in\{1,\ldots,m\}:(x,y)\in V(G)\}$ and let $L^-_y:=L_y\cup\{x-1:(x,y)\in V(G)\}$.  Observe that $|L^-_y|\le 2|L_y|$, so $\sum_{y=1}^h |L^-_y|\le 2n$.   Apply \lemref{chunk-bulk-trees} to obtain a sequence $T_1,\ldots,T_h$ of binary search trees such that

\begin{enumerate}[(PR1)]
  \item $V(T_y)\supseteq \bigcup_{b\in\{-1,0,1\}}L^-_{y+b}$;
  \item $h(T_y)=\log|T_y| + O(k+k^{-1}\lg n)$;
  \item $\sum_{y=1}^h|T_y| \le 12n$.
\end{enumerate}

By \lemref{node-transitions}, for each $y\in\{2,\ldots,h\}$ and each $x\in L_{y-1}$, there exists a code $\nu_{y-1}(x)$, $|\nu_y(x)|=O(k\lg\lg n)$ such that $B(\sigma_{T_{y-1}}(x),\nu_{y-1}(x))=\sigma_{T_y}(x)$.

Next, apply \lemref{row-code} using the weight function $w(y):=|T_y|$ to obtain a code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that $|\alpha(y)|=\log n - \log|T_y| + O(\lg\lg n)$.

Now, in the labelling scheme for $G$, each vertex $z=(x,y)\in V(G)$ receives a label consisting of the following:  
\begin{enumerate}[(GC1)]
  \item $\alpha(y)$;
  \item $\gamma(|\sigma_{T_y}(x)|)$ and $\sigma_{T_y}(x)$;
  \item $\delta_{T_y}(x)$;
  \item $\nu_y(x)$; and
  \item an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$.  (Note that some of these 8 vertices may not even be present in $G$ in which case the resulting bit is set to 0 since the edge is not present in $G$.)
\end{enumerate}
The two major components of this label are $\alpha(y)$ (GC1) and $\sigma_{T_y}(x)$ (GC2) which, together have length $\log n + O(\lg\lg n)$.  The remaining components each have size $O(\lg\lg n)$.  

\subsection{Adjacency Testing}

Given the labels of $z_1=(x_1,y_1)$ and $z_2=(x_2,y_2)$ we can test if they are adjacent as follows: Using with $\alpha(y_1)$ and $\alpha(y_2)$ (GC1), determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case we immediately conclude that $z_1$ and $z_2$ are not adjacent since $y_1y_2\not\in E(P_1)$.  
  
  \item $y_1=y_2$: In this case, let $y:=y_1=y_2$, let $T:=T_y$ and lexicographically compare $\sigma_T(x_1)$ and $\sigma_T(x_2)$ to determine (without loss of generality) that $x_1<x_2$.  Using $\sigma_{T}(x_2)$ and $\delta_{T}(x_2)$, compute $\sigma_T(x_2-1)$.  If $\sigma_T(x_2-1)\neq \sigma_T(x_1)$ then immediately conclude that $z_1$ and $z_2$ are not adjacent, since $x_1x_2\not\in E(P_2)$.  Otherwise, we know that $x_1=x_2-1$ and $y_1=y_2$ so use the relevant bit of $a(z_1)$ (or $a(z_2)$) to determine if $z_1$ and $z_2$ are adjacent in $G$.
  
  \item $y_1=y_2-1$: In this case, use $\sigma_{T_{y_1}}(x_1)$ and $\nu_{y_1}(x_1)$ to compute $\sigma_{T_{y_2}}(x_1)$.  Now let $y:=y_2$, let $T:=T_{y}$, and proceed as in the previous case (but consulting a different bit of $a(z_1)$ in the last step.)
  
  \item $y_2=y_1-1$: In this case, use $\sigma_{T_{y_2}}(x_2)$ and $\nu_{y_2}(x_2)$ to compute $\sigma_{T_{y_1}}(x_2)$.  Now let $y:=y_1$, $T:=T_{y}$, and proceed as in the previous case (but consulting a different bit of $a(z_1)$ in the last step.)
\end{enumerate}

This establishes our first result:

\begin{thm}\thmlabel{pxp}
  Let $P$ be an infinite path.  Then the family of subgraph of $P\boxtimes P$ has an $(\log n+ O(\lg\lg n))$-bit labelling scheme.
\end{thm}


\section{Subgraphs of $H\boxtimes P$}
\seclabel{hxp}

In this section we build on the result of \secref{pxp} to find labelling schemes for graphs $G$ that are subgraphs of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,2,\ldots,h$ is a path.  Our strategy is similar the approach taken in the previous section.
For each $y\in\{1,\ldots,h\}$ we define $L_y=\{x: (x,y)\in V(G)\}$ and we will build a labelling scheme for the induced graph $H[V_y]$ where $V_y\supseteq L_{y\pm 1}$ that is based on a binary tree $T_y$ and such that the labels in this scheme have length $\log|T_y|+o(\log n)$.  In addition to this, we will use \lemref{row-code} to give each vertex $(x,y)\in V(G)$ a \emph{row label} of length $\log n - \log|T_y|+o(\log n)$.

\subsection{A Labelling Scheme for $t$-Trees}

We begin by describing a labelling scheme for $t$-Trees that, like the labelling scheme for paths, is based on a binary search tree.

\subsubsection{$t$-Trees}

We begin by describing a labelling schemes for $t$-trees. The ideas behind this scheme are not new; this is essentially the labelling scheme for $t$-trees described by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  However, we present these ideas in a manner that makes it natural to generalize the results of \secref{pxp}.

A graph $H$ is a \emph{$t$-tree} if $H$ is a clique on $t$ vertices or if $H$ contains a vertex $v$ of degree $t$ whose neighbours form a clique and $H-v$ is a $t$-tree.  

Note that the recursive definition of $t$-trees implies that there is a vertex ordering $v_1,\ldots,v_{m}$ of $V(H)$ such that $v_1,\ldots,v_t$ form a clique and, for each $i\in\{t+1,\ldots,t_m\}$, $C_H(v_i):=B_H(v_i)\cap \{v_1,\ldots,v_{i}\}$ is a clique of size $t+1$.  We call $C_H(v_i)$ the \emph{family clique} of $v_i$ and $C_H(v_i)\setminus\{v_i\}$ the \emph{parent clique} of $v_i$.  The order $v_1,\ldots,v_m$ is called a \emph{construction order} for $H$.

The order $v_1,\ldots,v_m$ (in particular, the fact that each $v_i$ has at most $t$ neighbours among $v_1,\ldots,v_{i-1}$) implies that $V(H)$ has a proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$.  For each $i\in\{t+1,\ldots,m\}$ and each $j\in\{1,\ldots,t+1\}$ the \emph{$j$-parent} $p_j(v_i)$ of $v_i$ is the unique element $p\in C_H(v_i)$ with $\varphi(p)=j$.  Note that $v_i$ is the $j$-parent of itself for exactly one $j\in\{1,\ldots,t+1\}$.

\subsubsection{Interval Graphs}

For real numbers $a\le b$, let $[a,b]:=\{ x\in\R: a\le x\le b\}$, and let
$\mathbb{I}:=\{[a,b]: a,b\in\R,\, a\le b\}$ denote the set of closed real intervals.  For a finite set $S\subset\mathbb{I}$ of intervals, the \emph{interval intersection graph} $G_S$ is the graph with vertex set $V(G_S):=S$ and in which the edge $vw\in E(I)$ if and only if $v\cap w\neq \emptyset$.  

% The \emph{thickness} $\omega(G_S)$ of $S$ is the size of its largest clique, which (by Helly's Theorem) is equal to $\max_{x\in\R}|\{v\in V(H):x\in v\}|$.  By Dilworth's Theorem (applied to the poset $(V(I),\prec)$ where $[a,b]\prec [c,d]$ iff $b<c$), the chromatic number $\chi(I)$ of $I$ is equal to its thickness, i.e., $\chi(I)=\omega(I)$.  

The following well-known result states that every $n$-vertex $t$-tree is the subgraph of an interval graph with thickness $O(t\log n)$ \snote{TODO: Use the references David provided}:

\begin{lem}\lemlabel{interval-representation}
  For every $n$-vertex $t$-tree $H$, there exists a mapping $f:V(H)\to\mathbb{I}$, such that the interval intersection graph $G_S$ with $S:=\{f(v):v\in V(H)\}$ has thickness at most $\log_{3/2} t\log n$ and, for every $vw\in E(H)$, $f(v)\cap f(w)\neq\emptyset$.  
  
  Furthermore, for every proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$ of $H$, there exists a proper colouring $\varphi':V(G_S)\to\{1,\ldots,\lceil\log_{3/2} n\rceil\}\times\{1,\ldots,t+1\}$ where, for each $v\in V(H)$, $\varphi'(f(v))=(j,\varphi(v))$ for some $j\in\{1,\ldots,\lceil\log_{3/2} n\rceil\}$.
\end{lem}

In light of \lemref{interval-representation} we will not distinguish between a vertex $v\in V(H)$ and the interval $f(v)$.  That is, we will treat the nodes of every $t$-tree as intervals that satisfy the conditions of \lemref{interval-representation}.

A point $x\in\R$ \emph{stabs} an interval $[a,b]$ if $\{x\}\cap [a,b]=\{x\}$. A finite set $X\subset\R^2$ of points \emph{stabs} a set $S\subset\mathbb{I}$ of intervals if, for every $[a,b]\in S$, at least one point $x\in X$ stabs $[a,b]$, i.e., $X\cap [a,b]\neq\emptyset$.

\begin{lem}\lemlabel{common-ancestor}
  Let $S\subset\mathbb{I}$ be a set of intervals, let $X\subset\R$ be a set of points that stabs $S$, and let $T$ be a binary search tree with $V(T):=X$, let $[a,b]\in S$ and let $x$ be the lowest common ancestor, in $T$, of $X\cap [a,b]$.  Then $x\in [a,b]$.
\end{lem}

\begin{proof}
  Since $x$ is the least common ancestor of $X\cap[a,b]$, either $x\in X\cap[a,b]$, in which case there is nothing prove, or there is some pair $x_1,x_2\in X\cap[a,b]$ such that $x_1$ is in the subtree of $T$ rooted at the left child of $x$ and $x_2$ is in the subtree of $T$ rooted at the right child of $x$.  By the binary search tree property, $x_1<x<x_2$. But $x_1,x_2 \in [a,b]$, so $a\le x_1<x<x_2\le b$, so $x\in [a,b]$.  
\end{proof}

\subsubsection{The Labelling Scheme}
\seclabel{t-tree-labelling}

We can use \lemref{common-ancestor} to create a labelling scheme for a $t$-tree based on any binary search tree containing a stabbing set.  Let $H$ be a $t$-tree whose vertex set $V(H):=S$ consists of the intervals described by \lemref{interval-representation}, let $v_1,\ldots,v_m$ be a construction order for $H$, let $\varphi:V(H)\to\{1,\ldots,t+1\}$ be a proper colouring of $H$, and let $\varphi':V(H)\to\{1,\ldots,\lceil\log_{3/2} n\rceil\}\times\{1,\ldots,t+1\}$ be the extension of $\varphi$ to a proper colouring of $G_S$ described in \lemref{interval-representation}.

Let $X\subset\R$ be any set of points that stab $S$, let $T$ be a binary search tree with $V(T)=X$.
% , and let $\varphi:V(H)\to\{1,2,\ldots,\lfloor t\log n\rfloor\}$ be a proper colouring of the interval graph with vertex set $S$.
For each vertex $v:=[a_v,b_v]\in V(H)$, let $x_T(v)$ denote the lowest-common-ancestor of $X\cap [a_v,b_v]$ in $T$ (see \figref{x}).  For any subset $C\subseteq V(H)$, let $x_T(C):=\{x_T(x):x\in C\}$.  

\begin{figure}
  \begin{center}
    \includegraphics{figs/x}
  \end{center}
  \caption{The definition of $x_T(v)$.}
  \figlabel{x}
\end{figure}

\begin{lem}\lemlabel{one-path}
  For any $v\in V(H)$ with family clique $C_H(v)$, the set of nodes $x_T(C_H(v))$ are all contained a single root-to-leaf path in $T$.
\end{lem}

\begin{proof}
  Suppose for the sake of contradiction that this is not true, so there are $x_1,x_2\in x_T(C_H(v))$ neither of which is an ancestor of the other.  Then consider the lowest common ancestor $x$ of $x_1$ and $x_2$ in $T$.  Assume without loss of generality that $x_1$ is in the subtree of $T$ rooted at $x$'s left child and $v_2$ is in the subtree of $T$ rooted at $x$'s right child, so $x_1<x<x_2$. The node $x_1:=x_T(v_1)$ for some $v_1:=[a_1,b_1]\in C_H(v)$ and $x_2=x_T(v_2)$ for some $v_2:=[a_2,b_2]\in C_H(v)$.  Since $v_1$ and $v_2$ are both in the family clique $C_H(v)$, the edge $v_1v_2\in E(H)$, and therefore $[a_1,b_1]\cap[a_2,b_2]\neq\emptyset$.  This implies that $x\in [a_i,b_i]$ for at least one $i\in\{1,2\}$.  But this is a contradiction since $x_T(v_i)$ is supposed to be the lowest common ancestor of $[a_i,b_i]\cap X$.
\end{proof}

The following observation shows that a vertex $v$ of $H$ is uniquely identified by $x_T(v)$ and $\varphi'(v)$.

\begin{obs}\obslabel{unique-id}
    For any two distinct vertices $v,w\in V(H)$, $x_T(v)\neq x_T(w)$ or $\varphi'(v)\neq\varphi'(w)$.  Consequently, $\sigma_T(x_T(v))\neq \sigma_T(x_T(w))$ or $\varphi'(v)\neq\varphi'(w)$. 
\end{obs}

\begin{proof}
  If $x_T(v)=x_T(w)=x$, the intervals $v=[a_v,b_v]$ and $w=[a_w,b_w]$ each contain $x$, so $vw\in E(G_S)$.  Therefore $\varphi'(v)\neq\varphi'(w)$ since $\varphi'$ is a proper colouring of $G_S$.  The second, equivalent, statement of the observation is immediate from the fact that the $\sigma_T: V(T)\to\{0,1\}^*$ is injective, so $\sigma_T(x)$ uniquely identifies $x$.
\end{proof}

For each node $v\in V(H)$, let $\sigma_T(v)$ denote the path in $T$ that begins at the root of $T$ and ends at the node in $x_T(C_H(v))$ of maximum depth.  By \lemref{one-path}, $\sigma_T(v)$ contains every node in $x_T(C_H(v))$.
The label for a vertex $v\in V(H)$ consists of the following (we ignore any integers, such as $t$, $|\sigma_T(v)|$, and $\lceil\log_{3/2} m\rceil$, that can be encoded using \lemref{elias}):

\begin{enumerate}[(TC1)]
  \item $\sigma_T(v)$;
  \item $d_T(x_T(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; and
  \item $\varphi'(v)$.
\end{enumerate}

Given the labels of two vertices $v,w\in V(H)$, we test if $v$ and $w$ are adjacent as follows:
\begin{enumerate}[({A}1)]
  \item If the labels of $v$ and $w$ are identical then $v=w$, so return false.
  
  \item (uniquely identify $v$) From (TC4) extract $j:=\varphi(v)$ (which is contained in $\varphi'(v)$).  From (TC2) extract $d:=d_T(x_T(p_j(v)))$. Take the length-$d$ prefix of $\sigma_T(v)$ to get $\sigma_T(x_T(v))$.

  \item (check if $v$ is the $j$-parent of $w$) Extract $d:=d_T(x_T(p_j(w)))$ and take the length-$d$ prefix of $\sigma_T(w)$ to get $\sigma_T(x_T(p_j(w)))$.  If $\sigma_T(x_T(v))=\sigma_T(x_T(p_j(w)))$ then, by \obsref{unique-id}, $v$ is the $j$-parent of $w$ so $vw\in E(H)$, so return true.
  
  \item[(A4,A5)] Repeat (A2) and (A3) with the roles of $v$ and $w$ reversed.
  
  \item[(A6)] Return false
\end{enumerate}

The correctness of this procedure can be seen as follows:
\begin{itemize}
  \item Given the labels of $v$ and $w$ we can recover $\sigma_T(x_T(v))$, $\varphi'(v)$, $\sigma_T(x_T(w))$, and $\varphi'(w)$ so, by \obsref{unique-id}, the label of $v$ and the label of $w$ are identical if and only if $v=w$, so the negative result in (A1) is never incorrect;
  \item from \obsref{unique-id}, positive results in (A3) and (A5) are never incorrect; and 
  \item for every $vw\in E(H)$, there exists a $j\in\{1,\ldots,t+1\}$ such that $v$ is the $j$-parent of $w$ or $w$ is the $j$-parent of $v$, so the negative result in (A6) is never incorrect.    
\end{itemize}
In fact, this labelling scheme proves the slightly stronger result:

\begin{lem}\lemlabel{t-tree-labelling}
  Let $H$, $S$, $X$, and $T$ be defined as above.  There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=h(T) + O(t(\lg t + \lg h(T)))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
  \[
      \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{lem}

\begin{proof}
  Most of the details of this labelling are described above, though we have thus far ignored the length of the labels, which we analyze now.
  
  Part (TC1) of each label has length $|\sigma_T(v)|\le h(T)$.  For each $x\in V(T)$, $d_T(x)\le h(T)$, so Part~(TC2) of each label requires $O(t\lg h(T))$ bits.  Part~(TC3) of each label requires $O(t\log t + t\lg h(T))$ bits.  Part~(TC4) of each label requires $O(\log t + \lg h(T))$ bits.
\end{proof}

Taking $X$ to be a minimal set that stabs $S$ (so $|X|\le |S|=m$) and taking $T$ to be a perfectly balanced binary search tree (so $h(T)\le \log|X|\le\log m$) we obtain the following corollary.

\begin{cor}\corlabel{t-tree-labelling}
  There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that, for any $m$-vertex $t$-tree $H$ there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=\log m + O(t(\log t + \lg\lg m))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
  \[
      \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{cor}

\subsection{Interval Transition Labels}

We point out again that the result in \corref{t-tree-labelling} is not new and the labelling scheme is just a reformulation of the one given by Gavoille and Labourel \cite{gavoille.labourel:shorter} that happens to be convenient for what we are going to do next. Most important for us is that the largest part of the codes come from paths in the binary search tree $T$ that contains the stabbing set $X$.  

What we will do next is to show that the solution presented in \secref{pxp} generalizes to the current setting.  The only additional complication comes from the fact that each node $x$ in the binary search tree $T$ is equipped with a collection $B_x:=\{v\in V(H):x_T(v)=x\}$ of intervals.  Any structural changes that we make to $T$ may result in changes to $B_x$, which result in changes to the labels for the vertices of $H$ that enter or leave $B_x$.  We must show that these changes can be encoded using few bits.  We now proceed.

Let $G$ be an $n$-vertex subgraph of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,\ldots,h$ is a path. For each $y\in\{1,\ldots,h\}$, let $S_y=\{v\in V(H): (v,y)\in V(G)\}$ \snote{Consistency: $S_y$ was $L_y$ in \secref{pxp}} and let $S^-_y=\bigcup_{j=1}^{t+1}\{p_j(v):v\in S_y\}$.  Note that $|S^-_y|\le t|S_y|$. For each $y\in\{1,\ldots,t+1\}$, let $X_y\subset\R$ be the set of all endpoints of intervals in $S^-_y\cup S^-_{y-1}$.

By \lemref{chunked-bulk-trees} and \lemref{node-transitions} there is a bulk tree sequence $T_1,\ldots,T_h$ where, for each $y\in\{1,\ldots,h\}$, 
\begin{enumerate}[(PRX1)]
  \item $V(T_y)\supseteq X_y$;
  \item $h(T_y)\in \log |T_y| + o(\log n)$;
  \item $W:=\sum_{y=1}^h |T_y|\in O(n)$; and
  \item There is a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for every $x\in V(T_y)\cap V(T_{y+1})$, there is an $o(\log n)$-bit string $\nu_y(x)$ such that $B(\sigma_{T_y}(x),\nu_y(x))=\sigma_{T_{y+1}(x)}$.
\end{enumerate}

% As before, we can use \lemref{row-code} to assign each vertex $v=(x,y)\in V(G)$ a label $\alpha(v)$ of length $\log n - \log|T_y| + o(\log n)$. For any two nodes $v_1=(x_1,y_1)\in V(G)$ and $v_2=(x_2,y_2)$, $\alpha(v_1)$ and $\alpha(v_2)$ are sufficient to determine if $|y_1-y_2|\le 1$ and, if so, the actual value of $y_1-y_2$.
% 
% Now, for each $y\in\{1,\ldots,h\}$, $V(T_y)$ stabs $S^-_y\cup S^-_{y-1}$, so we can use $T_y$ to create a labelling scheme $\tau_y:(S^-_y\cup S^-_{y-1})\to\{0,1\}^*$ for the induced graph $H[S^-_y\cup S^-_{y-1}]$ as described in \secref{t-tree-labelling} leading to \lemref{t-tree-labelling} where the labels have length $h(T_y) + o(\log n)=\log|T_y|+o(\log n)$.  
% 
% For each $v\in S^-_y$, the label $\tau_y(v)$ has four parts (TC1)--(TC4).  Parts~(TC3) and (TC4) are completely determined by $H$ and $v$ and are independent of $T_y$.  In particular parts (TC3) and (TC4) of $\tau_{y_1}(v)$ and $\tau_{y_2}(v)$ are the same for any $y_1$ and $y_2$ such that $(v,y_1),(v,y_2)\in V(G)$.  
% 
% Part~(TC2) of $\tau_y(v)$, however depends very much on the tree $T_y$.  Luckily, Part~(TC2) is small: It has size $o(\log n)$, so the label of $(v,y)$ can include Part~(TC2) for $\tau_{y}(v)$ and $\tau_{y+1}(v)$.
% 
% The difficulty comes from Part~(TC1) of $\tau_y(v)$.


\begin{lem}\lemlabel{interval-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to \{0,1\}^*$ such that, for any 
  $H$, $G$, $L_1,\ldots,L_h$, $X_1,\ldots,X_h$, $T_1,\ldots,T_h$ defined as above, for each $y\in\{1,\ldots,h-1\}$ and each $v\in L_y\cup L_{y+1}$, there exists $\mu_y(v)\in\{0,1\}^*$, $|\mu_y(v)|\in O(k\lg\lg n)$ such that $B(\sigma_{T_y}(v), \mu_y(v))=\sigma_{T_{y+1}}(v)$.  \snote{We only need this for $v\in L_y$, right?}
\end{lem}

\begin{proof}
  For we note that, if $v\in L_y\cup L_{y+1}$, then the endpoints of $v$ are in $X_y\subseteq V_(T_y)$ and in $X_{y+1}\subseteq V(T_{y+1})$.
  Like the proof of \lemref{node-transitions}, we must dig into the three bulk tree operations that transform $T_y$ into $T_{y+1}$: rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion, which takes $T_y''$ onto $T_{y+1}$.
  
  The bulk insertion that converts $T_y'$ into $T_y''$ is the simplest to handle.  For any $v\in L_y$, $P_{T_y'}(v)$ is the path from the root of $T_y'$ to the deepest node in $x_{T_y'}(C_H(v))$.  Furthermore, for each $w\in C_H(v)$, $x_{T_y'}(v)$ is the element of $v\cap V(T_y')$ that is closest to the root fo $T_y'$. Since $T_y''$ is a supergraph of $T_y'$ obtained by adding small subtrees at the external nodes of $T_y'$, $x_{T_y''}(w)=x_{T_y'}(w)$ for each $w\in C_H(v)$.  Therefore $P_{T_y''}(w)=P_{T'}(w)$ and $\sigma_{T_y''}(w)=\sigma_{T'}(w)$ for each $w\in C_H(v)$, so $\sigma_{T_y''}(v)=\sigma_{T_y'}(v)$ for each $v\in L_y$.
  
  The bulk deletion that converts $T_y''$ to $T_{y+1}$ is also relatively simple.  A bulk deletion consists of a sequence if individual deletions. Consider one such deletion and let $T$ and $\tilde{T}$ denote the the tree before and after the deletion, respectively. We claim that, for any $v\in L_y$, $x_{\tilde{T}}(v)$ is an ancestor, in $T$, of $x_T(v)$. \snote{prove this now.}
  
  Done before, but now it's time to do it again.
\end{proof}
  
% This part, $\sigma_{T_y}(v)$, is determined by the path from the root of $T_y$ to the deepest node $z\in x_{T_y}(C_H(v))$.  When $T_y$ is restructured to become $T_{y+1}$, the path defining $\sigma_{T_y}(v)$ changes, the relative depths of nodes in $x_{T_y}(C_H(v))$ may change and even the value $x_{T_y}(w)$ may change for any $w\in V(H)$.  
% 
% We now examine the three operations that define how $T_y$ is transformed into $T_{y+1}$ to show how the effects of these operations on the labels of nodes in $S^-_y\cap S^-_{y+1}$ can be encoded succinctly.  For each $v\in S_y$, the changes to $\sigma_{T_y}(v)$ required to recover $\sigma_{T_{y+1}}(v)$ will be encoded in a string $\mu_y(v)$.
% 
% Recall that the three operations that transform $T_y$ into $T_{y+1}$ are (S1)~rebalancing, (S2)~bulk insertion and (S3)~bulk deletion. Rebalancing takes $T_y$ onto a tree $T_y'$. Bulk insertion takes $T_y'$ onto a tree $T_y''$.  Bulk deletion takes $T_y''$ onto $T_{y+1}$.
% 
% 
% \subsubsection{(S1): Rebalancing}
% 
% The rebalancing operation involves applying \lemref{multi-split} to all the subtrees of $T$ rooted at nodes of depth $(i-1)(k+1)$.  This, in turn, involves applying \lemref{split} to $2^k-1$ nodes so that they become roots of specific subtrees.
% 
% For a binary tree $T$ and a node $z\in V(T)$, let $P_T(z)$ denote the path from the root of $T$ to $z$.  We begin with a simple observation about the restructing operation in \lemref{split}.
% 
% \begin{obs}\obslabel{x-switch}
%   Let $T$ be a binary search tree, let $S$ be a set of intervals, and let $T'$ be the result of applying \lemref{split} to $T$ to make some node $x'\in V(T)$ become the root.  Then, for each $v\in S$, $x_{T'}(v)\in\{x_T(v), x'\}$.
% \end{obs}
% 
% \begin{proof}
%   Consider any node $z\in V(T)$ and without loss of generality, assume $z>x'$. 
%   If $x'$ is not in the subtree of $T$ rooted at $z$, then $P_T(z)=P_{T'}(z)$.  If $x'$ is in the subtree of $T$ rooted at $z$, then $P_T(z)$ is obtained by deleting all values less than $x'$ from $P_T(z)$ and (possibly) inserting $x'$.
% 
%   Now, consider any $v=[a,b]\in S$ and let $x:=x_T(v)$. By definition, $x$ is is the only node in $P_T(x)$ contained in $[a,b]$. Therefore, the only nodes of $P_{T'}(x)$ contained in $[a,b]$ are $x$ and (possibly) $x'$.  Therefore $x_{T'}(v)\in \{x,x'\}$.
% \end{proof}
% 
% For any $v\in S^-_{y}\cap S^-_{y+1}$, and any $y\in\{1,\ldots,h\}$, let $P_{T_y}(v)=x_0,\ldots,x_r$ be the path from the root of $T_y$ to the deepest node in $x_{T_y}(C_H(v))$.  In other words, $\sigma_{T_y}(v)=\sigma_{T_y}(x_r)$ and $x_r=x_{T_y}(w)$ for some $w\in C_H(v)$.
% 
% A rebalancing operation applies \lemref{multi-split} to each subtree of $T_y$ rooted at a node of depth $(i-1)(k+1)$.  Refer to \figref{rebalance-t-tree}. At most one of these subtrees contains nodes from $P_{T_y}(v)$. We first establish that none of the other application of \lemref{multi-split} has any effect on $\sigma_{T_y}(v)$.  Let $T_y^0$ be the result of applying \lemref{multi-split} to every subtree rooted at a depth $(i-1)(k+1)$ node that does not contain any nodes of $P_{T_y}(v)$.  By \obsref{x-switch}, $x_{T_y}(u)=x_{T_y^0}(u)$ for all $u\in C_H(v)$.  The path $P_{T_y}(v)=x_0,\ldots,x_r$ is also a path in $T_y^0$ and this is the path in $T_y^0$ from the root to the deepest node in $x_{T_y^0}(C_H(v))$. So, by definition, $P_{T_y}(v)=P_{T_y^0}(v)$.
% 
% \begin{figure}
%   \begin{center}
%     \includegraphics{figs/rebalance-t-tree}
%   \end{center}
%   \caption{Applying \lemref{multi-split} to each of the depth-$(i-1)(k+1)$ subtrees of $T_y$ except $T_*$ has no effect on $P_{T_y}(v)$.}
%   \figlabel{rebalance-t-tree}
% \end{figure}
% 
% Let $T_y'$ be the result of applying \lemref{multi-split} to the subtree $T_*$ of $T_y^0$ that contains some nodes of $P_{T_y}(v)=P_{T_y^0}(v)=x_0,\ldots,x_r$ and let $T_*'$ denote the result of applying \lemref{multi-split} to $T_*$.
% The subtree $T_*$ contains some suffix $x_i,\ldots,x_r$ of $x_0,\ldots,x_r$.  By definition $x_r=x_{T_y}(w)$ for some $w=[a_w,b_w]\in C_H(v)$.  Since the only restructuring done by \lemref{multi-split} is done by applications of \lemref{split} to subtrees contained in $T_*$,  \obsref{x-switch} implies that $x_{T_y'}(w)\in V(T_*)$.  Therefore $P_{T_y'}=x_0,\ldots,x_{(i-1)(k-1)-1},x'_0,\ldots,x'_{s}$ where $x_0',\ldots,x'_s$ is a path in $T_*'$. By including the integer $(i-1)(k+1)$ in $\mu_y(v)$, we can therefore focus on encoding the differences between $\sigma_{T_*}(x_r)$ and $\sigma_{T_*'}(x'_s)$.
% 
% To simplify notation, we now assume that $T^*=T_y$, so that the one application of \lemref{multi-split} that affects $P_{T_y}(v)$ is at the root of $T_y$.
% This application of \lemref{multi-split} involves several applications of \lemref{split}.  Consider the first application of \lemref{split}, that takes some node $x'$ in $T_y$ and moves it to the root, creating a new tree $T_y^1$.
% 
% By \obsref{x-switch} $x_{T_y^1}(w)\in\{x',x_{T_y^1}(w)\}$ for every $w\in C_H(v)$.  If $x_{T_y^1}(w)=x'$ for every $w\in C_H(v)$, then $P_{T_y^1}(v)=x'$ is a path of length 0.  This can be recorded by adding $O(1)$ bits to $\mu_y(v)$. Otherwise, there is a non-empty subset $W\subset C_H(v)$ such that $x_{T_y^1}(w)=x_{T_y}(w)$ for each $w\in W$.  Let $w^*\in W$ be an element that maximizes $d_{T_y}(w^*)$.  We claim that $w^*$ also maximizes $d_{T_y^1}(w^*)$.  Indeed, as noted already in the proof of \obsref{x-switch} $P_{T_y^1}(w^*)$ consists of $x'$ followed by a subsequence of $P_{T_y}(w^*)$ that includes every node in $W$.  Therefore, $P_{T_y^1}(w^*)$ contains every node of $W$ and ends at $w^*$.  Therefore $d_T(w^*)\ge d_T(w)$ for all $w\in W$.
% 
% Therefore $P_{T_y^1}(v)=P_{T_y^1}(w^*)$.  Now $w^*$ appear in $P_{T_y}(v)$, so $\sigma_{T_y}(w^*)$ can be recovered from $\sigma_{T_y}(v)$ and $d_{T_y}(w^*)$, so the $O(\lg\lg n)$ bits required to encode $d_{T_y}(w^*)$ are included in $\mu_y(v)$.  Furthermore, as shown in \lemref{split}, $\sigma_{T_y^1}(w^*)=\sigma_{T_y^1}(v)$ can be recovered from $\sigma_{T_y}(w^*)$ and an additional $O(\lg\lg n)$ bits that are included in $\mu_y(v)$.  In this way, we can recover $\sigma_{T_y^1}(v)=\sigma_{T_y^1}(w^*)$ with the addition of only $O(\lg\lg n)$ bits to $\mu_y(v)$.
% 
% Now \lemref{multi-split} involves $2^k-1$ applications of \lemref{split} resulting in intermediate trees $T_y^1,\ldots,T_y^{2^k-1}=T_y'$.  However, these applications are partitioned into $k$ sets $R_0,\ldots,R_{k-1}$, where the applications of \lemref{multi-split} in $R_i$ operate on $2^i$ disjoint subtrees rooted at nodes of depth $i$.  In particular, only one subtree in each set $R_i$ contains any nodes from $P_{T}(v)$.  Each of these applications adds $O(\lg\lg n)$ bits to $\mu_y(v)$ for a total of $O(k\lg\lg n)$ bits.
% 
% Therefore, $\mu_y(v)$ contains a sequence of $O(k\lg\lg n)$ bits, that makes it possible to recover $\sigma_{T_y'}(v)$ from $\sigma_{T_y}(v)$ for every $v\in S_y$.
% 
% \subsubsection{(S2): bulk Insertions}
% 
% During the bulk insertion phase, elements in $I_y:=X_{y+1}\setminus X_y$ are added to $T_y'$ to create the new tree $T_{y}''$.  The newly added elements are added to small complete binary search trees that are attached to existing nodes of $T_{y}'$.  This ensures that, in $T_y''$, no vertex of $T_y$ has any ancestor in $I_y$.  This in turn ensures that $x_{T_y''}(v)=x_{T_y'}(v)$ for every $v\in S_y$.  
% 
% Now, for every $v\in S_y$, $C_H(v)\subseteq S^-_y$, so $P_{T_y'}(v)$ is well-defined.  Since $T_y''$ is a supergraph of $T_y'$ and $x_{T_y''}(w)=x_{T_y'}(w)$ for each $w\in C_H(v)$, $P_{T_y''}(v)=P_{T_y'}(v)$ and therefore $\sigma_{T_y''}(v)=\sigma_{T_y'}(v)$ for every $v\in S_y$.
% 
% \subsubsection{(S3): bulk Deletions}
% 
% Each individual deletion either involves removing a leaf from $T_y''$ or it involves (possibly repeatedly) replacing some value $x$ with some value $x'$ that either the smallest value in $x$'s right subtree or the largest value in $x$'s left subtree.
% 
% Let $v=[a_v,b_v]\in S_y\cap S^-_y$.  Recall that, by definition, $a_v$ and $b_v$ are both contained in $X_y$ and in $X_{y+1}$.  Refer to interval $v_1$ in \figref{deletion-t-tree}.  If $x_{T_y''}(v)=x$, then $x\in[a_v,b_v]$ and, since $a_v,b_v\in X_{y}$, $x'\in[a_v,b_v]$.  Therefore, if $x_{T''}(v)=x$ then, after removing $x$ and replacing it with $x'$, $x_{T''}(v)=x'$.  
% 
% The only other possible change of this type occurs when this replacement operation causes $x'$ to become an ancestor of some node $x''$ that it wasn't before.  See vertex $v_2$ in \figref{deletion-t-tree}.  In this case, some $v\in S_y$ with $x_{T_y''}(v)=x''$ before the replacement will have $x_{T_y''}(v)=x'$ after the replacement.
% 
% \begin{figure}
%   \begin{center}
%     \includegraphics{figs/deletion-t-tree-1} \\[1ex]
%     $\Downarrow$ \\[1ex]
%     \includegraphics{figs/deletion-t-tree-2}
%   \end{center}
%   \caption{A deletion in $T''_y$ can only remove a suffix from $\sigma_{T''_y}(x_{T''_y}(v))$.}
%   \figlabel{deletion-t-tree}
% \end{figure}
% 
% In either of the preceding cases replacing $x$ with $x'$ has the effect of removing a (possibly empty) suffix from $\sigma_T(x_{T_y''}(v))$.  Therefore, the net effect of any number of these operations is to remove a (possibly empty) suffix from $\sigma_{T_y''}(v)$.  Therefore, the effect of all these operations on $\sigma_T(v)$ can be represented including one integer in the range $\{0,\ldots,h(T_y'')\}$ in $\mu_y(v)$.  This adds only $O(\lg\lg n)$ bits to $\mu_y(v)$.
% 
% In summary, for each $v\in S_y$, there is a bitstring $\mu_y(v)$ of length $O(k\lg\lg n)$ that allows us to compute $\sigma_{T_{y+1}}(v)$ from $\sigma_{T_y}(v)$.


\subsection{The Labels}

Summarizing, for any $n$-vertex subgraph $G$ of $H\boxtimes P$, each vertex $z=(v,y)\in V(G)$ has a label that contains the following information:

\begin{enumerate}[(PC1)]
  \item $\alpha(y)$; % of length $\log n-\log|T_y| + O(\lg\lg n)$;
  \item $\sigma_{T_y}(v)$; % of length $\log|T_y| + O(k+k^{-1}\log n)$;
  \item $d_{T_{y+b}}(x_{T_{y+b}}(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$ and $b\in\{-1,0,1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$;
  \item $\varphi'(v)$;
  \item $\mu_y(v)$;
  \item $a(z)$.
\end{enumerate}
The only one of these quantities not yet defined is $a(z)$, which is a sequence of $3t$ bits that indicate which of the potential edges joining $z$ to elements of $\{(p_j(v),y+b): j\in\{1,\ldots,t+1\},\, b\in\{-1,0,1\}\}$ are actually present in $G$.

\subsection{Adjacency Testing}
Given the labels of $z_1:=(v_1,y_1)$ and $z_2:=(v_2,y_2)$ we test if $z_1z_2\in E(G)$ by first using $\alpha(y_1)$ and $\alpha(y_2)$ to determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|>1$: In this case $y_1\neq y_2$ and $y_1y_2\not\in P$, so $z_1z_2\not\in E(H\boxtimes P)$, so $z_1z_2\not\in E(G)$.

  \item $y_1=y_2$.  Let $y=y_1=y_2$.  In this case (PC2)--(PC4) contains $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ and we use this to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ also tell us that (without loss of generality) $x_1$ is the $j$-parent of $x_2$ in $H$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=1$: Let $y=y_1$ (so that $y_2=y+1$).  We use $\mu_y(v_1)$ and $\sigma_{T_y}(v_1)$ to compute $\sigma_{T_{y+1}}(v_1)$.  Now, $\sigma_{T_{y+1}}(v_1)$ and (PC3)--(PC4) contains $\tau_{y+1}(v_1)$ and (PC2)--(PC4) contains $\tau_{y+1}(v_2)$.  We use these to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y+1}(v_1)$ and $\tau_{y+1}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=-1$:  This case is symmetric to the preceding case, with the roles of $z_1$ and $z_2$ reversed.
\end{enumerate}

This completes the proof of our main result.

\begin{thm}\thmlabel{main}
  For every $t\in\N$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some $t$-tree $H$ and some path $P$ has a $(\log n + O(\sqrt{\log n\lg\lg n}+t(\log t + \lg\lg n)))$-bit adjacency labelling scheme.
\end{thm}
% 
% 
%   For every $t\in\N$ and every $t$-tree $H$ and every path $P$, the family of subgraphs of $H\boxtimes P$ has a 
% 
% 
% 
%    subgraphs 
%   There exists an 
%   There exists a function $\mathds{A}:(\{0,1\}^*)^2\to\{0,1\}$ such that for every $t$-tree $H$, every path $P$, and every $n$-vertex subgraph $G$ of $H\boxtimes P$, there is a prefix-free code $\eta:V(G)\to\{0,1\}^*$ such that
%   $|\eta(v)|=\log n + O(\sqrt{\log n\lg\lg n}+t(\log t + \lg\lg n))$ for every $v\in V(G)$ and, for every $v,w\in V(G)$, 
%   \[  \mathds{A}(\eta(v),\eta(w)) = \begin{cases}
%         1 & \text{if $vw\in E(G)$} \\
%         0 & \text{if $vw\not\in E(G)$}
%       \end{cases}
%       \]
% \end{thm}

\section{Conclusion}
\seclabel{conclusion}

Given an $n$-vertex planar graph $G$, finding an 8-tree $H$, a path $P$, and a mapping of $G$ into a subgraph of $H\boxtimes P$ can be done in $O(n^2)$ time \cite{dujmovic.joret.ea:planar}.  The process of computing the labels of $V(G)$ as described in \secref{pxp} and \secref{hxp} is has a straightforward $O(n\log n)$ time implementation.  Thus, the adjacency labels described in \thmref{main} are computable in $O(n^2)$ time for $n$-vertex planar graphs.

The adjacency testing function $\mathds{A}$ is quite simple. Even without using word parallelism, this function is straightforward to implement in $O(tk\log n)$ time.  In the case of planar graphs $t=8$ and $k=O(\sqrt{\log n\lg\lg n})$, so the adjacency testing procedure can be implemented in $O(\log n\sqrt{\log n\lg\lg n})$ time.\snote{If we want to bother, we could probably do this in $O(\log n)$ time.}

\section*{Acknowledgement}

Part of this research was conducted during the Eighth Workshop on Geometry and Graphs, held at the Bellairs Research Institute, January~31--February~7, 2020.  We are grateful to the organizers and participants for providing a stimulating research environment.

  
\bibliographystyle{plainurl}
\bibliography{labelling}


\appendix

\section{Proof of \lemref{fractional}}
\applabel{fractional-proof}


\begin{proof}[Proof of \lemref{fractional}]
  We construct $V_1,\ldots,V_{h}$ incrementally using a recursive subroutine called $\textsc{Add}(x, y)$ using the following procedure:
  
  \noindent$\textsc{BuildV}(S_1,\ldots,S_h)$:
  \begin{algorithmic}[1]
    \STATE{$V_0\gets V_{h+1}\gets\Z$}
    \STATE{$V_y\gets\{0\}$ for each $y\in\{1,\ldots,h\}$}
    \FOR{$x= 1,\ldots,m$}
      \FOR{$y = 1,\ldots,h$}
        \IF{$x\in S_y\setminus V_y$}
          \STATE{$\mathrm{add}(x, y)$}
        \ENDIF
      \ENDFOR
    \ENDFOR
    \STATE{$V_y\gets V_y\setminus \{0\}$ for each $y\in\{1,\ldots,h\}$}
  \end{algorithmic}
  
  \noindent$\textsc{Add}(x, y)$:
  \begin{algorithmic}[1]
    \IF{$y\in\{1,\ldots,h\}$}
      \STATE{$V_y\gets V_y\cup\{x\}$}
      \IF{$|V_y|\ge 5$}      
        \STATE{let $x_{-1}>x_{-2}>\cdots>x_{-5}$ be the 5 largest elements in $V_y$ (so $x_{-1}=x$)}
        \IF{$\{x_{-1},\ldots,x_{-4}\}\cap V_{y-1}=\emptyset$ or
            $\{x_{-1},\ldots,x_{-4}\}\cap V_{y+1}=\emptyset$}
            \STATE{$\textsc{Add}(x,y-1)$}
            \STATE{$\textsc{Add}(x,y+1)$}
        \ENDIF
      \ENDIF
    \ENDIF
  \end{algorithmic}
  
  It is easiest to think of the sets $V_y$ as sequences, sorted in increasing order, so that Line~2 in $\textsc{Add}(x,y)$ appends $x$ to $V_y$.
  
  That the procedure produces sets $V_1,\ldots,V_h$ such that $V_y\supseteq S_y$ for each $y\in\{1,\ldots,h\}$ is obvious.  So the resulting sets $V_1,\ldots,V_h$ satisfy the first condition of the lemma.
  
  The prove that $V_1,\ldots,V_h$ satisfy the second condition, we establish the loop invariant that, outside of $\textsc{Add}(x,y)$, $V_{y-1}$ and $V_{y+1}$ each 3-chunk  $V_y$ for each $y\in\{1,\ldots,h\}$.  Indeed, the only instant at which $V_{y-1}$ fails to 3-chunk $V_y$ is immediately after appending some value $x$ to $V_y$ in Line~2 of $\textsc{Add}(x,y)$.  If this occurs, it is immediately detected in Lines~3--5 and corrected in Line~6.  Similarly, if $V_{y+1}$ fails to $3$-chunk $V_y$ then this is immediately detected and corrected in Line~7.
  
  Finally, we need to argue that $V_1,\ldots,V_h$ satisfy the third condition.  In particular, we must show that $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|\le 4n$.

  We do this with a credit scheme that maintains the following invariant  during the execution of the algorithm:  For each $V_y$, let $c_y$ be the length the longest suffix $x_{-k},\ldots,x_{-1}$ of $V_y$ that does not intersect $V_{y-1}$ or does not intersect $V_{y+1}$.  Except during the execution of $\textsc{Add}(x,y)$, $c_y\le 3$, since $V_{y-1}$ and $V_{y+1}$ each 3-chunk $V_y$.  We maintain the invariant that $V_{y}$ stores $c_y$ credits at all times.  When we append to the list $V_y$ in Line~2 of $\textsc{Add}(x,y)$ we will pay with one credit that is spent and can never be used again.
  
  To maintain our credit invariant, we will create 2 credits each time $\textsc{BuildV}$ calls $\textsc{Add}(x,y)$ in Line~6.  Line~6 executes at most once for each of the original $2n$ values in $S_1,\ldots,S_h$.  Therefore Line~6 executes at most $2n$ times and at most $4n$ credits are created.  Since each execution of Line~2 in $\textsc{Add}(x,y)$ takes away one credit, this means that the total number of times we append to lists in $V_1,\ldots,V_h$ is at most $4n$.
  Therefore, $\sum_{y=1}^h |V_y|\le 4n$.
   
  To manage these credits, we will pass two credits into each invocation of $\textsc{Add}(x,y)$, including the recursive invocations.  For the invocations of $\textsc{Add}(x,y)$ in Line~6 of \textsc{BuildV}, the two credits passed in are the two newly-created credits.
  
  When $\textsc{Add}(x,y)$ executes, one of the two credits passed to itis used to pay for the execution of Line~2, and this credit disappears forever, leaving one extra credit that we add to $V_y$ since the newly-added value $x\in V_y$ may have increased $c_y$ by 1. Thus far the credit invariant is maintained.  
  
  If no further recursive invocation of $\textsc{Add}(x,y)$ are made, then there is nothing further to do, so we consider the case where the two recursive invocations in Lines~6 and 7 are made.  In this case, $c_y=4$ before these recursive invocations are made.  Afterwards, $c_y=0$ since these invocations add $x$ to $V_{y-1}$ and $V_{y+1}$.  This frees 4 credits.  We pass 2 of these free credits into the recursive invocation of $\textsc{Add}(x,y-1)$ and the other 2 free credits into the recursive invocation of $\textsc{Add}(x,y+1)$. 
\end{proof}

\end{document}
