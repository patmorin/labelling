\documentclass[kpfonts]{patmorin}
\listfiles
\usepackage{pat}
\usepackage{paralist}
\usepackage{dsfont}  % for \mathds{A}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}
\usepackage[noend]{algorithmic}

\usepackage{xcolor}
\definecolor{light-gray}{gray}{0.95}

\usepackage[normalem]{ulem}
\usepackage{cancel}

\newcommand{\snote}[1]{\fcolorbox{red}{yellow}{#1}}
\newcommand{\pnote}[1]{\ \newline\noindent\fcolorbox{red}{yellow}{\begin{minipage}{\textwidth}#1\end{minipage}}}
\setlength{\parskip}{1ex}

\DeclareMathOperator{\A}{\mathds{A}}
\DeclareMathOperator{\sn}{sn}
\DeclareMathOperator{\qn}{qn}

\renewcommand{\SS}{\mathcal{S}}

%Piotreks overloads
\let\le\leqslant
\let\ge\geqslant
\let\leq\leqslant
\let\geq\geqslant
\let\nleq\nleqslant
\let\ngeq\ngeqslant
%%Piotrek end

\newcommand{\aref}[1]{(X\ref{a:#1})}
\newcommand{\alabel}[1]{\label{a:#1}}

\title{\MakeUppercase{Adjacency Labelling for Planar Graphs}}
\author{
  Vida Dujmović,%
    \thanks{School of Computer Science and Electrical Engineering, University of Ottawa, Canada. This research was partially supported by NSERC.}\quad
  Louis Esperet,%
    \thanks{Laboratoire G-SCOP (CNRS, Univ.\ Grenoble Alpes), Grenoble, France. Partially supported by the French ANR Projects ANR-16-CE40-0009-01 (GATO) and ANR-18-CE40-0032 (GrR).}\quad
  Cyril Gavoille,%
    \thanks{LaBRI, University of Bordeaux, France. This research was partially supported by the French ANR projects ANR-16-CE40-0023 (DESCARTES) and ANR-17-CE40-0015 (DISTANCIA).}\quad
  Gwenaël Joret,%
     \thanks{Département d'Informatique, Université Libre de Bruxelles, Brussels, Belgium. Research supported by an ARC grant from the Wallonia-Brussels Federation of Belgium and by a grant from the National Fund for Scientific Research (FNRS).}\quad
  Piotr Micek,%
    \thanks{Theoretical Computer Science Department, Faculty of Mathematics and Computer Science, Jagiellonian University, Krak\'{o}w, Poland. This research was partially supported by the Polish National Science Center grant (BEETHOVEN; UMO-2018/31/G/ST1/03718).}\newline
  and Pat Morin%
    \thanks{School of Computer Science, Carleton University, Canada. This research was partially supported by NSERC.}
}
\date{}

\begin{document}
\begin{titlepage}
\maketitle

\begin{abstract}
  We show that there exists an adjacency labelling scheme for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log_2 n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  This is optimal up to the lower order term and is the first such asymptotically optimal result.  An alternative, but equivalent, interpretation of this result is that, for every $n$, there exists a graph $U_n$ with $n^{1+o(1)}$ vertices such that every $n$-vertex planar graph is an induced subgraph of $U_n$. 
\end{abstract}
\end{titlepage}
\pagenumbering{roman}
\tableofcontents

\newpage

\setcounter{page}{0}
\pagenumbering{arabic}
\section{Introduction}

%G: I moved this to Section 2
% In this paper, which is concerned with binary encodings, $\log x:=\log_2 x$ denotes the binary logarithm of $x$ and, for convenience, $\log x := \log\max\{1,x\}$.  All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The \emph{size} of a graph $G$ is denoted by $|G|:=|V(G)|$.

A family $\mathcal{G}$ of graphs has an \emph{$f(n)$-bit adjacency labelling scheme} if there exists a function $A:(\{0,1\}^*)^2\to \{0,1\}$ such that for every $n$-vertex graph $G\in \mathcal{G}$ there exists $\ell:V(G)\to\{0,1\}^*$ such that $|\ell(v)|\le f(n)$ for each vertex $v$ of $G$ and such that, for every two vertices $v,w$ of $G$,
\[  A(\ell(v),\ell(w)) = 
      \begin{cases} 
        0 & \text{if $vw\not\in E(G)$;} \\
        1 & \text{if $vw\in E(G)$.}
      \end{cases}
\]

Let $\log x:=\log_2 x$ denote the binary logarithm of $x$. 
In this paper we prove the following result:
\begin{thm}\thmlabel{main}
  The family of planar graphs has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

% We show that there exists an \emph{adjacency labelling scheme} for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  

\thmref{main} is optimal up to the lower order term.  An alternative, but equivalent, interpretation of \thmref{main} is that, for every integer $n\ge 1$, there exists a graph $U_n$ with $n^{1+o(1)}$  vertices such that every $n$-vertex planar graph is isomorphic to some vertex-induced subgraph of $U_n$.\footnote{There is a small technicality that the equivalence between adjacency labelling schemes and universal graphs requires that $\ell:V(G)\to\{0,1\}^*$ be injective.  The labelling schemes we discuss satisfy this requirement.  For more details about the connection between labelling schemes and universal graphs, the reader is directed to Spinrad's monograph \cite[Section~2.1]{spinrad:efficient}.} 

\subsection{Previous Work}

The current paper is the latest in a series of results dating back to Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit0,kannan.naor.ea:implicit} and Muller \cite{muller:local} who defined adjacency labelling schemes\footnote{There are some small technical differences between the two definitions that have to do with the complexity of computing $\ell(\cdot)$ as a function of $G$ and
$A(\cdot,\cdot)$.} and described $O(\log n)$-bit adjacency labelling schemes for several classes of graphs, including planar graphs.  Since this initial work, adjacency labelling schemes and, more generally, informative labelling schemes have remained a very active area of research \cite{adjiashvili.rotbart:labeling,alstrup.kaplan.ea:adjacency,abrahamsen.alstrup.ea:near-optimal,alstrup.dahlgaard.ea:sublinear,alstrup.gortz.ea:distance,alstrup.gavoille.ea:simpler,alstrup.rauhe:improved}. 

Here we review results most relevant to the current work, namely results on planar graphs and their supporting results on trees and bounded-treewidth graphs.  First, a superficial review: Planar graphs have been shown to have $(c+o(1))\log n$-bit adjacency labelling schemes for successive values of $c=6,4,3,2,\tfrac{4}{3}$ and finally \thmref{main} gives the optimal\footnote{It is easy to see that, in any adjacency labelling scheme for any $n$-vertex graph $G$ in which no two vertices have the same neighbourhood, all labels must be distinct, so some label must have length at least $\lceil\log n\rceil$.} result $c=1$.  We now give details of these results.

Muller's scheme for planar graphs \cite{muller:local} is based on the fact that planar graphs are 5-degenerate.  This scheme orients the edges of the graph so that each vertex has 5 outgoing edges, assigns each vertex $v$ an arbitrary $\lceil\log n\rceil$-bit identifier, and assigns a label to $v$ consisting of $v$'s identifier and the identifiers of the targets of $v$'s outgoing edges.  In this way, each vertex $v$ is assigned a label of length at most $6\lceil\log n\rceil$.  Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit} use the fact that planar graphs have arboricity 3 (so their edges can be partitioned into three forests \cite{nash-williams:edge-disjoint}) to devise an adjacency labelling scheme for planar graphs whose labels have length at most $4\lceil\log n\rceil$.  

A number of $(1+o(1))\log n$-bit adjacency labelling schemes for forests have been devised \cite{chung:universal, alstrup.rauhe:improved,alstrup.dahlgaard.ea:optimal}, culminating with a recent $(\log n + O(1))$-bit adjacency labelling scheme \cite{alstrup.dahlgaard.ea:optimal} for forests.  Combined with the fact that planar graphs have arboricity 3, these schemes imply $(3+o(1))\log n$-bit adjacency labelling schemes for planar graphs.  
%Schnyder's representation of planar graphs in terms of dimension-3 posets \cite{schnyder:planar} also implies a $3\lceil\log n\rceil$-bit labelling scheme for planar graphs. \snote{Piotrek: Really?}

A further improvement, also based on the idea of partitioning the edges of a planar graph into simpler graphs was obtained by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  Generalizing the results for forests, they describe a $(1+o(1))\log n$-bit adjacency labelling scheme for $n$-vertex graphs of bounded treewidth. As is well known, the edges of a planar graph can be partitioned into two sets, each of which induces a bounded treewidth graph. 
%\pnote{Actually for a planar graphs, there's a really short proof using layering: Even layers plus edges to the previous layer has bounded treewidth. Same for odd layers.} 
This results in a $(2+o(1))\log n$-bit adjacency labelling scheme for planar graphs.

Very recently, Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter} described a $(4/3+o(1))\log n$-bit adjacency labelling scheme for planar graphs based on a recent \emph{graph product structure theorem} of Dujmović \etal\ \cite{dujmovic.joret.ea:planar}.  This product structure theorem states that any planar graph is a subgraph of a strong product $H\boxtimes P$ where $H$ is a bounded-treewidth graph and $P$ is a path. See \figref{product}. It is helpful to think of $H\boxtimes P$ as a graph whose vertices can be partitioned into $h:=|V(P)|$ \emph{rows} $H_1,\ldots,H_{h}$, each of which induces a copy of $H$ and with vertical and diagonal edges joining corresponding and adjacent vertices between consecutive rows.  
% We now quickly sketch the construction of Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter}.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics{figs/product}
  \end{center}
  \caption{The strong product $H\boxtimes P$ of a tree $H$ and a path $P$.}
  \figlabel{product}
\end{figure}  
% In the following two paragraphs we omit $o(\log n)$ terms.

The product structure theorem quickly leads to a $(1+o(1))\log(mh)$-bit labelling scheme where $m:=|V(H)|$ and $h:=|V(P)|$ by using a $(1+o(1))\log m$-bit labelling scheme for $H$ (a bounded treewidth graph) and a $(1+o(1))\log h$-labelling scheme for $P$ (a path).  However, in the worst case $m$ and $h$ are each $\Omega(n)$, so this offers no immediate improvement over the existing $(2+o(1))\log n$-bit scheme.

Bonamy, Gavoille, and Pilipczuk improve upon this by cutting $P$ (and hence $G$) into subpaths of length $n^{1/3}$ in such a way that this corresponds to removing $O(n^{2/3})$ vertices of $G$ that have a neighbourhood of size $O(n^{2/3})$. The resulting (cut) graph is a subgraph of $H'\boxtimes P'$ where $H'$ has bounded treewidth, $|H'|\le n$, and $P'$ is a path of length $n^{1/3}$ so it has a labelling scheme in which each vertex has a label of length $(1+o(1))\log (|H'|\cdot|P'|) \le (4/3+o(1))\log n$.  A slight modification of this scheme allows for the $O(n^{2/3})$ \emph{boundary} vertices adjacent to the cuts to have shorter labels, of length only $(2/3+o(1))\log n$.  The cut vertices and the boundary vertices induce a bounded-treewidth graph of size $O(n^{2/3})$.  The vertices in this graph receive secondary labels of length $(2/3+o(1))\log n$.  In this way, every vertex receives a label of length at most $(4/3 + o(1))\log n$.

\subsection{The New Result}

The adjacency labelling scheme described in the current paper is also based on the product structure theorem for planar graphs, but it avoids cutting the path $P$, and thus avoids boundary vertices that take part in two different labelling schemes.  Instead, it uses a weighted labelling scheme on the rows $H_1,\ldots,H_h$ of $H\boxtimes P$ in which vertices that belong to $H_i$ receive a label of length $(1+o(1))\log n-\log W_i$ where $W_i$ is related to the number of vertices of $G$ contained in $H_i$ and $H_{i-1}$.  The vertices of $G$ in row $i$ participate in a secondary labelling scheme for the subgraph of $G$ contained in $H_i$ and $H_{i-1}$ and the labels in this scheme have length $\log W_i + o(\log n)$. Thus every vertex receives two labels, one of length $(1+o(1))\log n-\log W_i$ and another of length $\log W_i + o(\log n)$ for a total label length of $(1+o(1))\log n$.  

The key new technique that allows all of this to work is that the labelling schemes of the rows $H_1,\ldots,H_h$ are not independent.  All of these labelling schemes are based on a single balanced binary search tree $T$ that undergoes insertions and deletions resulting in a sequence of related binary search trees $T_1,\ldots,T_h$ where each $T_i$ contains all vertices of $G$ in $H_{i}$ and $H_{i-1}$ and the label assigned to a vertex of $H_i$ is essentially based on a path from the root of $T_i$ to some vertex of $T_i$.  By carefully maintaining the binary search tree $T$, the trees $T_{i-1}$ and $T_{i}$ can be similar enough so that the label for $v$ in $H_i$ can be obtained, with $o(\log n)$ additional bits from the label for $v$ in $H_{i-1}$.

The product structure theorem has been generalized to a number of additional graph families including bounded-genus graphs, apex-minor free graphs, $k$-planar graphs, powers of bounded-degree bounded genus graphs, and $k$-nearest neighbour graphs of points in $\R^2$ \cite{dujmovic.joret.ea:planar,dujmovic.morin.ea:structure}. As a side-effect of designing a labelling scheme to work directly on subgraphs of a strong product $H\boxtimes P$, where $H$ has bounded treewidth and $P$ is a path, 
we obtain $(1+o(1))\log n$-bit labelling schemes for all of these graph families.  All of these results are optimal up to the lower order term.

\subsection{Outline}

The remainder of the paper is organized as follows. \Secref{preliminaries} reviews some preliminary definitions and easy results.  \Secref{bulk-trees} describes a new type of balanced binary search tree that has the specific properties needed for our application. \Secref{pxp} solves a special case, where $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1$ and $P_2$ are both paths. We include it to highlight the generic idea behind our adjacency labelling scheme. \Secref{hxp} solves the general case in which $G$ is an $n$-vertex subgraph of $H\boxtimes P$ where $H$ has bounded treewidth and $P$ is a path.  \Secref{conclusion} concludes with a discussion of the computational complexity of assigning labels and testing adjacency and presents directions for future work.

% \subsection{Proof Overview}
% 
% Like Bonamy \etal\ \cite{bonamy.gavoille.ea:shorter}.  Our starting point is a recent result that characterizes planar graphs in terms of the strong product of two simpler graphs.  The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
% \begin{enumerate}
%   \item  $v_1\neq v_2$; and
%   \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
%   \item $y_1=y_2$ or $y_1y_2\in E(B)$.
% \end{enumerate}
% 
% \begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]
%   Every planar graph $G$ is the subgraph of a strong product $G^+:=H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
% \end{thm}
% 
% \ldots

% \snote{TODO: Gwen and Piotr's comments.}

% For graph products like $G^+$, there is a natural labelling scheme: Computer a labelling scheme $\alpha:V(H)\to\{0,1\}^*$ for $H$ and a labelling scheme $\beta:V(P)\to\{0,1\}^*$ for $P$ and assign each vertex $v:=(x,y)\in V(G^*)$ the label $\mu(v):=\alpha(x),\beta(y)$.  Given two labels $\ell_1=\alpha(x_1),\beta(y_1)$ and $\ell_2=\alpha(x_2),\beta(y_2)$ for vertices $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ adjacency testing is done using the following formula whose three clauses follow from definition of strong product:
% \[
%     L(\ell_1,\ell_2):= (\ell_1\neq \ell_2) \wedge \A(\alpha(x_1),\alpha(x_2)) \wedge \A(\beta(y_1),\beta(y_2)) \enspace .
% \]
% 
% \ldots



\section{Preliminaries}
\seclabel{preliminaries}

All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The \emph{size} of a graph $G$ is denoted by $|G|:=|V(G)|$. 
For convenience, we let $\log x := \log\max\{1,x\}$. 

For any graph $G$ and any vertex $v\in V(G)$, let $N_G(v):=\{w\in V(G): vw\in E(G)\}$ and $N_G[v]:=N_G(v)\cup\{v\}$ denote the open neighbourhood and closed neighbourhood of $v$ in $G$, respectively.

\subsection{Prefix-Free Codes}

For a string $s=s_1,\ldots,s_k$, we use $|s|:=k$ to denote the length of $s$. 
We denote the empty string by $\varepsilon$. 
A string $s_1,\ldots,s_k$ is a \emph{prefix} of a string $t_1,\ldots,t_\ell$ if $k\le \ell$ and $s_1,\ldots,s_k=t_1,\ldots,t_k$.  A \emph{prefix-free code} $c:X\to\{0,1\}^*$ is a one-to-one function in which $c(x)$ is not a prefix of $c(y)$ for any two distinct $x,y\in X$.  Let $\N$ denote the set of non-negative integers.  The following is a classic observation of Elias from 1975.

%Louis. I reverted that back to a lemma... observation should be reserved for completely obvious things, right?  Pat: I agree.

\begin{lem}[Elias \cite{elias:universal}]\lemlabel{elias}
    There exists a prefix-free code $\gamma:\N\to\{0,1\}^*$ such that, for each $i\in\N$, $|\gamma(i)|\le 2\lfloor\log(i+1)\rfloor + 1\in O(\log i)$.
  \end{lem}

  In the remainder of the paper, $\gamma$ (which we call an \emph{Elias encoding}) will be used extensively, without referring systematically to \lemref{elias}.

\subsection{Labelling Schemes Based on Binary Trees}

A \emph{binary tree} $T$ is a rooted tree in which each node except the root is either the \emph{left} or \emph{right} child of its parent and each node has at most one left and at most one right child.  For any node $x$ in $T$, $P_T(x)$ denotes the path from the root of $T$ to $x$.  The \emph{length} of a path $P$ is the number of edges in $P$, i.e., $|P|-1$.  The \emph{depth}, $d_T(x)$ of $x$ is the length of $P_T(x)$.  The \emph{height} of $T$ is $h(T):=\max_{x\in V(T)} d_T(x)$.  A \emph{perfectly balanced} binary tree is any binary tree $T$ of height $h(T)=\lfloor\log|T|\rfloor$.

A binary tree is \emph{full} if each non-leaf node has exactly two children. For a binary tree $T$, we let $T^+$ denote the full binary tree obtained by attaching to each node $x$ of $T$ $2-c$ leaves where $c$ is the number of children of $x$.  We call the leaves of $T^+$ the \emph{external nodes} of $T$.  (Note that these external nodes are not actually in $T$.)

A node $a\in V(T)$ is a \emph{$T$-ancestor} of $x\in V(T)$ if $a\in V(P_T(x))$. If $a$ is a $T$-ancestor of $x$ then $x$ is a \emph{$T$-descendant} of $a$. (Note that $x$ is a $T$-ancestor and $T$-descendant of itself.)  For a subset of nodes $X\subseteq V(T)$, the \emph{lowest common $T$-ancestor} of $X$ is the maximum-depth node $a\in V(T)$ such that $a$ is a $T$-ancestor of $x$ for each $x\in X$.  

Let $x_0,\ldots,x_{r}$ be a path from the root $x_0$ of $T$ to some node $x_r$ (possibly $r=0$).  Then the \emph{signature} of $x_r$ in $T$, denoted $\sigma_T(x_r)$ is a binary string $b_1,\ldots,b_r$ where $b_i=0$ if and only if $x_{i}$ is the left child of $x_{i-1}$.  (Note that the signature of the root of $T$ is the empty string, i.e., $\sigma_T(x_0)=\varepsilon$.)

A \emph{binary search tree} $T$ is a binary tree whose node set $V(T)$ consists of distinct real numbers and that has the \emph{binary search tree property}:  For each node $x$ in $T$, $z<x$ for each node $z$ in $x$'s left subtree and $z>x$ for each node $z$ in $x$'s right subtree. For any $x\in\R\setminus V(T)$, the \emph{search path} $P_T(x)$ in $T$ is the unique root-to-leaf path $v_0,\ldots,v_r$ in $T^+$ such that adding $x$ as a (left or right, as appropriate) child of $v_{r-1}$ in $T$ would result in a binary search tree $T'$ with $V(T')=V(T)\cup\{x\}$.

The following observation allows us to compare values in a binary search tree just given their signatures in the tree.

\begin{obs}\obslabel{lexicographic}
  For any binary search tree $T$ and any $x,y\in V(T)$, $x<y$ if and only if $\sigma_T(x)$ is lexicographically less than $\sigma_T(y)$.
\end{obs}

Let $\R^+$ denote the set of positive real numbers. The following is a folklore result about biased binary search trees, but we sketch a proof here for completeness.

\begin{lem}\lemlabel{biased-bst}
  For any finite $S\subset \R$ and any function $w:S\to\R^+$, there exists a binary search tree $T$ with $V(T)=S$ such that, for each $y\in S$, $d_T(y)\le\log(W/w(y))$, where $W:=\sum_{y\in S} w(y)$.
\end{lem}

\begin{proof}
  The proof is by induction on $|S|$. The base case $|S|=0$ is vacuously true.
  For any $x\in\R$, let $S_{<x}:=\{y\in S: y < x\}$ and $S_{>x}:=\{y\in S: y>x\}$. For $|S|\ge 1$, choose the root of $T$ to be the unique node $y_0\in S$ such that $\sum_{z\in S_{<y_0}} w(z)\le W/2$ and $\sum_{z\in S_{>y_0}}< W/2$. Apply induction on $S_{<y_0}$ and $S_{>y_0}$ to obtain the left and right subtrees of $T$, respectively.
  
  Then $d_T(y_0)=0=\log 1\le \log (W/w(y_0))$.  For each $y\in S_{<y_0}$, 
  \[ 
    d_T(y) \le 1 + \log\left(\frac{\sum_{z\in S_{<y_0}}w(z)}{w(y)}\right) 
            \le 1 + \log \left(\frac{W/2}{w(y)}\right) 
            = \log \left(\frac{W}{w(y)}\right) , 
  \]
  and the same argument shows that $d_T(y) < \log (W/w(y))$ for each $y\in S_{>y_0}$.  
\end{proof}

The following fact about binary search trees is useful, for example, in the deletion algorithms for several types of balanced binary search trees \cite[Section~6.2.3]{morin:open}, see \figref{sigma-minus-one}:

\begin{figure}
  \begin{center}
    \includegraphics{figs/sigma-minus-one}
  \end{center}
  \caption{An illustration of \obsref{predecessor-encoding}: (1)~$\sigma_T(y_1)=11000$ and $\sigma_T(x_1)=1\mbox{\sout{1000}}$ (2)~$\sigma_T(y_2)=10\mbox{\sout{011}}$ and $\sigma_T(x_2)=10011$.}
  \figlabel{sigma-minus-one}
\end{figure}

\begin{obs}\obslabel{predecessor-encoding}
  Let $T$ be a binary search tree and let $x$, $y$ be nodes in $T$ such that $x<y$ and there is no node $z$ in $T$ such that $x<z<y$, i.e., $x$ and $y$ are consecutive in the sorted order of $V(T)$.  Then
  \begin{enumerate}
    \item (if $y$ has no left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by removing all trailing 0's and the last 1; or
    \item (if $y$ has a left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by appending a 0 followed by $d_T(y)-d_T(x)-1$ 1's.
  \end{enumerate}
\end{obs}

% \snote{Piotrek: lets put a small figure here illustrating the two cases of Obs. Pat: Done}

\obsref{predecessor-encoding} leads to the following definition. For a binary search tree $T$ and an integer $i$ such that $V(T)$ contains $i-1$ and $i$, we define $\delta_T(i)$ as
a single bit indicating whether $i$ has a left-child in $T$ and, in case $i$ does have a left-child, an Elias encoding $\gamma(s)$ of the value $s:=d_T(i)-d_T(i-1)-1$.  More precisely, $\delta_T(i)=0$ or $\delta_T(i)=1,\gamma(s)$. \obsref{predecessor-encoding} implies that $\sigma_T(i)$ and $\delta_T(i)$ are enough to recover $\sigma_T(i-1)$.

\smallskip

Putting some of the preceding results together we obtain the following useful coding result.

\begin{lem}\lemlabel{row-code}
  There exists a function $A:(\{0,1\}^*)^2\to\{-1,0,1,\perp\}$ such that, for any $h\in\N$, and any $w:\{1,\ldots,h\}\to\R^+$ there is a prefix-free code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that 
  \begin{compactenum}
    \item for each $i\in\{1,\ldots,h\}$, $|\alpha(i)|=\log W -\log w(i) + O(\log\log h)$;
    \item for any distinct $i,j\in\{1,\ldots,h\}$, 
    \[   A(\alpha(i),\alpha(j)) 
    = \begin{cases}
       0 & \text{if $j=i$;}\\
       1 & \text{if $j=i+1$;} \\
       -1 & \text{if $j=i-1$;} \\
       \perp & \text{otherwise.}
      \end{cases}
      \]
    \end{compactenum}
\end{lem}


\begin{proof}
  Define $w':\{1,\ldots,h\}\to \R^+$ as $w'(i)=w(i)+W/h$ and let $W':=\sum_{i=1}^h w'(i)=2W$.
  Using \lemref{biased-bst}, construct a biased binary search tree $T$ on $\{1,\ldots,h\}$ using $w'$ so that 
  \[   
    d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log w(i)+1
  \]
  and
  \[
  d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log (W/h)+1 \le \log h + 1\enspace ,
  \]
  for each $i\in\{1,\ldots,h\}$.  This latter inequality implies that $h(T)\le\log h + 1$.

  The code $\alpha(i)$ for $i$ consists of three parts.  The first part, $\gamma(|\sigma_T(i)|)$, is the Elias encoding of the length of the path from the root to $i$ in $T$. The second part $\sigma_T(i)$ encodes the left/right turns along this path. The third part is $\delta_T(i)$, defined after \obsref{predecessor-encoding}. The length of $\delta_T(i)$ is at most $1+O(\log s)=O(\log\log h)$. Note that since $\gamma$ is prefix-free and two sequences $\sigma_T(i)$ and $\sigma_T(j)$ of the same length cannot be prefix of one another, the code $\alpha$ is also prefix-free (and thus injective).

  The function $A$ is given by a simple algorithm: Given $\alpha(i)$ and $\alpha(j)$, first observe that the values of $\gamma(\cdot)$, $\sigma_T(\cdot)$, and $\delta_T(\cdot)$ can be extracted: $\gamma(\cdot)$ is first extracted using the fact that Elias encoding is prefix-free, this then gives us the length of $\sigma_T(\cdot)$, and finally $\delta_T(\cdot)$ consists of the remaining bits. 
   The function $A$ extracts the values and lexicographically compare $\sigma_T(i)$ and $\sigma_T(j)$.  If $\sigma_T(i)=\sigma_T(j)$, then $A$ outputs $0$. 
   Otherwise, assume for now that $\sigma_T(i)$ is lexicographically less than $\sigma_T(j)$ so that, by \obsref{lexicographic}, $i < j$.  Now using $\sigma_T(j)$ and $\delta_T(j)$, $A$ computes $\sigma_T(j-1)$ as described in \obsref{predecessor-encoding}.  
   If $\sigma_T(j-1)=\sigma_T(i)$ then $A$ outputs $1$, otherwise $A$ outputs $\perp$.
  In the case where $\sigma_T(i)$ is lexicographically greater than $\sigma_T(j)$, $A$ proceeds in the same manner, but reversing the roles of $i$ and $j$ and outputting $-1$ in the case where $\sigma_T(i-1)=\sigma_T(j)$.
\end{proof}

\subsection{Chunked Sets and Fractional Cascading}

For non-empty finite sets $X,Y\subset \R$ and an integer $a$, we say that $X$ \emph{$a$-chunks} $Y$ if, for any $a+1$-element subset $S\subseteq Y$, there exists $x\in X$, such that $\min S\le x\le \max S$. Observe that, if $X$ $a$-chunks $Y$, then $|Y\setminus X|\le a(|X|+1)\le 2a|X|$ so $|X\cup Y|\le (2a+1)|X|$. 

\begin{lem}\lemlabel{fractional}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exist sets $V_0,\ldots,V_{h+1}$ such that
  \begin{compactenum}
    \item for each $y\in\{1,\ldots,h\}$, $V_y\supseteq S_y$;
    \item for each $y\in\{1,\ldots,h\}$, $V_{y-1}$ 3-chunks $V_y$ and $V_{y+1}$ 3-chunks $V_y$;
    \item $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|$.
  \end{compactenum}
\end{lem}

A proof of a much more general version of \lemref{fractional} (with larger constants) is implicit in the iterated search structure of Chazelle and Guibas \cite{chazelle.guibas:fractional1}.   For the sake of completeness, \appref{fractional-proof} includes a proof of \lemref{fractional} that borrows heavily from the amortized analysis of partially persistent data structures \cite[Section~2.3]{driscoll.sarnak.ea:making}.


\subsection{Product Structure Theorems}

The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two distinct vertices $(x_1,y_1)$ and $(x_2,y_2)$ are adjacent if and only if:
\begin{enumerate}
  \item  $x_1x_2 \in E(A)$ and $y_1y_2 \in E(B)$; or
  \item $x_1=x_2$ and $y_1y_2\in E(B)$; or
  \item $x_1x_2 \in E(A)$ and $y_1=y_2$.
\end{enumerate}

\begin{thm}[Dujmović \etal\ \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure}
  Every planar graph $G$ is a subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
\end{thm}

\thmref{product-structure} can be generalized (replacing $8$ with a larger constant) to bounded genus graphs, and more generally to apex-minor free graphs.
%\begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure-apex-minor-free}
%  Let $\mathcal{G}$ be a minor-closed family of graphs that excludes some fixed apex graph.  Then every $G\in\mathcal{G}$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of bounded treewidth and $P$ is a path.
%\end{thm}
Dujmović, Morin, and Wood \cite{dujmovic.morin.ea:structure} gave analogous product structure theorems for some non-minor closed families of graphs including $k$-planar graphs, map graphs, powers of bounded-degree planar graphs, and $k$-nearest-neighbour graphs of points in $\R^2$. Dujmović, Esperet, Morin, Walczak, and Wood \cite{DEMWW20} proved that a similar product structure theorem holds for graphs of bounded degree from any (fixed) proper minor-closed class.

%Dujmović, Morin, and Wood \cite{dujmovic.morin.ea:structure} gave analogous product structure theorems for some non-minor closed families of graphs based on so-called $(k,d)$-shortcut systems.  Such graphs include $k$-planar graphs, map graphs, powers of bounded-degree planar graphs, and $k$-nearest-neighbour graphs of points in $\R^2$. Dujmović, Esperet, Morin, and Walczak and Wood \cite{DEMWW20} proved that a similar product structure theorem holds for graphs of bounded degree from any (fixed) proper minor-closed class.

Our main result, which is a $(1+o(1))\log n$-bit adjacency labelling scheme for $n$-vertex subgraphs of $H\boxtimes P$, where $H$ has bounded treewidth and $P$ is a path, holds for all these classes of graphs.

The case of graphs of bounded degree from minor-closed classes is particularly interesting, 
since the best known bound for adjacency labelling schemes in planar graphs of bounded degree was the same as for general planar graphs, i.e.\ $(4/3+o(1))\log n$. On the other hand, our main result implies an asymptotically optimal bound of $(1+o(1))\log n$ for graphs of bounded degree from any proper minor-closed class.


\section{Bulk Trees}
\seclabel{bulk-trees}

The labelling scheme for planar graphs uses labels whose largest part comes from paths in a special type of balanced binary search tree that we call a \emph{bulk tree}.  The operations in a bulk tree proceed in \emph{rounds} where, in each round, two types of bulk operations are performed: \emph{bulk insertion}, in which a set $I\subset \R\setminus V(T)$ of new values are inserted into $T$, and \emph{bulk deletion}, in which a set $D\subseteq V(T)$ of values are removed from $T$. The sets $I$ and $D$ inserted into and deleted from $T$ in a single round must satisfy the following two restrictions: (i)~$V(T)$ $3$-chunks $I$; and (ii)~$V(T)\setminus D$ 3-chunks $D$.\footnote{There is nothing special about the constant $3$ here.  The data structure and its analysis work with $3$ replaced by any constant $a$.}  Note that (ii) implies that $|D|\le 6(|V(T)|-|D|)$, so $|D|\le (6/7)|V(T)|$.

\subsection{Phases}\label{sec:3.1}

A bulk tree is parameterized by an integer $k\ge 1$.  The rounds of a bulk tree $T$ are partitioned into \emph{phases} that are kept track of using two integer values.
% \snote{L. Is ``broken up'' the right term here? When I read it I had the impression that each round has different phases, this got me confused in the remainder. P: changed to partitioned}.  
At the beginning of a phase, a counter $y$ is initialized to $0$ and a value $y^*$ is computed:
\[  
  y^* := \left\lceil \frac{\log|T|}{k-\log 7}\right\rceil. 
\]
After each round, the value $y$ is incremented.  When $y=y^*$, a new phase begins, so $y$ is reset to 0 and a new value of $y^*$ is computed using the current size of $T$.

\smallskip

This will not be needed until the final sections, but it is good to have in mind in the remainder that ultimately we will take $k=\left\lceil\sqrt{\log n \log \log n}\right\rceil$, so that the expression $O(k+k^{-1}\log n)$ (which appears many times), is $\omega(1)$ and $o(\log n)$.

\subsection{Bulk Insertion}

The bulk insertion operation, in which a finite set $I\subset  \R\setminus V(T)$ of new values are inserted into $T$, is implemented as follows: Let $z_0,\ldots,z_{|T|}$ denote the external nodes of $T$.  For each $i\in\{0,\ldots,|T|\}$, let $I_i$ consist of all $x\in I$ such that $P_T(x)$ ends at $z_i$. 
Since $V(T)$ $3$-chunks $I$, $|I_i|\le 3$ for each $i\in\{0,\ldots,|T|\}$. For each $i\in\{0,\ldots,|T|\}$, construct a perfectly balanced binary search tree $T_i$ with vertex set $I_i$. For each $i\in\{1,\ldots,|T|\}$, replace $z_i$ with $T_i$ in $T^+$. 
The resulting tree is the outcome of the operation. 

\begin{lem}\lemlabel{insertion-depth}
  Let $T$ be any binary search tree and perform a bulk insertion on $T$ to obtain a new tree $T'$.  Then $T'$ is a supergraph of $T$ and $h(T')\le h(T)+2$.
\end{lem}

\begin{proof}
  That $T'$ is a supergraph of $T$ is obvious.  That $h(T')\le h(T)+2$ comes from the fact that, for each $i\in\{0,\ldots,|T|\}$, $|T_i|=|I_i|\le 3$ and $T_i$ is perfectly balanced, so $h(T_i)\le\lfloor\log 3\rfloor = 1$. Any root-to-leaf path in $T'$ consists of a root-to-leaf path in $T$ followed by at most 2 elements of $T_i$ for some $i\in\{1,\ldots,|T|\}$.  Therefore the length of any root-to-leaf path in $T'$ is at most $h(T)+2$.
\end{proof}

\begin{lem}\lemlabel{insertion-size}
  Let $T$ be any binary search tree and perform a bulk insertion on $T$ to obtain a new tree $T'$.  Let $x$ be any node of $T$ and let $T_x$ and $T_x'$ be the subtrees of $T$ and $T'$, respectively, rooted at $x$.  Then $|T_x'|\le 7|T_x|$.
\end{lem}

\begin{proof}
  By definition, $V(T)$ 3-chunks $I:=V(T')\setminus V(T)$.  This implies that $V(T_x)$ 3-chunks $I_x:=V(T_x')\setminus V(T_x)$.  Therefore $|I_x|\le 3(|T_x|+1)\le 6|T_x|$, so $|T_x'|=|T_x|+|I_x|\le 7|T_x|$.
\end{proof}


\subsection{Bulk Deletion}

The bulk deletion operation of a subset $D$ of nodes is implemented as a series of $|D|$ individual deletions, performed in any order, each implemented by running the following recursive algorithm for each $x\in D$:  If $x$ is a leaf, then simply remove $x$ from $T$.  Otherwise, $x$ has at least one child.  If $x$ has a left child, then recursively delete the largest value $x'$ in the subtree of $T$ rooted at the left child of $x$ and then replace $x$ with $x'$.  Otherwise $x$ has a right child, so recursively delete the smallest value $x'$ in the subtree of $T$ rooted at the right child of $x$ and then replace $x$ with $x'$.


\begin{lem}\lemlabel{deletion-signature}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, for any node $x$ in $T'$, $\sigma_{T'}(x)$ is a prefix of $\sigma_T(x)$.
\end{lem}

\begin{proof}
  This follows immediately from the fact the only operations performed during a bulk deletion are (i)~deletion of leaves and (ii)~using a value $x'$ to replace the value of one of its $T$-ancestors $x$.  The deletion of a leaf has no effect on $\sigma_{T'}(x)$ for any node $x$ in $T'$.  For any node $z$ in $T'$ other than $x'$, (ii) has no effect on $\sigma_T(z)$.  For the node $x'$, (ii) has the effect of replacing $\sigma_T(x')$ by its length-$d_T(x)$ prefix.  
  % Therefore, for any node $z\in v(T)$, $\sigma_{T'}(z)$ is obtained by truncating $\sigma_{T}(z)$ zero or more times, so $\sigma_{T'}(x)$ is a prefix of $\sigma_T(z)$.
\end{proof}

%The following consequence of \lemref{deletion-signature} follows immediately from the fact that, for any node $z$ in a binary search tree $T$, $d_T(z)=|\sigma_T(z)|$.
The following is an immediate consequence. 

\begin{lem}\lemlabel{deletion-depth}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, $h(T')\le h(T)$.
\end{lem}


\subsection{Rebalancing}

At the beginning of a round, before bulk insertion and bulk deletion, a rebalancing operation is performed.  This operation uses several subroutines that we now discuss, beginning with the most fundamental one:  $\textsc{Split}(x)$.

\subsubsection{$\textsc{Split}(x)$}

The argument of $\textsc{Split}(x)$ is a node $x$ in $T$ and the end result of the subroutine is to split $T$ into two subtrees $T_{<x}$ and $T_{>x}$ where $V(T_{<x})=\{z\in V(T): z<x\}$ and $V(T_{>x})=\{z\in V(T): z>x\}$. Refer to \figref{split}.  Let $x_0,\ldots,x_r$ be the path in $T$ from the root $x_0$ of $T$ to $x=x_r$.  Partition $x_0,\ldots,x_{r-1}$ into two subsequences $a:=a_1,\ldots,a_s$ and $b:=b_1,\ldots,b_t$ where the elements of $a$ are less than $x$ and the elements of $b$ are greater than $x$.
Note that the properties of a binary search tree guarantee that
\[
a_1 < \cdots < a_s < x < b_t < \cdots < b_1.
\]
\begin{figure}
  \begin{center}
    \includegraphics{figs/split-1} \\[1ex]
    $\Downarrow$ \\[1ex]
    \includegraphics{figs/split-2}
  \end{center}
  \caption{The operation of $\textsc{Split}(x)$.}
  \figlabel{split}
\end{figure}

Make a binary search tree $T_0$ that has $x$ as root, the path $a_1,\ldots,a_s$ as the left subtree of $x$ and the path $b_1,\ldots,b_t$ as the right subtree of $x$.  Note that $a_{i+1}$ is the right child of $a_i$ for each $i\in\{1,\ldots,s-1\}$ and $b_{i+1}$ is the left child of $b_i$ for each $i\in\{1,\ldots,t-1\}$. 

Next, consider the forest $F:=T-\{x_0,\ldots,x_r\}$. This forest consists of $r+2$ (possibly empty) trees $A_1,\ldots,A_{r-1},L,R$ where $L$ and $R$ are the subtrees of $T$ rooted at the left and right child of $x$ and, for each $i\in\{1,\ldots,r-1\}$, $A_i$ is the subtree of $T$ rooted at the child $c_i\neq x_{i+1}$ of $x_i$.  Make a binary search tree $T_x$ by replacing each of the $r+2$ external nodes of $T_0^+$ with the corresponding tree in $F$.  Finally, let $T_{<x}$ be the subtree of $T_x$ rooted at the left child of $x$ and let $T_{>x}$ be the subtree of $T_x$ rooted at the right child of $x$.

\begin{lem}\lemlabel{split-height}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\textsc{Split}(x)$ to obtain $T_{<x}$ and $T_{>x}$.  
  Then $h(T_{<x})\le h(T)$ and $h(T_{>x})\le h(T)$.
\end{lem}

\begin{proof}
  Note that for each node $z$ of $T_{<x}$, we have $V(P_{T_{<x}}(z))\subseteq V(P_T(z))$, 
  so $d_{T_{<x}}(z)\le d_T(z)$. 
  Therefore $h(T_{<x})\le h(T)$. The argument for $T_{>x}$ is symmetric.
\end{proof}

The following observation shows that there is a simple relationship between a node's signature in $T$ before calling $\textsc{Split}(x)$ and its signature in the subtree $T_{<x}$ or $T_{>x}$.

\begin{obs}\obslabel{split-signature}
  Let $T$, $x$, $x_0,\ldots,x_r$, $A_1,\ldots,A_{r-1},L,R$, $a_1,\ldots,a_s$, and $b_1,\ldots,b_t$ be defined as above. Then
  \begin{compactenum}
    \item for each $j\in\{1,\ldots,s\}$ where $a_j=x_i$
    \begin{compactenum}
      \item $\sigma_{T_{<x}}(a_j)=1^{j-1}$, and 
      \item $\sigma_{T_{<x}}(z) = 1^{j-1},0,\sigma_{A_i}(z)$ for each $z\in V(A_i)$;
    \end{compactenum}
    \item for each $j\in\{1,\ldots,t\}$ where $b_j=x_i$
    \begin{compactenum}
      \item $\sigma_{T_{>x}}(b_j)=0^{j-1}$, and 
      \item $\sigma_{T_{>x}}(z) = 0^{j-1},1,\sigma_{A_i}(z)$ for each $z\in V(A_i)$;
    \end{compactenum}
    \item $\sigma_{T_{<x}}(z)=1^s,\sigma_L(z)$ for each $z\in V(L)$; and
    \item $\sigma_{T_{>x}}(z)=0^t,\sigma_R(z)$ for each $z\in V(R)$.
  \end{compactenum}
  In particular, for any $z\in V(T)\setminus\{x\}$, $\sigma_{T_{<x}}(z)$ or $\sigma_{T_{>x}}(z)$ can be obtained from $\sigma_T(z)$ by deleting a prefix and replacing it with one of the $4\cdot h(T)$ strings in $\Pi:=\bigcup_{j=0}^{h(T)-1}\{0^j,0^j1,1^j,1^j0\}$.
\end{obs}

\subsubsection{$\textsc{MultiSplit}(x_1,\ldots,x_c)$}

From the $\textsc{Split}(x)$ operation we build the $\textsc{MultiSplit}(x_1,\ldots,x_c)$ operation that takes as input a sequence of nodes $x_1<\cdots<x_c$ of $T$.  For convenience, define $x_0=-\infty$ and $x_{c+1}=\infty$.  The effect of $\textsc{MultiSplit}(x_1,\ldots,x_c)$ is to split $T$ into a sequence of binary search trees $T_0,\ldots,T_{c}$ where, for each $i\in\{0,\ldots,c\}$, $V(T_i)=\{z\in V(T): x_i< z<x_{i+1}\}$.

The implementation of $\textsc{MultiSplit}(x_1,\ldots,x_c)$ is straightforward divide-and-conquer:  If $c=0$, then there is nothing to do.  Otherwise, call $\textsc{Split}(x_{\lceil c/2\rceil})$ to obtain $T_{<x_{\lceil c/2\rceil}}$ and $T_{>x_{\lceil c/2\rceil}}$.  Next, apply $\textsc{MultiSplit}(x_1,\ldots,x_{\lceil c/2\rceil-1})$ to $T_{<x_{\lceil c/2\rceil}}$ to obtain $T_0,\ldots,T_{\lceil c/2\rceil-1}$ and then apply $\textsc{MultiSplit}(x_{\lceil c/2\rceil+1},\ldots,x_c)$ to $T_{>x_{\lceil c/2\rceil}}$ to obtain $T_{\lceil c/2\rceil},\ldots,T_c$.

The following lemma is immediate from \lemref{split-height}. 
\begin{lem}\lemlabel{multisplit-height}
  Let $T$ be any binary search tree and apply $\textsc{MultiSplit}(x_1,\ldots,x_c)$ to $T$ to obtain $T_0,\ldots,T_c$.  Then $h(T_i)\le h(T)$ for each $i\in\{0,\ldots,c\}$.
\end{lem}

\subsubsection{$\textsc{Balance}(x)$}

The $\textsc{Balance}(x)$ operation operates on the subtree $T_x$ of $T$ rooted at some node $x\in V(T)$.   Refer to \figref{balance-x}.

\begin{figure}
    \begin{center}
      \includegraphics{figs/balance-x-1} \\[-2ex]
      $\Downarrow$ \\[1ex]
      \includegraphics{figs/balance-x-2}
    \end{center}  
  \caption{The operation of $\textsc{Balance}(x)$}
  \figlabel{balance-x}
\end{figure}

If $|V(T_x)|< 2^k$, then this operation simply replaces $T_x$ with a perfectly balanced binary search tree containing $V(T_x)$.  Otherwise, let $Z:=\{z\in V(T_x): d_{T_x}(z)< k\}$.  Call the $m\le 2^k-1$ elements of $Z$  $z_1<z_2<\cdots<z_{m}$ and, for convenience, define $z_0=-\infty$ and $z_{m+1}=\infty$.

Select the nodes $X:=\{x_1,\ldots,x_{2^k-1}\}$ of $T_x$ where each $x_j$ has rank $\lfloor j|T_x|/2^k\rfloor$ in $V(T_x)$.\footnote{For a finite set $X\subset\R$, and $x\in\R$, the \emph{rank} of $x$ in $S$ is $|\{x'\in S: x'<x\}|$.}  The $\textsc{Balance}(x)$ operation will turn $T_x$ into a tree with a top part $\hat{T}_0$ that is a perfectly balanced binary search tree on $Z\cup X$.  We now describe how this is done.

$T_x-Z$ is a forest consisting of $m+1\le 2^{k}$ trees $T_0,\ldots,T_m$. (Some of these trees may be empty.)  Order $T_{0},\ldots,T_m$ so that, for each $i\in\{0,\ldots,m\}$ and each $x'\in V(T_i)$, $z_i< x' < z_{i+1}$.  For each $i\in\{0,\ldots,m\}$, let $\{x_{i,1},\ldots,x_{i,c_i}\}:=X\cap V(T_i)$ where $x_{i,1}<\cdots<x_{i,c_i}$ and define $x_{i,0}:=z_i$ and $x_{i,c_i+1}:=z_{i+1}$. Note that for each $i\in\{0,\ldots,m\}$, $c_i\le |X|\le 2^k-1$.

For each $i\in\{0,\ldots,m\}$, apply $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ to the tree $T_i$.  The result of this call to $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ is a sequence of trees $T_{i,0},\ldots,T_{i,c_i}$ where, for each $i\in\{0,\ldots,m\}$, each $j\in\{0,\ldots,c_i\}$, and each $x'\in V(T_{i,j})$, we have $x_{i,j}<x'<x_{i,j+1}$.  Observe that $\bigcup_{i=0}^m\bigcup_{j=0}^{c_i} V(T_{i,j}) = V(T_x)\setminus (Z\cup X)$.

Let $p:=|Z\cup X|$, let $s_1<\cdots< s_p$ denote the elements of $Z\cup X$ and define $s_0:=-\infty$ and $s_{p+1}:=\infty$.  For each $\ell\in\{0,\ldots,p\}$, let $i_\ell:=|Z\cap \{s_1,\ldots,s_\ell\}|$ and $j_\ell:= \ell - \max\{ q\in\{1,\ldots,\ell\}: s_q\in Z\}$ and let $A_\ell:=T_{i_\ell,j_\ell}$.   Then, for each $\ell\in \{0,\ldots,p\}$ and each $x'\in V(A_\ell)$, we have $s_\ell < x' < s_{\ell+1}$.

Now construct a perfectly balanced tree $\hat{T}_0$ with vertex set $V(\hat{T}_0):=\{s_1,\ldots,s_p\}=Z\cup X$.  The tree $\hat{T}_0$ has $p+1$ external nodes $a_0,\ldots,a_p$.  We obtain a new tree $T_x'$ by replacing $a_\ell$ with $A_\ell$ for each $\ell\in\{0,\ldots,p\}$ in $\hat{T}_0$.  In the bulk tree $T$ we replace the subtree $T_x$ with $T_x'$.

\begin{lem}\lemlabel{multisplit-depth}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\textsc{Balance}(x)$ to $T$ to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{proof}
  Since $\textsc{Balance}(x)$ only affects the subtree $T_x$ rooted at $x$, it suffices to show that $h(T_x')\le h(T_x)+1$.  For each $i\in\{0,\ldots, m\}$, $T_i$ is rooted at a depth-$k$ node of $T_x$, so $h(T_i)\le h(T_x)-k$. For each $\ell \in\{0,\ldots,p\}$, $A_\ell$ is obtained by an application of $\textsc{MultiSplit}$ to $T_i$ for some $i\in\{0,\ldots,m\}$ so, by \lemref{multisplit-height}, $h(A_\ell)\le h(T_i)\le h(T_x)-k$.  Next, $|Z\cup X|\le |Z|+|X| \le 2^k-1 + 2^k-1 < 2^{k+1}-1$ and $\hat{T}_0$ is a perfectly balanced binary search tree of size $|\hat{T}_0|=|Z\cup X|$.  Therefore $h(\hat{T}_0)\le \lfloor\log|\hat{T}_0|\rfloor\le \lfloor\log(2^{k+1}-1)\rfloor = k$.  Finally, $h(T_x')\le h(\hat{T}_0)+1 +\max \{h(A_\ell):\ell\in\{0,\ldots,p\}\} \le k +1 + h(T_x) - k\le h(T_x)+1$.  
\end{proof}

\begin{lem}\lemlabel{balance-x-weight}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, let $T_x$ be the subtree of $T$ rooted at $x$, and apply $\textsc{Balance}(x)$ to $T$ to obtain a new tree $T'$.  Then, for each $T'$-descendant $z$ of $x$ with $d_{T'}(z)=d_{T}(x)+k+1$, the subtree of $T'$ rooted at $z$ has size at most $|T_x|/2^k$.
\end{lem}

\begin{proof}
  Each such subtree is a subtree of $A_\ell$ for some $\ell\in\{0,\ldots,p\}$. Now, $V(A_\ell)\subset (x_j,x_{j+1})$ for some $j\in\{1,\ldots,2^{k-1}\}$.  The values $x_j$ and $x_{j+1}$ have ranks $\lfloor j|T_x|/2^k\rfloor$ and $\lfloor (j+1)|T_x|/2^k\rfloor$ in the set $V(T_x)$.  Therefore, $|A_\ell|\le \lfloor (j+1)|T_x|/2^k\rfloor- \lfloor j|T_x|/2^k\rfloor -1 < |T_x|/2^k$.
\end{proof}

\subsubsection{$\textsc{BulkBalance}(\theta)$}

The ultimate restructuring operation in bulk trees is $\textsc{BulkBalance}(\theta)$.
It calls $\textsc{Balance}(x)$ for each node $x$ of depth $\theta$ in $T$. Note that this operation is well defined, since $\textsc{Balance}(x)$ only influences the subtree rooted in $x$, and the subtrees modified by $\textsc{BulkBalance}(\theta)$ are pairwise disjoint.
The following two lemmas are immediate consequences of \lemref{multisplit-depth} and \lemref{balance-x-weight}, respectively.

\begin{lem}\lemlabel{balance-depth}
  Let $T$ be any binary search tree and apply the $\textsc{BulkBalance}(\theta)$ operation to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{lem}\lemlabel{balance-weight}
  Let $T$ be any binary search tree and apply the $\textsc{BulkBalance}(\theta)$ operation to obtain a new tree $T'$.  
  Let $x$ be any node of $T$ of depth $\theta$ and let $T_x$ be the subtree of $T$ rooted at $x$.   
  Then, for each $T'$-descendant $z$ of $x$ with $d_{T'}(z)=\theta+k+1$, the subtree of $T'$ rooted at $z$ has size at most $|T_x|/2^k$. 
  %% PREVIOUS VERSION:
  %For every node $z$ in $T$ of depth $\theta+k+1$, let $x$ be a $T$-ancestor of $z$ of depth $\theta$, 
  %then a subtree $T'_z$ of $T'$ rooted at $z$ has size at most $|T_x|/2^k$.
  %% FIRST VERSION:
  %Then each subtree $T_z$ of $T'$ rooted at a node $z$ of depth $\theta+k+1$ has size at most $|T_x|/2^k$, where $x$ is the depth-$\theta$ $T$-ancestor of $z$ and $T_x$ is the subtree of $T$ rooted at $x$.
\end{lem}

Finally, recall that a bulk tree works in phases and, within a phase, maintains a counter $y$ that counts the rounds of the phase from $0$ to $y^*$.  The $\textsc{BulkBalance}(\theta)$ operation executes once, at the beginning of each round, with the argument $\theta=y(k+1)$.

\subsection{Analysis of Height}

In this section we show that a bulk tree always has a height that is asymptotically optimal.

\begin{lem}\lemlabel{bulktree-height-i}
  Let $T$ be a bulk tree, let $T_0,\ldots,T_{y^*}$ be the states of $T$ before the first round ($T_0$) and after each round ($T_1,\ldots,T_{y^*}$) of a phase, and let $r_0=h(T_0)-\log|T_0|$.  Then,
  \begin{compactenum}[(i)]
    \item for each $y\in\{0,\ldots,y^*\}$, $h(T_y)\le \log|T_y| + O(k^{-1}\log|T_y|) + r_0$; and
    \item $h(T_{y^*}) = \log|T_{y^*}|+O(k+k^{-1}\log|T_{y^*}|)$.
  \end{compactenum}
\end{lem}

\begin{proof}
  Let $I_0,\ldots,I_{y^*-1}$ and $D_0,\ldots,D_{y^*-1}$ be the sets inserted and deleted so that $I_y$ and $D_y$ are the bulk insertions and bulk deletions performed in round $y$.  First, recall that $|D_y|\le (6/7)|T_y|$, which implies that $|T_{y+1}|\ge |T_y|-|D_y|\ge |T_y|/7$.  Iterating this beginning with $T_0$ implies that 
  \begin{equation}
    |T_y|\ge |T_0|/7^y \quad \Leftrightarrow \quad \log|T_0| \le \log|T_y| + y\log 7, \eqlabel{height-diff}
  \end{equation}
  for each $y\in\{0,\ldots,y^*\}$. 


  We will prove the lemma by establishing the following two invariants:
  \begin{enumerate}[(B1)]
    \item $h(T_y)\le h(T_0) + 3y$;
    \item each subtree of $T_y$ rooted at a node of depth $y(k+1)$ has size at most $|T_0|(7/2^k)^{y}$.
  \end{enumerate}

  First we show that (B1) implies (i). Observe that, for any $y\in\{0,\ldots,y^*\}$,  
  \[  
  y^*\le \tfrac{\log |T_0|}{k-\log 7}+1\le \tfrac{\log |T_y|+y^*\log 7}{k-\log 7}+1, 
  \]
  and thus 
  \begin{equation}  
    y^*\le \tfrac{\log |T_y|}{k-2\log 7}+ \tfrac{k-\log 7}{k-2\log 7} = O(k^{-1}\log|T_y|). 
    \eqlabel{ystar-bound}
  \end{equation}


  For each  $y\in\{0,\ldots,y^*\}$, (B1) gives the upper bound
  \begin{align*}
       h(T_y) & \le h(T_0) + 3y \\
              &= \log|T_0| + 3y + r_0  \\
              &\le \log |T_y| + (3+\log 7)y + r_0  &\text{(by \eqref{height-diff})} \\
              &\le \log |T_y| + (3+\log 7)y^* + r_0 &\text{(since $y\le y^*$)}\\
              &\le \log |T_y| + O(k^{-1}\log|T_y|) + r_0. &\text{(by \eqref{ystar-bound})}
  \end{align*}

  Next we show that (B2) implies (ii).  Recall that $y^*=\lceil\log|T_0|/(\log(2^k/7))\rceil$ so
  $|T_{0}|(7/2^k)^{y^*} \le 1$.  Therefore, by (B2) every subtree of $T_{y^*}$ of depth $y^*(k+1)$ has size at most 1.  A subtree of size 1 has height 0.  Therefore,
  \begin{align*}
    h(T_{y^*}) & \le (k+1)y^* \\
    & = (k+1)\left\lceil \frac{\log|T_0|}{k-\log 7}\right\rceil \\
    & \le (k+1)\left(\frac{\log|T_0|}{k-\log 7 } + 1\right)\\
    & = \left(\frac{k+1}{k-\log 7}\right)\left(\log|T_0|\right) + (k+1)\\
    & = (1+O(k^{-1}))\cdot(\log|T_0|) + (k+1) \\
    & \le (1+O(k^{-1}))\cdot(\log|T_{y^*}| + y^*\log 7) + (k+1) & \text{(by \eqref{height-diff})}\\
    & = \log|T_{y^*}| + O(k+k^{-1}\log |T_{y^*}|). &\text{(by \eqref{ystar-bound})}
  \end{align*}


  All that remains is to show that invariants (B1) and (B2) are indeed satisfied for all $y\in\{0,\ldots,y^*\}$.  The proof is by induction on $y$.  For the base case $y=0$, both properties are trivial: (B1) asserts that $h(T_0)\le h(T_0)$ and (B2) asserts that the subtree of $T_0$ rooted at the root of $T_0$ has size at most $|T_0|$.

  For the inductive step, assume $y\ge 1$ and invariants (B1) and (B2) hold for $T_{y-1}$.  First we establish invariant (B1) as follows:
  Lemmas~\ref{lem:insertion-depth}, \ref{lem:deletion-depth}, and \ref{lem:balance-depth} imply that $h(T_y)\le h(T_{y-1})+3$.  
  By the inductive hypothesis (B1) is satisfied for $T_{y-1}$, so $h(T_{y-1})\le h(T_0)+3(y-1)$.  Thus $h(T_y)\le h(T_{y-1}) + 3 \le h(T_0)+3y$.
  
  Next we establish (B2).  By (B2) applied to $T_{y-1}$, every subtree of $T_{y-1}$ rooted at a node of depth $(y-1)(k+1)$ has size at most $|T_{0}|(7/2^k)^{y-1}$.  The first step in round $y-1$ is to execute $\textsc{BulkBalance}((y-1)(k+1))$.  By \lemref{balance-weight}, this results in a tree $T_{y-1}'$ in which every subtree rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y-1}/2^k$.  The second step in round $y-1$ is to perform a bulk insertion on $T_{y-1}'$ to obtain a new tree $T_{y-1}''$.  
  % The fact that $V(T_{y-1})$ 3-chunks the newly inserted set $I_{y-1}$ ensures that the size of any subtree increases by a factor of at most $6$.  
  By \lemref{insertion-size}, every subtree of $T_{y-1}''$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y}$.  Finally, the third step in round $y-1$ is to perform a bulk deletion on $T_{y-1}''$ to obtain $T_{y}$.  Bulk deletion does not increase the size of any subtree, so every subtree of $T_{y}$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y}$, as required.
\end{proof}

A \emph{bulk tree sequence} $T_1,\ldots,T_h$ is a sequence of binary search trees where $T_1$ is a perfectly balanced binary search tree and for each $y\in\{2,\ldots,h\}$, $T_y$ is obtained from $T_{y-1}$ by a round of bulk tree operations (bulk balance, bulk insert, bulk delete).  Note that any bulk tree sequence also defines sequences $I_1,\ldots,I_{h-1}$ and $D_1,\ldots,D_{h-1}$ of insertion and deletion sequences, respectively, where $I_y:=V(T_{y+1})\setminus V(T_y)$ and $D_y:=V(T_{y})\setminus V(T_{y+1})$ for each $y\in\{1,\ldots,h-1\}$. 
The following lemma shows that bulk trees are balanced at all times:
\begin{lem}\lemlabel{bulk-tree-height}
  For each bulk tree sequence $T_1,\ldots,T_h$ and each $y\in\{1,\ldots,h\}$,  $h(T_y)\le \log|T_y| + O(k+k^{-1}\log|T_y|)$.
\end{lem}

\begin{proof}
  Let $Y\subseteq\{1,\ldots,h\}$ be the set of indices containing exactly those indices $y$ where $T_y$ begins a new phase. By definition $1\in Y$ and, since $T_1$ is a perfectly balanced binary tree it certainly satisfies the conditions of the lemma.  For $y\in Y\setminus\{1\}$, 
  \lemref{bulktree-height-i}(ii) implies that $T_y$ satisfies the conditions of the lemma.  
  
  All that remains is to show that the conditions of the lemma are satisfied for each $y\in\{1,\ldots,h\}\setminus Y$. To show this, let $y_0=\max\{ y'\in Y: y'<y\}$.  That is, $T_{y_0}$ is the tree that began the phase in which $T_y$ takes part.  Let $y^*$ be defined as in Section~\ref{sec:3.1}, but with respect to the tree $T_{y_0}$, i.e.\ $y^*=\left\lceil\tfrac{\log |T_{y_0}|}{k-\log 7}\right\rceil$.
  %=(1+o(1))k^{-1}\log |T_{y_0}|$.
  In this case \lemref{bulktree-height-i}(i) implies that
  \[  h(T_y) \le \log |T_y| + O(k^{-1}\log |T_y|) + h(T_{y_0})-\log|T_{y_0}|.\]  
  Thus, all that is required is to show that $r_0:=h(T_{y_0})-\log|T_{y_0}|\in O(k^{-1}\log|T_y|)$ so that is what we do:
  \begin{align*}
    r_0 &= h(T_{y_0})-\log|T_{y_0}| \\
       &= O(k + k^{-1}\log|T_{y_0}|) 
        & \text{(by \lemref{bulktree-height-i}(ii))}\\
       &= O(k + k^{-1}(\log|T_{y}| + (y-y_0)\log7)) 
        & \text{(by \eqref{height-diff})} \\
       &= O(k + k^{-1}\log|T_{y}| + y^*) 
        & \text{(since $y-y_0 \le y^*$)} \\
       &= O(k + k^{-1}\log|T_{y}|). & \text{(by \eqref{ystar-bound})} & \qedhere
  \end{align*}
\end{proof}



\subsection{Making Bulk Tree Sequences}

Although the 3-chunking requirements on the insertion and deletion sets of bulk trees seem restrictive, the following lemma allows us to store any sequence of subsets of $\R$ in a bulk tree sequence that is not much larger.

\begin{lem}\lemlabel{chunked-bulk-trees}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exists a bulk tree sequence $T_1,\ldots,T_h$ such that $\sum_{y=1}^h |T_y|\le 2\sum_{y=1}^h |S_i|$ and, for each $y\in\{1,\ldots,h\}$, $V(T_y)\supseteq S_y$.
\end{lem}

\begin{proof}
  Apply \lemref{fractional} to the sequence $S_1,\ldots,S_h$ in order to obtain $V(T_1),\ldots,V(T_h)$ satisfying the conditions of the lemma and satisfying the 3-chunking requirement of bulk trees, namely that $V(T_y)$ 3-chunks $I_y:=V(T_{y+1})\setminus V(T_y)$ and that $V(T_{y+1})$ 3-chunks $D_y:=V(T_y)\setminus V(T_{y+1})$.
\end{proof}

\subsection{Transition Codes for Nodes}
\seclabel{node-transitions}

We now arrive at the \emph{raison d'être} of bulk trees:  For two consecutive trees $T_y$ and $T_{y+1}$ in a bulk tree sequence and any $z\in V(T_y)\cap V(T_{y+1})$, the signatures $\sigma_{T_y}(z)$ and $\sigma_{T_{y+1}}(z)$ are so closely related that $\sigma_{T_{y+1}}(z)$ can be derived from $\sigma_{T_y}(z)$ and a short \emph{transition code} $\nu_y(z)$.  The following lemma makes this precise:

\begin{lem}\lemlabel{node-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each bulk tree sequence $T_1,\ldots,T_h$, each $y\in\{1,\ldots,h-1\}$, and each $z\in V(T_y)\cap V(T_{y+1})$, there exists $\nu_y(z)\in\{0,1\}^*$ with $|\nu_y(z)| = O(k\log h(T_y))$ such that $B(\sigma_{T_y}(z), \nu_y(z)) = \sigma_{T_{y+1}}(z)$.  
\end{lem}

\begin{proof}
  The transformation of $T_{y}$ into $T_{y+1}$ occurs in three steps: rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion of $D_y$, which takes $T_y''$ onto $T_{y+1}$.  We consider each of these in turn, saving the most difficult for last.
  
  The transition from $T_y''$ to $T_{y+1}$ (bulk deletion) is simple.  By \lemref{deletion-signature}, the effect of each individual deletion on $\sigma_T(z)$ is to remove a suffix.  Therefore, the net effect of all deletions is to remove a suffix.  The length of this suffix can be included in $\nu_y(x)$ using $O(\log h(T))$ bits.
  
  The transition from $T_y'$ to $T_y''$ (bulk insertion) is even simpler: For every node $z\in V(T_y')\cap V(T_y'')$, $\sigma_{T_y'}(z)=\sigma_{T_y''}(z)$.  A bulk insertion does not require any changes to encode.
  
  The most elaborate transition is from $T_y$ to $T_y'$ (rebalancing).  We will show how to obtain $\sigma_{T_y'}(z)$ by starting with $b:=\sigma_{T_y}(z)$ and performing the following operations:
  \begin{enumerate}[($\nu_1$)]
    \item Splitting $b$ into two strings $b^-$ and $b'$ at some index $\theta$ that can be specified using $O(\log h(T))$ bits.
    \item Deleting a prefix of $b'$ whose length is at most $k$ and can be described using $O(\log h(T))$ bits.
    \item Repeatedly (up to $k+1$ times) deleting a prefix of $b'$ and replacing it with a string in the set $\Pi$ described in \obsref{split-signature}.  The length of each deleted prefix and its replacement can be described with $O(\log h(T))$ bits for a total of $O(k\log h(T))$ bits.
    \item Adding a specific $O(k)$-bit prefix to $b'$, which can be described with $O(k)$ bits.
    \item Concatenating $b^-$ and $b'$ to obtain $\sigma_{T_y'}(z)$.
  \end{enumerate}
  To verify this we have to dig into the details of the rebalancing operations, which involves a single call to $\textsc{BulkBalance}(\theta)$ which calls $\textsc{Balance}(x)$ on each of the nodes $x$ in $T_y$ of depth $\theta$.    
  For a node $z$ in $T_y$, a call to $\textsc{Balance}(x)$ does not affect $\sigma_T(z)$ unless $x$ is an ancestor of $z$ in $T_y$.  Thus, for each $z$ in $T_y$, we can focus on the changes to $\sigma_{T_y}(z)$ caused by the at most one call to $\textsc{Balance}(x)$ where $x$ is an ancestor of $z$. Note that, if $d_{T_y}(z)<\theta$, then $\sigma_{T_y}(z)=\sigma_{T_y'}(z)$, in which case $\nu(z)$ has $O(1)$ bits indicating that this is the case and parts ($\nu_1(z)$)--($\nu_4(z)$) of $\nu_y(x)$ are empty.
  
  Otherwise, $z$ has some depth-$\theta$ $T_y$-ancestor $x$ on which $\textsc{Balance}(x)$ executes. In this case $\nu_{1}(z)=\theta$, indicating that $b$ should be split into $b^-$ and $b'$ at position $\theta$.  
  The $\textsc{Balance}(x)$ operation first identifies two sets of nodes $Z$ and $X$ that will eventually form the perfectly balanced tree $\hat{T}_0$ to which the subtrees $A_0,\ldots,A_p$ are attached.  For each node $z\in Z\cup X$, $\nu_{2}(z):=|b'|$ and $\nu_{4}(z):=\sigma_{\hat{T}_0}(z)$ indicating that all of $b'$ should be deleted and replaced with $\sigma_{\hat{T}_0}(z)$.  For these nodes $\nu_3(z)$ is empty.
    
  Otherwise, each $z\not\in Z\cup X$ is contained in some tree $T_i$ of the forest $T_y-Z$.  In this case, $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ is called on $T_i$ (with $c_i\le 2^k-1$).  During the execution of $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$, $z$ is involved in at most $1+\log c_i\le 1+k$ subtrees that are split by calls to $\textsc{Split}(x)$.  Any call to $\textsc{Split}(x)$ on a subtree $A$ that contains $z$ leaves $z$ in one of the two resulting subtrees, say $A_{<x}$.  When this happens $\sigma_{A_{<x}}(z)$ can be obtained from $b':=\sigma_{A}(z)$ by deleting a prefix and replacing it with a string from $\Pi$ (see \obsref{split-signature}).  This happens at most $k+1$ times and $|\Pi|= 4h(T_y)$, so all of these changes can be recorded with $O(k\log h(T_y))$ bits that are included in $\nu_{3}(z)$.
  
  At the end of this process, $z\in V(A_\ell)$ for some $\ell\in\{1,\ldots,p\}$, and $b'=\sigma_{A_\ell}(z)$.  The tree $A_\ell$ is a subtree of $T_y'$.  The final piece of information then is $\nu_4(z):=\sigma_{\hat{T}_0}(z')$, where $z'$ is the root of $A_\ell$.  This is a bitstring of length $h(\hat{T}_0)+1\le k+1$.
\end{proof}

\section{Subgraphs of $P\boxtimes P$}
\seclabel{pxp}

Before continuing, we show that using the techniques developed thus far, we can already solve a non-trivial special case.  In particular, we consider the case in which $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1=1,\ldots,m$ and $P_2=1,\ldots,h$ are paths. Each vertex of $G$ is a point $(x,y)\in\{1,\ldots,m\}\times \{1,\ldots,h\}$ in the $m\times h$ grid-with diagonals, see \figref{pxp}.

\begin{figure}
  \begin{center}
    \includegraphics{figs/pxp}
  \end{center}
  \caption{The special case where $G$ is a subgraph of $P_1\boxtimes P_2$.}
  \figlabel{pxp}
\end{figure}


\subsection{The Labels}

For each $y\in\{1,\ldots,h\}$, we let $L_y=\{x\in\{1,\ldots,m\}:(x,y)\in V(G)\}$ and let $L^-_y:=L_y\cup\{x-1:(x,y)\in V(G)\}$.  Observe that $|L^-_y|\le 2|L_y|$, so $\sum_{y=1}^h |L^-_y|\le 2n$.   Apply \lemref{chunked-bulk-trees} and \lemref{bulk-tree-height} to obtain a sequence $T_1,\ldots,T_h$ of binary search trees such that

\begin{enumerate}[(PR1)]
  \item $V(T_y)\supseteq L^-_{y}\cup L^-_{y-1}$;
  \item $h(T_y)=\log|T_y| + O(k+k^{-1}\log n)$;
  \item $\sum_{y=1}^h|T_y| \le 8n$.
\end{enumerate}

By \lemref{node-transitions}, for each $y\in\{2,\ldots,h\}$ and each $x\in L_{y-1}$, there exists a code $\nu_{y-1}(x)$, $|\nu_y(x)|=O(k\log\log n)$ such that $B(\sigma_{T_{y-1}}(x),\nu_{y-1}(x))=\sigma_{T_y}(x)$.

Next, apply \lemref{row-code} using the weight function $w(y):=|T_y|$ to obtain a code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that $|\alpha(y)|=\log n - \log|T_y| + O(\log\log n)$.

Now, in the labelling scheme for $G$, each vertex $z=(x,y)\in V(G)$ receives a label consisting of the following:  
\begin{enumerate}[(GC1)]
  \item $\alpha(y)$;
  \item $\gamma(|\sigma_{T_y}(x)|)$ and $\sigma_{T_y}(x)$;
  \item $\delta_{T_y}(x)$ and $\delta_{T_{y+1}}(x)$ (where $\delta_T$ is the function  introduced after \obsref{predecessor-encoding});
  \item $\nu_y(x)$; and
  \item an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$.  (Note that some of these 8 vertices may not even be present in $G$ in which case the resulting bit is set to 0 since the edge is not present in $G$.)
\end{enumerate}
The two major components of this label are $\alpha(y)$ (GC1) and $\sigma_{T_y}(x)$ (GC2) which, together have length $\log n + O(k+k^{-1}\log n+\log\log n)$. For the remaining components, (GC3) has size $O(\log\log n)$, (GC4) has size $O(k\log\log n)$, and (GC5) has size $O(1)$.  Thus, the total length of each label is $\log n+ O(k\log\log n + k^{-1}\log n)$.  

\subsection{Adjacency Testing}

Given the labels of $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ we can test if they are adjacent as follows: Using \lemref{row-code} with $\alpha(y_1)$ and $\alpha(y_2)$ (GC1), determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case we immediately conclude that $v_1$ and $v_2$ are not adjacent in $G$ since they are not adjacent even in $H\boxtimes P$. %since $y_1\neq y_2$ and $y_1y_2\not\in E(P_1)$.  
  
  \item $y_1=y_2$: In this case, let $y:=y_1=y_2$.
  If the two bitstrings $\sigma_{T_y}(x_1)$, $\sigma_{T_y}(x_2)$ are the same, 
  we conclude that $x_1=x_2$ and $y_1=y_2$, so $v_1=v_2$ and we should output that they are not adjacent.
  Otherwise, 
  lexicographically compare $\sigma_{T_y}(x_1)$ and $\sigma_{T_y}(x_2)$. 
  Without loss of generality, $\sigma_{T_y}(x_1)$ is smaller than $\sigma_{T_y}(x_2)$. 
  Therefore, $x_1<x_2$. 
  Using $\sigma_{T_y}(x_2)$ and $\delta_{T_y}(x_2)$, compute $\sigma_{T_y}(x_2-1)$.  If $\sigma_{T_y}(x_2-1)\neq \sigma_{T_y}(x_1)$, then immediately conclude that $v_1$ and $v_2$ are not adjacent in $G$, since they are not adjacent even in $H\boxtimes P$.  Otherwise, we know that 
  $v_1=(x_2-1,y)$ and $v_2=(x_2,y)$ are adjacent in $H\boxtimes P$.
  Now we use the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine if $v_1$ and $v_2$ are adjacent in $G$.
  
  \item $y_1=y_2-1$: 
  In this case, use $\sigma_{T_{y_1}}(x_1)$ and $\nu_{y_1}(x_1)$ to compute $\sigma_{T_{y_2}}(x_1)$. 
  Now let $y:=y_2$, 
  If the two bitstrings $\sigma_{T_y}(x_1)$, $\sigma_{T_y}(x_2)$ are the same, 
  we conclude that $x_1=x_2$. Thus $v_1=(x_1,y-1)$ and $v_2=(x_1,y)$ are adjacent in $H \boxtimes P$.
  Now we look up the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine 
  if $v_1$ and $v_2$ are adjacent in $G$.
  Otherwise, lexicographically compare $\sigma_{T_y}(x_1)$ and $\sigma_{T_y}(x_2)$. 
  If $\sigma_{T_y}(x_1)$ is smaller than $\sigma_{T_y}(x_2)$, then we conclude that $x_1<x_2$.
  Using $\sigma_{T_y}(x_2)$ and $\delta_{T_y}(x_2)$, compute $\sigma_{T_y}(x_2-1)$.  
  If $\sigma_{T_y}(x_2-1)\neq \sigma_{T_y}(x_1)$, then immediately conclude that $v_1$ and $v_2$ are not adjacent in $G$, since they are not adjacent even in $H\boxtimes P$.  Otherwise, we know that 
  $v_1=(x_2-1,y-1)$ and $v_2=(x_2,y)$ are adjacent in $H\boxtimes P$.
  Now we use the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine if $v_1$ and $v_2$ are adjacent in $G$.
  If $\sigma_{T_y}(x_1)$ is larger than $\sigma_{T_y}(x_2)$, then we conclude that $x_1>x_2$.
  Using $\sigma_{T_y}(x_1)$ and $\delta_{T_y}(x_1)$, compute $\sigma_{T_y}(x_1-1)$ and procees as in the previous case. 
  Note here that it is important that part (GC3) of the label for $v_1=(x_1,y_1)$ contains $\delta_{T_{y_1+1}}(x_1)=\delta_{T_{y}}(x_1)$.
  
  \item $y_2=y_1-1$: In this case, use $\sigma_{T_{y_2}}(x_2)$ and $\nu_{y_2}(x_2)$ to compute $\sigma_{T_{y_1}}(x_2)$.  Now proceed as in the previous case.
\end{enumerate}

This establishes our first result:

\begin{thm}\thmlabel{pxp}
  The family $\mathcal{G}$ of $n$-vertex subgraphs of a strong product $P\boxtimes P$ where $P$ is a path has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

\begin{rem}
  The $o(\log n)$ term in the label length of \thmref{pxp} is $O(k\log\log n + k^{-1}\log n)$.  An asymptotically optimal choice of $k$ is therefore $k=\left\lceil\sqrt{\log n\log\log n}\right\rceil$, yielding labels of length $\log n + O\left(\sqrt{\log n\log\log n}\right)$.
\end{rem}


\section{Subgraphs of $H\boxtimes P$}
\seclabel{hxp}

In this section we describe adjacency labelling schemes for graphs $G$ that are subgraphs of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,2,\ldots,h$ is a path.  

% Our strategy is similar the approach taken in the previous section.
% For each $y\in\{1,\ldots,h\}$ we define $L_y=\{x: (x,y)\in V(G)\}$ and we will build a labelling scheme for the induced graph $H[V_y]$ where $V_y\supseteq L_{y\pm 1}$ that is based on a binary tree $T_y$ and such that the labels in this scheme have length $\log|T_y|+o(\log n)$.  In addition to this, we will use \lemref{row-code} to give each vertex $(x,y)\in V(G)$ a \emph{row label} of length $\log n - \log|T_y|+o(\log n)$.

\subsection{A Labelling Scheme for $t$-Trees}

We begin by describing a labelling scheme for $t$-trees that, like our labelling scheme for paths, is based on a binary search tree.  The ideas behind this scheme are not new; this is essentially the labelling scheme for $t$-trees described by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  However, we present these ideas in a manner that makes it natural to generalize the results of \secref{pxp}.

\subsubsection{$t$-Trees}

A graph $H$ is a \emph{$t$-tree} if $H$ is a clique on $t$ vertices or if $H$ contains a vertex $v$ of degree $t$ whose neighbours form a clique and $H-v$ is a $t$-tree.  

Note that the recursive definition of $t$-trees implies that there is a vertex ordering $v_1,\ldots,v_{m}$ of $V(H)$ such that $v_1,\ldots,v_t$ form a clique and, for each $i\in\{t+1,\ldots,m\}$, $C_H(v_i):=N_H[v_i]\cap \{v_1,\ldots,v_{i}\}$ is a clique of size $t+1$.  We call $C_H(v_i)$ the \emph{family clique} of $v_i$ and $C_H(v_i)\setminus\{v_i\}$ the \emph{parent clique} of $v_i$.  The order $v_1,\ldots,v_m$ is called a \emph{construction order} for $H$.

The order $v_1,\ldots,v_m$ (in particular, the fact that each $v_i$ has at most $t$ neighbours among $v_1,\ldots,v_{i-1}$) implies that $V(H)$ has a proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$.  When such a colouring of $H$ is given then, for each $i\in\{t+1,\ldots,m\}$ and each $j\in\{1,\ldots,t+1\}$ the \emph{$j$-parent} $p_j(v_i)$ of $v_i$ is the unique element $p\in C_H(v_i)$ with $\varphi(p)=j$.  Note that $v_i$ is the $j$-parent of itself for exactly one $j\in\{1,\ldots,t+1\}$.

\subsubsection{Interval Graphs}

For real numbers $a\le b$, let $[a,b]:=\{ x\in\R: a\le x\le b\}$, and let
$\mathbb{I}:=\{[a,b]: a,b\in\R,\, a\le b\}$ denote the set of closed real intervals.  For a finite set $S\subset\mathbb{I}$ of intervals, the \emph{interval intersection graph} $G_S$ is the graph with vertex set $V(G_S):=S$ and in which the edge $vw\in E(G_S)$ if and only if $v\cap w\neq \emptyset$.  The \emph{thickness} $\omega(G_S)$ of $S$ is the size of its largest clique, which (by Helly's Theorem) is equal to $\max_{x\in\R}|\{v\in V(G_S):x\in v\}|$.  

% By Dilworth's Theorem (applied to the poset $(V(I),\prec)$ where $[a,b]\prec [c,d]$ iff $b<c$), the chromatic number $\chi(I)$ of $I$ is equal to its thickness, i.e., $\chi(I)=\omega(I)$.  

The following well-known result states that every $n$-vertex $t$-tree is the subgraph of an interval graph with thickness $O(t\log n)$:\footnote{The specific value $\log_3 (2n+1)$ in \lemref{interval-representation} is obtained by applying a result of Scheffler \cite{scheffler:optimal} on the tree underlying the width-$t$ tree decomposition of $H$.}

\begin{lem}\lemlabel{interval-representation}
  For every $n$-vertex $t$-tree $H$, there exists a mapping $f:V(H)\to\mathbb{I}$, such that the interval intersection graph $G_S$ with $S:=\{f(v):v\in V(H)\}$ has thickness at most $(t+1)\log_3(2n+1)$ and, for every $vw\in E(H)$, $f(v)\cap f(w)\neq\emptyset$.  
  
  Furthermore, for every proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$ of $H$, there exists a proper colouring $\varphi':V(G_S)\to\{1,\ldots,\lfloor\log_3(2n+1)\rfloor\}\times\{1,\ldots,t+1\}$ where, for each $v\in V(H)$, $\varphi'(f(v))=(j,\varphi(v))$ for some $j\in\{1,\ldots,\lfloor\log_3(2n+1)\rfloor\}$.
\end{lem}

In light of \lemref{interval-representation} we will not distinguish between a vertex $v\in V(H)$ and the interval $f(v)$.  That is, we will treat the nodes of every $t$-tree as intervals that satisfy the conditions of \lemref{interval-representation}.

A point $x\in\R$ \emph{stabs} an interval $[a,b]$ if $\{x\}\cap [a,b]=\{x\}$. A finite set $X\subset\R^2$ of points \emph{stabs} a set $S\subset\mathbb{I}$ of intervals if $X\cap [a,b]\neq\emptyset$ for every $[a,b]\in S$.

\begin{lem}\lemlabel{common-ancestor}
  Let $S\subset\mathbb{I}$ be a set of intervals, let $X\subset\R$ be a set of points that stabs $S$, let $T$ be a binary search tree with $V(T):=X$, let $[a,b]\in S$, and let $x$ be the lowest common $T$-ancestor of $X\cap [a,b]$.  Then $x\in [a,b]$.
\end{lem}

\begin{proof}
  Since $x$ is the lowest common $T$-ancestor of $X\cap[a,b]$, either $x\in X\cap[a,b]$, in which case there is nothing prove, or there is some pair $x_1,x_2\in X\cap[a,b]$ such that $x_1$ is in the subtree of $T$ rooted at the left child of $x$ and $x_2$ is in the subtree of $T$ rooted at the right child of $x$.  By the binary search tree property, $x_1<x<x_2$. But $x_1,x_2 \in [a,b]$, so $a\le x_1<x<x_2\le b$, so $x\in [a,b]$.  
\end{proof}

\subsubsection{The Labelling Scheme}
\seclabel{t-tree-labelling}

We can use \lemref{common-ancestor} to create a labelling scheme for a $t$-tree based on any binary search tree containing a stabbing set.  Let $H$ be a $t$-tree whose vertex set $V(H):=S$ consists of the intervals described by \lemref{interval-representation}, let $v_1,\ldots,v_m$ be a construction order for $H$, let $\varphi:V(H)\to\{1,\ldots,t+1\}$ be a proper colouring of $H$, and let $\varphi':V(H)\to\{1,\ldots,\lceil\log_{3/2} m\rceil\}\times\{1,\ldots,t+1\}$ be the extension of $\varphi$ to a proper colouring of $G_S$ described in \lemref{interval-representation}.

Let $X\subset\R$ be any set of points that stab $S$, let $T$ be a binary search tree with $V(T):=X$.
% , and let $\varphi:V(H)\to\{1,2,\ldots,\lfloor t\log n\rfloor\}$ be a proper colouring of the interval graph with vertex set $S$.
For each vertex $v:=[a_v,b_v]\in V(H)$, let $x_T(v)$ denote the lowest common $T$-ancestor of $V(T)\cap [a_v,b_v]$ (see \figref{x}).  Note that \lemref{common-ancestor} can be rephrased as $x_T(v)\in [a_v,b_v]$. For any subset $C\subseteq V(H)$, let $x_T(C):=\{x_T(x):x\in C\}$.  

\begin{figure}
  \begin{center}
    \includegraphics{figs/x}
  \end{center}
  \caption{The definition of $x_T(v)$.}
  \figlabel{x}
\end{figure}

\begin{lem}\lemlabel{one-path}
  For any $v\in V(H)$ with family clique $C_H(v)$, the set of nodes $x_T(C_H(v))$ are all contained a single root-to-leaf path in $T$.
\end{lem}

\begin{proof}
  Suppose for the sake of contradiction that this is not true, so there are $x_1,x_2\in x_T(C_H(v))$ neither of which is an ancestor of the other.  Then consider the lowest common ancestor $x$ of $x_1$ and $x_2$ in $T$.  Assume without loss of generality that $x_1$ is in the subtree of $T$ rooted at $x$'s left child and $x_2$ is in the subtree of $T$ rooted at $x$'s right child, so $x_1<x<x_2$. The node $x_1:=x_T(v_1)$ for some $v_1:=[a_1,b_1]\in C_H(v)$ and $x_2=x_T(v_2)$ for some $v_2:=[a_2,b_2]\in C_H(v)$.  Since $v_1$ and $v_2$ are both in the family clique $C_H(v)$, the vertices $v_1$ and $v_2$ are adjacent in $H$, and therefore $[a_1,b_1]\cap[a_2,b_2]\neq\emptyset$.  This implies that $x\in [a_i,b_i]$ for at least one $i\in\{1,2\}$.  But this is a contradiction since $x_T(v_i)$ is supposed to be the lowest common ancestor of $[a_i,b_i]\cap X$.
\end{proof}

The following observation shows that a vertex $v$ of $H$ is uniquely identified by $x_T(v)$ and $\varphi'(v)$.

\begin{obs}\obslabel{unique-id}
    For any two distinct vertices $v,w\in V(H)$, $x_T(v)\neq x_T(w)$ or $\varphi'(v)\neq\varphi'(w)$.  Consequently, $\sigma_T(x_T(v))\neq \sigma_T(x_T(w))$ or $\varphi'(v)\neq\varphi'(w)$. 
\end{obs}

\begin{proof}
  If $x_T(v)=x_T(w)=x$, the intervals $v=[a_v,b_v]$ and $w=[a_w,b_w]$ each contain $x$, so $vw\in E(G_S)$.  Therefore $\varphi'(v)\neq\varphi'(w)$ since $\varphi'$ is a proper colouring of $G_S$.  The second, equivalent, statement of the observation is immediate from the fact that the $\sigma_T: V(T)\to\{0,1\}^*$ is injective, so $\sigma_T(x)$ uniquely identifies $x$.
\end{proof}

For each vertex $v\in V(H)$, let $P_T(v)$ denote the path in $T$ that begins at the root of $T$ and ends at the node in $x_T(C_H(v))$ of maximum depth.  By \lemref{one-path}, $P_T(v)$ is well defined and contains every node in $x_T(C_H(v))$.  Let $\sigma_T(v):=\sigma_T(z)$ where $z$ is the node of maximum depth in $x_T(C_H(v))$.  The label for a vertex $v\in V(H)$ consists of the following (we ignore any integers, such as $t$, $|\sigma_T(v)|$, and $\lceil\log_{3/2} m\rceil$, that can be encoded using \lemref{elias}):

\begin{enumerate}[(TC1)]
  \item $\sigma_T(v)$;
  \item $d_T(x_T(p_j(v)))$ for each $j\in\{1,\ldots,t+1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; and
  \item $\varphi'(v)$.
\end{enumerate}

Given the labels of two vertices $v,w\in V(H)$, we test if $v$ and $w$ are adjacent as follows:
\begin{enumerate}[({A}1)]
  \item If the labels of $v$ and $w$ are identical then $v=w$, so return false.
  
  \item (uniquely identify $v$) From (TC4) extract $j:=\varphi(v)$ (which is contained in $\varphi'(v)$).  From (TC2) extract $d:=d_T(x_T(p_j(v)))$. Take the length-$d$ prefix of $\sigma_T(v)$ to get $\sigma_T(x_T(v))$.

  \item (check if $v$ is the $j$-parent of $w$) Extract $d:=d_T(x_T(p_j(w)))$ and take the length-$d$ prefix of $\sigma_T(w)$ to get $\sigma_T(x_T(p_j(w)))$.  If $\sigma_T(x_T(v))=\sigma_T(x_T(p_j(w)))$ and $\varphi'(v)=\varphi'(p_j(w))$ then, by \obsref{unique-id}, $v$ is the $j$-parent of $w$ and $vw\in E(H)$, so return true.
  
  \item[(A4,A5)] Repeat (A2) and (A3) with the roles of $v$ and $w$ reversed.
  
  \item[(A6)] Return false
\end{enumerate}

The correctness of this adjacency test can be seen as follows:
\begin{itemize}
  \item Given the labels of $v$ and $w$ we can recover $\sigma_T(x_T(v))$, $\varphi'(v)$, $\sigma_T(x_T(w))$, and $\varphi'(w)$ so, by \obsref{unique-id}, the label of $v$ and the label of $w$ are identical if and only if $v=w$, so the negative result in (A1) is never incorrect;
  \item from \obsref{unique-id}, positive results in (A3) and (A5) are never incorrect; and 
  \item for every $vw\in E(H)$, there exists a $j\in\{1,\ldots,t+1\}$ such that $v$ is the $j$-parent of $w$ or $w$ is the $j$-parent of $v$, so the negative result in (A6) is never incorrect.    
\end{itemize}
In fact, this labelling scheme proves the following slightly stronger result:

\begin{lem}\lemlabel{t-tree-labelling}
  Let $H$, $S$, $X$, and $T$ be defined as above.  There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=h(T) + O(t(\log t + \log h(T)))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
  \[
      \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{lem}

\begin{proof}
  Most of the details of this labelling are described above, though we have thus far ignored the length of the labels, which we analyze now.
  
  Part (TC1) of each label has length $|\sigma_T(v)|\le h(T)$.  For each $x\in V(T)$, $d_T(x)\le h(T)$, so Part~(TC2) of each label requires $O(t\log h(T))$ bits.  Part~(TC3) of each label requires $O(t\log t + t\log h(T))$ bits.  Part~(TC4) of each label requires $O(\log t + \log h(T))$ bits.
\end{proof}

% Taking $X$ to be a minimal set that stabs $S$ (so $|X|\le |S|=m$) and taking $T$ to be a perfectly balanced binary search tree (so $h(T)\le \log|X|\le\log m$) we obtain the following corollary.
% 
% \begin{cor}\corlabel{t-tree-labelling}
%   There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that, for any $m$-vertex $t$-tree $H$ there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=\log m + O(t(\log t + \log\log m))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
%   \[
%       \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
%       0 & \text{if $v=w$} \\
%       -j & \text{if $v$ is the $j$-parent of $w$} \\
%       j & \text{if $w$ is the $j$-parent of $v$} \\
%       \perp & \text{otherwise.}
%     \end{cases}
%   \]
% \end{cor}

\subsection{Interval Transition Labels}

% We point out again that the result in \corref{t-tree-labelling} is not new and the labelling scheme is just a reformulation of the one given by Gavoille and Labourel \cite{gavoille.labourel:shorter} that happens to be convenient for what we are going to do next. Most important for us is that the largest part of the codes come from paths in the binary search tree $T$ that contains the stabbing set $X$.  

We now show that the solution presented in \secref{pxp} generalizes to the current setting of subgraphs of $H\boxtimes P$.  The only additional complication comes from the fact that each node $x$ in the binary search tree $T$ is equipped with a set $B_x:=\{v\in V(H):x_T(v)=x\}$ of intervals.  Any structural changes that we make to $T$ may result in changes to $B_x$, which result in changes to the labels for the vertices of $H$ that enter or leave $B_x$.  We must show that these changes can be encoded using few bits.  We now proceed.

Let $G$ be an $n$-vertex subgraph of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,\ldots,h$ is a path. For each $y\in\{1,\ldots,h\}$, let $S_y=\{v\in V(H): (v,y)\in V(G)\}$ and let $S^-_y=\bigcup_{j=1}^{t+1}\{p_j(v):v\in S_y\}$.  Note that $|S^-_y|\le (t+1)|S_y|$. For each $y\in\{1,\ldots,h\}$, let $X_y\subset\R$ be the set of all endpoints of intervals in $S^-_y\cup S^-_{y-1}$.

By \lemref{bulk-tree-height}, \lemref{chunked-bulk-trees} and  \lemref{node-transitions} there is a bulk tree sequence $T_1,\ldots,T_h$ with parameter $k=\lceil \sqrt{\log n \log \log n}\rceil$ where, for each $y\in\{1,\ldots,h\}$, 
\begin{enumerate}[(PR1)]
  \item $V(T_y)\supseteq X_y$;
  \item $h(T_y)= \log |T_y| + O(k+k^{-1}\log |T_y|)= \log |T_y| + o(\log n)$;
  \item $W:=\sum_{y=1}^h |T_y|= O(n)$; and
  \item There is a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for every $x\in V(T_y)\cap V(T_{y+1})$, there is a string $\nu_y(x)$ such that $B(\sigma_{T_y}(x),\nu_y(x))=\sigma_{T_{y+1}(x)}$ and $|\nu_y(x)|=O(k\log\log n)=o(\log n)$.
\end{enumerate}

% As before, we can use \lemref{row-code} to assign each vertex $v=(x,y)\in V(G)$ a label $\alpha(v)$ of length $\log n - \log|T_y| + o(\log n)$. For any two nodes $v_1=(x_1,y_1)\in V(G)$ and $v_2=(x_2,y_2)$, $\alpha(v_1)$ and $\alpha(v_2)$ are sufficient to determine if $|y_1-y_2|\le 1$ and, if so, the actual value of $y_1-y_2$.
% 
% Now, for each $y\in\{1,\ldots,h\}$, $V(T_y)$ stabs $S^-_y\cup S^-_{y-1}$, so we can use $T_y$ to create a labelling scheme $\tau_y:(S^-_y\cup S^-_{y-1})\to\{0,1\}^*$ for the induced graph $H[S^-_y\cup S^-_{y-1}]$ as described in \secref{t-tree-labelling} leading to \lemref{t-tree-labelling} where the labels have length $h(T_y) + o(\log n)=\log|T_y|+o(\log n)$.  
% 
% For each $v\in S^-_y$, the label $\tau_y(v)$ has four parts (TC1)--(TC4).  Parts~(TC3) and (TC4) are completely determined by $H$ and $v$ and are independent of $T_y$.  In particular parts (TC3) and (TC4) of $\tau_{y_1}(v)$ and $\tau_{y_2}(v)$ are the same for any $y_1$ and $y_2$ such that $(v,y_1),(v,y_2)\in V(G)$.  
% 
% Part~(TC2) of $\tau_y(v)$, however depends very much on the tree $T_y$.  Luckily, Part~(TC2) is small: It has size $o(\log n)$, so the label of $(v,y)$ can include Part~(TC2) for $\tau_{y}(v)$ and $\tau_{y+1}(v)$.
% 
% The difficulty comes from Part~(TC1) of $\tau_y(v)$.

The following lemma, which is analogous to \lemref{node-transitions} is the last piece of the puzzle needed for an adjacency labelling scheme for subgraphs of $H\boxtimes P$. Recall that the notation $\sigma_T(v)$ and $P_T(v)$, used below in the context of $t$-trees, has been introduced shortly after \obsref{unique-id}.

\begin{lem}\lemlabel{interval-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to \{0,1\}^*$ such that, for any 
  $H$, $G$, $S_1,\ldots,S_h$, $X_1,\ldots,X_h$, $T_1,\ldots,T_h$ defined as above, for each $y\in\{1,\ldots,h-1\}$ and each $v\in S_y \cup S_{y+1}$, there exists $\mu_y(v)\in\{0,1\}^*$ with $|\mu_y(v)|= O(k\log\log n)=o(\log n)$ such that $B(\sigma_{T_y}(v), \mu_y(v))=\sigma_{T_{y+1}}(v)$.
\end{lem}

\begin{proof}
  First we note that, if $v\in S_y\cup S_{y+1}$, then the endpoints of $v$ are in $X_y\subseteq V(T_y)$ and in $X_{y+1}\subseteq V(T_{y+1})$.
  As in the proof of \lemref{node-transitions}, we must dig into the three bulk tree operations that transform $T_y$ into $T_{y+1}$. These are rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion of $D_y$, which takes $T_y''$ onto $T_{y+1}$.
  
  The bulk insertion that converts $T_y'$ into $T_y''$ is the simplest to handle.  For any $v\in S_y$, $P_{T_y'}(v)$ is the path from the root of $T_y'$ to the deepest node in $x_{T_y'}(C_H(v))$.  Furthermore, for each $w=[a_w,b_w]\in C_H(v)$, $x_{T_y'}(w)$ is the element of $w\cap V(T_y')$ that is closest to the root of $T_y'$. Since $T_y''$ is a supergraph of $T_y'$ obtained by adding small subtrees at the external nodes of $T_y'$, $x_{T_y''}(w)=x_{T_y'}(w)$ for each $w\in C_H(v)$.  Therefore $P_{T_y''}(w)=P_{T'}(w)$ and $\sigma_{T_y''}(w)=\sigma_{T'}(w)$ for each $w\in C_H(v)$, so $\sigma_{T_y''}(v)=\sigma_{T_y'}(v)$ for each $v\in S_y$.
  
  Next we consider the bulk deletion that converts $T_y''$ into $T_{y+1}$.  A bulk deletion consists of a sequence of individual deletions. Consider one such deletion and let $T$ and $\tilde{T}$ denote the tree before and after the deletion, respectively.  
  
  \begin{clm}\clmlabel{deletion-ancestor}
    For any $v=[a_v,b_v]\in S_y$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))$ is a prefix of $\sigma_T(x_T(v))$.   
  \end{clm}
  
  \begin{proof}[Proof of \clmref{deletion-ancestor}]  
    See \figref{deletion-t-tree}.  At a global level, the deletion of a value $x$ from $T$ involves finding a sequence of consecutive values $x_0<x_1<\cdots<x_r$ or $x_0>x_1>\cdots>x_r$ where $x=x_0$, $x_r$ is a leaf and $x_{i-1}$ is a $T$-ancestor of $x_{i}$ for each $i\in\{1,\ldots,r\}$.  The leaf containing $x_r$ is deleted and, for each $i\in\{0,\ldots,r-1\}$, the (value in the) node $x_i$ is replaced with (the value in) node $x_{i+1}$.  

    \begin{figure}
      \begin{center}
        \includegraphics{figs/deletion-t-tree-1}\\[1ex]
        $\Downarrow$\\[1ex]   
        \includegraphics{figs/deletion-t-tree-2}   
      \end{center}
      \caption{The effect of a single deletion on $x_T(v)$.}
      \figlabel{deletion-t-tree}
    \end{figure}
    
    If $x_T(v)=x_0$ then recall that $v\in S_y\subset S^-_y$ and $X_{y+1}\supseteq V(T_{y+1})$ contains both endpoints of each segment in $S^-_{y+1}\cup S^-_y$.  Therefore $a_v,b_v\in V(T_{y+1})$.  Therefore $r\ge 1$ and $x_1\in [a_v,b_v]$ so $x_{\tilde{T}}(v)=x_1$ and $\sigma_{\tilde{T}}(v)=\sigma_T(v)$.
    
    If $x_T(v)=x_i$ for some $i\in\{1,\ldots,r\}$, then $x_{\tilde{T}}(v)=x_i$ (see the interval $v_1$ in \figref{deletion-t-tree}) and $\sigma_{\tilde{T}}(x_i)=\sigma_{T}(x_{i-1})$.  Since $x_{i-1}$ is a $T$-ancestor of $x_i$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_{\tilde{T}}(x_i)$ is a prefix of $\sigma_{T}(x_{T}(x))$, as required.
    
    Finally, if $x_T(v)\neq x_i$ for any $i\in\{0,\ldots,r\}$ and $x_T(v)\neq x_{\tilde{T}}(v)$, then the only possibility is that $x_{\tilde{T}}(v)=x_i$ for some $x_i\in [a_v,b_v]$ (see the interval $v_2$ in \figref{deletion-t-tree}).  This can only happen if $x_i$ is not a $T$-ancestor of $x_T(v)$, but $x_i$ is a $\tilde{T}$ ancestor of $x_T(v)$.  By \lemref{common-ancestor}, $x_i$ is a $T$-descendant of $x_T(v)$.  Since $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$, $x_{i-1}$ is a $T$-ancestor of $x_T(v)$.  Therefore $\sigma_{\tilde{T}}(v)=\sigma_{\tilde{T}}(x_i)=\sigma_T(x_{i-1})$ is a prefix of $\sigma_T(x_T(v))$, as required.  This completes the proof of \clmref{deletion-ancestor}.    
  \end{proof}
  
  Let $a\preceq b$ denote that $a$ is a prefix of $b$.
  Since a bulk deletion is implemented as a sequence of individual deletions,
  \begin{align*}
    \sigma_{T_y''}(v) 
      & = \sigma_{T_y''}(x_{T_y''}(w)) & \text{(for some $w\in C_H(v)$)} \\
      & \preceq \sigma_{T_y'}(x_{T_y'}(w)) & \text{(by \clmref{deletion-ancestor})} \\
      & \preceq \sigma_{T_y'}(v) \enspace . & \text{(by \lemref{one-path})}
  \end{align*} 
  Therefore, by including $|\sigma_{T_y''}(v)|$ in $\mu_y(v)$ we can derive $\sigma_{T_y''}(v)$ from $\sigma_{T_y'}(v)$.  This requires only $O(\log h({T_y'}))=O(\log\log n)$ bits.
  
  Finally, we consider the rebalancing operation that takes $T_y$ onto $T_y'$ by calling $\textsc{BulkBalance}(\theta)$, which calls $\textsc{Balance}(x)$ on each depth-$\theta$ node $x$ of $T_y$ to restructure the subtree of $T_y$ rooted at $x$ (refer to \figref{rebalance-t-tree}). Therefore, for any $v\in S_y$, and any $\theta'\in\{0,\ldots,\theta\}$, the length-$\theta'$ prefix of $\sigma_{T_y}(v)$ and length-$\theta'$ prefix of $\sigma_{T_y'}(v)$ are the same.  By including the value of $\theta$ in $\mu_y(v)$, we then only need to consider the effect of the call to $\textsc{Balance}(x)$ where $x$ is the unique depth-$\theta$ node of $T_y$ contained in $P_{T_y}(v)$ (if any).
  
  \begin{figure}
    \begin{center}
      \includegraphics{figs/rebalance-t-tree}
    \end{center}
    \caption{Only the call to $\textsc{Balance}(x)$ on a node $x\in V(P_{T_2}(v))$ affects $\sigma_{T_2'}(v)$.}
    \figlabel{rebalance-t-tree}
  \end{figure}
  
  Let $T_*$ be the subtree of $T_y$ rooted at $x$ and let $T_*'$ be the new tree obtained after calling $\textsc{Balance}(x)$ on the root, $x$, of $T_*$. (So $T_*$ is a subtree of $T_y$ and $T_*'$ is a subtree of $T_y'$.)
  The transition code $\mu_y(v)$ will contain enough information to recover $\sigma_{T_y*'}(v)$ from $\sigma_{T_y}(v)$. 
  
  Now, $\textsc{Balance}(x)$ identifies two special node sets $Z$ and $X$ that it turns into a perfectly balanced binary search tree $\hat{T}_0$.  Eventually, $\hat{T}_0$ will become a subgraph of $T_*'$ that contains the root of $T_*'$.   In particular, every node in $V(T_*')$ has a $T_*'$-ancestor in $Z\cup X$.
  
  For any $v\in S_y$ such that $P_{T_y'}(v)$ ends at a vertex $z\in Z\cup X=V(\hat{T}_0)$, the problem is easy.  We include $\sigma_{\hat{T}_0}(z)$, which has length at most $h(T_0)\le k$, in $\mu_y(v)$, and this (along with $\theta$) is sufficient to recover $\sigma_{T_y'}(v)$ from $\sigma_{T_y}(v)$.

  Thus, we only need to consider those $v\in S_v$ such that $P_{T_y'}(v)$ ends a vertex $z\not\in Z\cup X$ with $d_{T_y}(z)>\theta$.    By definition,  $z=x_{T_y'}(w)$ for some $w=[a_w,b_w]\in C_H(v)$.  By \lemref{common-ancestor}, $z$ is the unique node of $P_{T_y'}(z)$ contained in $[a_w,b_w]$.  Therefore
  \begin{equation}  
    [a_w,b_w]\cap (Z\cup X)=\emptyset \enspace . \eqlabel{empty}
  \end{equation}
  
  For each such node $v$, $P_{T_y}(v)$ has vertices (including $z$) in common with exactly one tree $T_{i}$ in the forest $T_*-Z$.  Then $\textsc{Balance}(x)$ calls $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ on the subtree $T_{i}$.  This, in turn results in zero or more calls to $\textsc{Split}(x)$ for nodes $x\in V(T_{i})$. The following claim explains the effect of one individual call to $\textsc{Split}(x)$:
  
  \begin{clm}\clmlabel{x-switch}
    Let $S$ by a set of intervals, let $T$ be a binary search tree where $V(T)$ stabs $S$, and let $T_{<x}$ and $T_{>x}$ be the two trees resulting from calling $\textsc{Split}(x)$ on $T$ for some $x\in V(T)$.  Then, for each $w=[a_w,b_w]\in S$ exactly one of the following is true:
    \begin{compactenum}
      \item $a_w\le x\le b_w$; or
      \item $x< a_w$, in which case $x_{T_{>x}}(w)=x_T(w)$; or
      \item $b_w < x$, in which case $x_{T_{<x}}(w)=x_T(w)$.
    \end{compactenum}
  \end{clm}

  \begin{proof}
    That exactly one of the three cases applies is obvious.  Case~(1) has no specific requirements and Cases~(2) and (3) are symmetric, so we focus on Case~(2), so $x < a_w\le b_w$.
    
    By \lemref{common-ancestor}, $z=x_T(v)$ is the unique node $z\in V(T)$ such that $P_T(z)$ has exactly one node $z\in [a_w,b_w]$.  Now $P_{T_{>x}}(z)$ is obtained from $P_T(z)$ by deleting all values less than or equal to $x$. Therefore $P_{T_{>x}}(z)$ has exactly one node $z\in[a_w,b_w]$, so $z=x_{T_{>x}}(w)$.  This completes the proof of \clmref{x-switch}.
  \end{proof}
  
  From \clmref{x-switch}, we can conclude that $P_{T_y'}(v)=P_{T_y'}(x_{T_y}(w))$ for some $w\in C_H(v)$.  Indeed, by definition $x_{T_y'}(w)\not\in Z\cup X$. By \clmref{x-switch}, either $x_{T_y'}(w)=x_{T_y}(w)$ or at some point $\textsc{Split}(x)$ was called on some node $x\in[a_w,b_w]$.  But $\textsc{Split}(x)$ is only called on nodes $x\in X$ so, by \eqref{empty}, $x_{T_y'}(w)=x_{T_y}(w)$.
  
  Thus, for each $v\in L_y$ such that $x(v)\not\in Z\cup Y$, there exists some $w\in C_H(v)$ with $x_{T_y'}(w)=x_{T_y}(w)$ such that $P_{T_y'}(v)=P_{T_y'}(x_{T_y}(w)$, so $\sigma_{T_y'}(v)=\sigma_{T_y'}(x_{T_y}(w))$.  By \lemref{one-path}, $\sigma_{T_y}(x_{T_y}(w))$ is a prefix of $\sigma_{T_y}(v)$ and the length of this prefix can be included in $\mu_y(v)$, which makes it possible to recover $\sigma_{T_y}(x_{T_y}(w))$ from $\sigma_{T_y}(v)$ .  By \lemref{node-transitions}, there exists a function $B$ and a string $\nu_y(x_{T_y}(w))$ of length $O(k\log\log n)$ such that $B(\sigma_{T_y}(x_{T_y}(w)), \nu_y(x_{T_y}(w))) = \sigma_{T_y'}(x_{T_y}(w)) = \sigma_{T_y'}(v)$.
  
  Therefore, for any $v\in S_y$ there is a string $\mu_y(v)$ of length $O(k\log\log n)$ that satisfies the conditions of the lemma.
\end{proof}
  
\subsection{The Labels}

Summarizing, for any $n$-vertex subgraph $G$ of $H\boxtimes P$, each vertex $z=(v,y)\in V(G)$ has a label that contains the following information:

\begin{enumerate}[(PC1)]
  \item $\alpha(y)$ (given by \lemref{row-code});% of length $\log n-\log|T_y| + O(\log\log n)$;
  \item $\sigma_{T_y}(v)$; % of length $\log|T_y| + O(k+k^{-1}\log n)$;
  \item $d_{T_{y+b}}(x_{T_{y+b}}(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$ and $b\in\{-1,0,1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$;
  %\snote{L. I assume these $\varphi'$ should be replaced by $\tau$ of \lemref{t-tree-labelling}?}
  %\snote{Pat: No, just the colouring. $\tau_H(v)$ is the whole label.}
  \item $\varphi'(v)$;
  \item $\mu_y(v)$;
  \item $a(z)$.
\end{enumerate}
The only one of these quantities not yet defined is $a(z)$, which is a sequence of $3t$ bits that indicate which of the potential edges joining $z$ to elements of $\{(p_j(v),y+b): j\in\{1,\ldots,t+1\},\, b\in\{-1,0,1\}\}$ are actually present in $G$.

\subsection{Adjacency Testing}

Given the labels of $z_1:=(v_1,y_1)$ and $z_2:=(v_2,y_2)$ we test if $z_1z_2\in E(G)$ by first using $\alpha(y_1)$ and $\alpha(y_2)$ to determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|>1$: In this case $y_1\neq y_2$ and $y_1y_2\not\in P$, so $z_1z_2\not\in E(H\boxtimes P)$, so $z_1z_2\not\in E(G)$.

  \item $y_1=y_2$.  Let $y=y_1=y_2$.  In this case (PC2)--(PC4) contains $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ and we use this to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ also tell us that (without loss of generality) $x_1$ is the $j$-parent of $x_2$ in $H$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=1$: Let $y=y_1$ (so that $y_2=y+1$).  We use $\mu_y(v_1)$ and $\sigma_{T_y}(v_1)$ to compute $\sigma_{T_{y+1}}(v_1)$.  Now, $\sigma_{T_{y+1}}(v_1)$ and (PC3)--(PC4) contains $\tau_{y+1}(v_1)$ and (PC2)--(PC4) contains $\tau_{y+1}(v_2)$.  We use these to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y+1}(v_1)$ and $\tau_{y+1}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=-1$:  This case is symmetric to the preceding case, with the roles of $z_1$ and $z_2$ reversed.
\end{enumerate}

This completes the proof of our main result.

\begin{thm}\thmlabel{main-product}
  For every $t\in\N$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some $t$-tree $H$ and some path $P$ has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

\thmref{main} is an immediate consequence of \thmref{main-product} and \thmref{product-structure}. 

\section{Conclusion}
\seclabel{conclusion}

We conclude with a few remarks on the computational complexity of our labelling scheme.  Given an $n$-vertex planar graph $G$, finding an 8-tree $H$, a path $P$, and a mapping of $G$ into a subgraph of $H\boxtimes P$ can be done in $O(n^2)$ time \cite{dujmovic.joret.ea:planar}.  The process of computing the labels of $V(G)$ as described in \secref{pxp} and \secref{hxp} has a straightforward $O(n\log n)$ time implementation.  Thus, the adjacency labels described in \thmref{main} are computable in $O(n^2)$ time for $n$-vertex planar graphs.

The adjacency testing function is quite simple. Even without using word parallelism, this function is straightforward to implement in $O(tk\log n)$ time.  Note that this already allows a tradeoff between the (lower order term in the) code length and the complexity of adjacency testing.
In the case of planar graphs $t=8$ and, if we use the shortest possible code length, $k=O(\sqrt{\log n\log\log n})$, so the adjacency testing procedure can be implemented in $O(\log^{3/2} n\sqrt{\log\log n})$ time. 

In a realistic $\log n$-bit word RAM model of computation with bitwise logical operations, bitwise shift operations, and a most-significant-bit\footnote{The only purpose of the most-significant-bit operation is allow decoding of the Elias $\gamma$ code in constant time.} operation the adjacency test, as described, can be implemented in $O(k)$ time.  The bottleneck in such an implementation is the need to evaluate the function $B$ described in \lemref{interval-transitions} and the bottleneck there is the need to evaluate the function $B$ described in \lemref{node-transitions}.  The bottleneck in evaluating this latter function $B$ is the fact that, up to $k+1$ times, this replaces a prefix of $\sigma_T(x)$ with a string in $\Pi$.  The end result of all of these replacements is that a prefix of $\sigma_T(x)$ is replaced with a bitstring of length $O(\log n)$ that has a run-length encoding of size $O(k\log\log n)$.  This is, of course, easily implemented in $O(k)$ time, but perhaps a faster implementation is possible.

% \snote{If we want to bother, we could probably do this in $O(\log n)$ time.}
The current result leaves two obvious directions for future work:
\begin{enumerate}
  \item The precise length of the labels in \thmref{main} is $\log n + O(\sqrt{\log n\log\log n})$.  The only known lower bound is $\log n + \Omega(1)$.  Closing the gap in the lower-order term remains an open problem.
  
  \item \thmref{main-product} implies a $(1+o(1))\log n$-bit labelling schemes for any family of graphs that excludes an apex graph as a minor.  Can this be extended to any $K_t$-minor free family of graphs?
\end{enumerate}

\section*{Acknowledgement}

Part of this research was conducted during the Eighth Workshop on Geometry and Graphs, held at the Bellairs Research Institute, January~31--February~7, 2020.  We are grateful to the organizers and participants for providing a stimulating research environment.  The authors are particularly grateful to David Wood for helpful discussions.

  
\bibliographystyle{plainurl}
\bibliography{labelling}

\newpage
\appendix

\section{Proof of \lemref{fractional}}
\applabel{fractional-proof}


\begin{proof}[Proof of \lemref{fractional}]
  $V_1,\ldots,V_{h}$ are constructed incrementally by a procedure $\textsc{BuildV}(S_1,\ldots,S_h)$ that makes use of a recursive subroutine $\textsc{Add}(x, y)$.  In the following code, $V_0$ and $V_{h+1}$ act as sentinels whose only purpose to eliminate distracting boundary cases.
  
  \noindent$\textsc{BuildV}(S_1,\ldots,S_h)$:
  \begin{algorithmic}[1]
    \STATE{$V_0\gets V_{h+1}\gets\Z$}
    \STATE{$V_y\gets\emptyset$ for each $y\in\{1,\ldots,h\}$}
    \FOR{$x= 1,\ldots,m$}
      \FOR{$y = 1,\ldots,h$}
        \IF{$x\in S_y\setminus V_y$}
          \STATE{$\mathrm{add}(x, y)$}
        \ENDIF
      \ENDFOR
    \ENDFOR
 % (L. to be removed)   \STATE{$V_y\gets V_y\setminus \{0\}$ for each $y\in\{1,\ldots,h\}$}
  \end{algorithmic}
  
  \noindent$\textsc{Add}(x, y)$:
  \begin{algorithmic}[1]
    \IF{$y\in\{1,\ldots,h\}$}
      \STATE{$V_y\gets V_y\cup\{x\}$}
      \IF{$|V_y|\ge 4$}      
        \STATE{let $x_{-1}>x_{-2}>\cdots>x_{-4}$ be the 4 largest elements in $V_y$ (so $x_{-1}=x$)}
        \IF{$\{x_{-1},\ldots,x_{-4}\}\cap V_{y-1}=\emptyset$ or
            $\{x_{-1},\ldots,x_{-4}\}\cap V_{y+1}=\emptyset$}
            \STATE{$\textsc{Add}(x,y-1)$}
            \STATE{$\textsc{Add}(x,y+1)$}
        \ENDIF
      \ENDIF
    \ENDIF
  \end{algorithmic}

  % % \snote{L. Is $x_{-5}$ really necessary here?}
  % % \pnote{Pat: I suppose not.  I was worried about a boundary condition.  Let's see:  $V_1=\{0\}$, $V_2=\{0,1,2,3,4\}$ seems not need $y_{-5}$.  In fact, maybe we don't need to include $0$ either.  It should be enough to require $|V_y|\ge 4$ in Line~3 and then work only with $y_{-1},\ldots,y_{-4}$.
  % 
  % Summary:
  % \begin{compactenum}
  %   \item The text about including 0 should be removed.
  %   \item Line~2 of BuildV should be deleted.
  %   \item References to Line~6 should be changed to Line~5.
  %   \item Line~3 of Add should be: {$|V_y|\ge 4$}
  %   \item Line~4 of Add should be: {let $x_{-1}>x_{-2}>x_{-3}>x_{-4}$ be the 4 largest elements in $V_y$ (so $x_{-1}=x$)}
  % \end{compactenum}
  % That's everything, right?
  % }
  It is easiest to think of the sets $V_y$ as sequences, sorted in increasing order, so that Line~2 in $\textsc{Add}(x,y)$ appends $x$ to $V_y$.
  
  That the procedure produces sets $V_1,\ldots,V_h$ such that $V_y\supseteq S_y$ for each $y\in\{1,\ldots,h\}$ is obvious.  So the resulting sets $V_1,\ldots,V_h$ satisfy the first condition of the lemma.
  
  To prove that $V_1,\ldots,V_h$ satisfy the second condition, we establish the loop invariant that, outside of $\textsc{Add}(x,y)$, $V_{y-1}$ and $V_{y+1}$ each 3-chunk  $V_y$ for each $y\in\{1,\ldots,h\}$.  Indeed, the only instant at which $V_{y-1}$ fails to 3-chunk $V_y$ is immediately after appending some value $x$ to $V_y$ in Line~2 of $\textsc{Add}(x,y)$.  If this occurs, it is immediately detected in Lines~3--5 and corrected in Line~6.  Similarly, if $V_{y+1}$ fails to $3$-chunk $V_y$ then this is immediately detected and corrected in Line~7.
  
  Finally, we need to argue that $V_1,\ldots,V_h$ satisfy the third condition. 
  For convenience, define $n:=\sum_{y=1}^h |S_y|$ so that our task is to show that $\sum_{y=1}^h |V_y|\le 2n$.

  We do this with a \emph{credit scheme} that maintains the following invariant  during the execution of the algorithm:  For each $V_y$, let $c_y$ be the length the longest suffix $x_{-k},\ldots,x_{-1}$ of $V_y$ that does not intersect $V_{y-1}$ or does not intersect $V_{y+1}$.  Except during the execution of $\textsc{Add}(x,y)$, $c_y\le 3$, since $V_{y-1}$ and $V_{y+1}$ each 3-chunk $V_y$.  We maintain the invariant that $V_{y}$ stores $c_y$ credits at all times.  When we append to the list $V_y$ in Line~2 of $\textsc{Add}(x,y)$ we will pay with one credit that is spent and can never be used again.
  
  To maintain our credit invariant, we will create 2 credits each time $\textsc{BuildV}$ calls $\textsc{Add}(x,y)$ in Line~6.  Line~6 executes at most once for each of the $n$ values in $S_1,\ldots,S_h$.  Therefore Line~6 executes at most $n$ times and at most $2n$ credits are created.  Since each execution of Line~2 in $\textsc{Add}(x,y)$ takes away one credit, this means that the total number of times we append to lists in $V_1,\ldots,V_h$ is at most $2n$. Therefore, $\sum_{y=1}^h |V_y|\le 2n$.
   
  To manage these credits, we will pass two credits into each invocation of $\textsc{Add}(x,y)$, including the recursive invocations.  For the invocations of $\textsc{Add}(x,y)$ in Line~6 of \textsc{BuildV}, the two credits passed in are the two newly-created credits.
  
  When $\textsc{Add}(x,y)$ executes, one of the two credits passed to it is used to pay for the execution of Line~2, and this credit disappears forever, leaving one extra credit that we add to $V_y$ since the newly-added value $x\in V_y$ may have increased $c_y$ by 1. Thus far the credit invariant is maintained.  
  
  If no further recursive invocations of $\textsc{Add}(x,y)$ are made, then there is nothing further to do, so we consider the case where the two recursive invocations in Lines~6 and 7 are made.  In this case, $c_y=4$ before these recursive invocations are made.  Afterwards, $c_y=0$ since these invocations add $x$ to $V_{y-1}$ and $V_{y+1}$.  This frees 4 credits.  We pass 2 of these free credits into the recursive invocation of $\textsc{Add}(x,y-1)$ and the other 2 free credits into the recursive invocation of $\textsc{Add}(x,y+1)$. 
\end{proof}

\end{document}
