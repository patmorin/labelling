\documentclass[kpfonts]{patmorin}
\listfiles
\usepackage{pat}
\usepackage{paralist}
\usepackage{dsfont}  % for \mathds{A}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}
\usepackage[noend]{algorithmic}

\usepackage{xcolor}
\definecolor{light-gray}{gray}{0.95}

\usepackage[normalem]{ulem}
\usepackage{cancel}
\usepackage{enumitem}

\usepackage{comment}

\newcommand{\snote}[1]{\fcolorbox{red}{yellow}{#1}}
\newcommand{\pnote}[1]{\ \newline\noindent\fcolorbox{red}{yellow}{\begin{minipage}{\textwidth}#1\end{minipage}}}
\setlength{\parskip}{1ex}

\DeclareMathOperator{\A}{\mathds{A}}
\DeclareMathOperator{\sn}{sn}
\DeclareMathOperator{\qn}{qn}

\renewcommand{\SS}{\mathcal{S}}

\newcommand{\Oh}{\mathcal{O}}


%Piotreks overloads
\let\le\leqslant
\let\ge\geqslant
\let\leq\leqslant
\let\geq\geqslant
\let\nleq\nleqslant
\let\ngeq\ngeqslant
%%Piotrek end

\newcommand{\aref}[1]{(X\ref{a:#1})}
\newcommand{\alabel}[1]{\label{a:#1}}

\newcommand{\itemref}[1]{(\ref{#1})}

\title{\MakeUppercase{Adjacency Labelling for Planar Graphs (and Beyond)}}
\author{
  Vida Dujmović,%
    \thanks{School of Computer Science and Electrical Engineering, University of Ottawa, Canada. This research was partially supported by NSERC.}\quad
  Louis Esperet,%
    \thanks{Laboratoire G-SCOP (CNRS, Univ.\ Grenoble Alpes), Grenoble, France. Partially supported by the French ANR Projects ANR-16-CE40-0009-01 (GATO) and ANR-18-CE40-0032 (GrR).}\quad
  Cyril Gavoille,%
    \thanks{LaBRI, University of Bordeaux, France. This research was partially supported by the French ANR projects ANR-16-CE40-0023 (DESCARTES) and ANR-17-CE40-0015 (DISTANCIA).}\quad
  Gwenaël Joret,%
     \thanks{Département d'Informatique, Université Libre de Bruxelles, Brussels, Belgium. Research supported by an ARC grant from the Wallonia-Brussels Federation of Belgium and by a grant from the National Fund for Scientific Research (FNRS).}\quad
  Piotr Micek,%
    \thanks{Theoretical Computer Science Department, Faculty of Mathematics and Computer Science, Jagiellonian University, Krak\'{o}w, Poland. This research was partially supported by the Polish National Science Center grant (BEETHOVEN; UMO-2018/31/G/ST1/03718).}\newline
  and Pat Morin%
    \thanks{School of Computer Science, Carleton University, Canada. This research was partially supported by NSERC.}
}
\date{}

\begin{document}
\begin{titlepage}
\maketitle

\begin{abstract}
  We show that there exists an adjacency labelling scheme for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log_2 n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  This is optimal up to the lower order term and is the first such asymptotically optimal result.  An alternative, but equivalent, interpretation of this result is that, for every positive integer $n$, there exists a graph $U_n$ with $n^{1+o(1)}$ vertices such that every $n$-vertex planar graph is an induced subgraph of $U_n$.  These results generalize to a number of other graph classes, including bounded genus graphs, apex-minor-free graphs,  bounded-degree graphs from minor closed families, and $k$-planar graphs.
\end{abstract}
\end{titlepage}
\pagenumbering{roman}
\tableofcontents

\newpage

\setcounter{page}{0}
\pagenumbering{arabic}
\section{Introduction}

%G: I moved this to Section 2
% In this paper, which is concerned with binary encodings, $\log x:=\log_2 x$ denotes the binary logarithm of $x$ and, for convenience, $\log x := \log\max\{1,x\}$.  All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The \emph{size} of a graph $G$ is denoted by $|G|:=|V(G)|$.

A family $\mathcal{G}$ of graphs has an \emph{$f(n)$-bit adjacency labelling scheme} if there exists a function $A:(\{0,1\}^*)^2\to \{0,1\}$ such that for every $n$-vertex graph $G\in \mathcal{G}$ there exists $\ell:V(G)\to\{0,1\}^*$ such that $|\ell(v)|\le f(n)$ for each vertex $v$ of $G$ and such that, for every two vertices $v,w$ of $G$,
\[  A(\ell(v),\ell(w)) =
      \begin{cases}
        0 & \text{if $vw\not\in E(G)$;} \\
        1 & \text{if $vw\in E(G)$.}
      \end{cases}
\]

Let $\log x:=\log_2 x$ denote the binary logarithm of $x$.
In this paper we prove the following result:
\begin{thm}\thmlabel{main}
  The family of planar graphs has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

% We show that there exists an \emph{adjacency labelling scheme} for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.

\thmref{main} is optimal up to the lower order term,
which is $\Oh\left(\sqrt{\log n\log\log n}\right)$ in our proof.
An alternative, but equivalent, interpretation of \thmref{main} is that, for every integer $n\ge 1$, there exists a graph $U_n$ with $n^{1+o(1)}$  vertices such that every $n$-vertex planar graph is isomorphic to some vertex-induced subgraph of $U_n$.\footnote{There is a small technicality that the equivalence between adjacency labelling schemes and universal graphs requires that $\ell:V(G)\to\{0,1\}^*$ be injective.  The labelling schemes we discuss satisfy this requirement.  For more details about the connection between labelling schemes and universal graphs, the reader is directed to Spinrad's monograph \cite[Section~2.1]{spinrad:efficient}.}

Note that the proof of \thmref{main} is constructive: it gives an algorithm producing the labels in $\Oh(n\log n)$ time.

\subsection{Previous Work}

The current paper is the latest in a series of results dating back to Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit0,kannan.naor.ea:implicit} and Muller \cite{muller:local} who defined adjacency labelling schemes\footnote{There are some small technical differences between the two definitions that have to do with the complexity of computing $\ell(\cdot)$ as a function of $G$ and
$A(\cdot,\cdot)$.} and described $\Oh(\log n)$-bit adjacency labelling schemes for several classes of graphs, including planar graphs.  Since this initial work, adjacency labelling schemes and, more generally, informative labelling schemes have remained a very active area of research \cite{adjiashvili.rotbart:labeling,alstrup.kaplan.ea:adjacency,abrahamsen.alstrup.ea:near-optimal,alstrup.dahlgaard.ea:sublinear,alstrup.gortz.ea:distance,alstrup.gavoille.ea:simpler,alstrup.rauhe:improved,Alon17}.
% Cyril: [Alon17] -> induced-universal graph of (1+o(1))2^{(n-1)/2} vertices for general n-vertex graphs.

Here we review results most relevant to the current work, namely results on planar graphs and their supporting results on trees and bounded-treewidth graphs.  First, a superficial review: Planar graphs have been shown to have $(c+o(1))\log n$-bit adjacency labelling schemes for successive values of $c=6,4,3,2,\tfrac{4}{3}$ and finally \thmref{main} gives the optimal\footnote{It is easy to see that, in any adjacency labelling scheme for any $n$-vertex graph $G$ in which no two vertices have the same neighbourhood, all labels must be distinct, so some label must have length at least $\lceil\log n\rceil$.} result $c=1$.  We now give details of these results.

Muller's scheme for planar graphs \cite{muller:local} is based on the fact that planar graphs are 5-degenerate.  This scheme orients the edges of the graph so that each vertex has 5 outgoing edges, assigns each vertex $v$ an arbitrary $\lceil\log n\rceil$-bit identifier, and assigns a label to $v$ consisting of $v$'s identifier and the identifiers of the targets of $v$'s outgoing edges.  In this way, each vertex $v$ is assigned a label of length at most $6\lceil\log n\rceil$.  Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit} use a similar approach that makes use of the fact that planar graphs have arboricity 3 (so their edges can be partitioned into three forests \cite{nash-williams:edge-disjoint}) to devise an adjacency labelling scheme for planar graphs whose labels have length at most $4\lceil\log n\rceil$.

A number of $(1+o(1))\log n$-bit adjacency labelling schemes for forests have been devised \cite{chung:universal, alstrup.rauhe:improved,alstrup.dahlgaard.ea:optimal}, culminating with a recent $(\log n + \Oh(1))$-bit adjacency labelling scheme \cite{alstrup.dahlgaard.ea:optimal} for forests.  Combined with the fact that planar graphs have arboricity 3, these schemes imply $(3+o(1))\log n$-bit adjacency labelling schemes for planar graphs.

A further improvement, also based on the idea of partitioning the edges of a planar graph into simpler graphs was obtained by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  Generalizing the results for forests, they describe a $(1+o(1))\log n$-bit adjacency labelling scheme for $n$-vertex graphs of bounded treewidth. As is well known, the edges of a planar graph can be partitioned into two sets, each of which induces a bounded treewidth graph.
%\pnote{Actually for a planar graphs, there's a really short proof using layering: Even layers plus edges to the previous layer has bounded treewidth. Same for odd layers.}
This results in a $(2+o(1))\log n$-bit adjacency labelling scheme for planar graphs.

Very recently, Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter} described a $(4/3+o(1))\log n$-bit adjacency labelling scheme for planar graphs based on a recent \emph{graph product structure theorem} of Dujmović \etal\ \cite{dujmovic.joret.ea:planar}.  This product structure theorem states that any planar graph is a subgraph of a strong product $H\boxtimes P$ where $H$ is a bounded-treewidth graph and $P$ is a path. See \figref{product}. It is helpful to think of $H\boxtimes P$ as a graph whose vertices can be partitioned into $h:=|V(P)|$ \emph{rows} $H_1,\ldots,H_{h}$, each of which induces a copy of $H$ and with vertical and diagonal edges joining corresponding and adjacent vertices between consecutive rows.
% We now quickly sketch the construction of Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter}.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics{figs/product}
  \end{center}
  \caption{The strong product $H\boxtimes P$ of a tree $H$ and a path $P$.}
  \figlabel{product}
\end{figure}
% In the following two paragraphs we omit $o(\log n)$ terms.

The product structure theorem quickly leads to a $(1+o(1))\log(mh)$-bit labelling scheme where $m:=|V(H)|$ and $h:=|V(P)|$ by using a $(1+o(1))\log m$-bit labelling scheme for $H$ (a bounded treewidth graph), a $\ceil{\log{h}}$-bit labelling scheme for $P$ (a path), and a constant number of bits to locally encode the subgraph of $H\boxtimes P$ (of constant arboricity).  However, for an $n$-vertex graph $G$ that is a subgraph of $H\boxtimes P$ in the worst case $m$ and $h$ are each $\Omega(n)$, so this offers no immediate improvement over the existing $(2+o(1))\log n$-bit scheme.

Bonamy, Gavoille, and Pilipczuk improve upon this by cutting $P$ (and hence $G$) into subpaths of length $n^{1/3}$ in such a way that this corresponds to removing $\Oh(n^{2/3})$ vertices of $G$ that have a neighbourhood of size $\Oh(n^{2/3})$. The resulting (cut) graph is a subgraph of $H'\boxtimes P'$ where $H'$ has bounded treewidth, $|H'|\le n$, and $P'$ is a path of length $n^{1/3}$ so it has a labelling scheme in which each vertex has a label of length $(1+o(1))\log (|H'|\cdot|P'|) \le (4/3+o(1))\log n$.  A slight modification of this scheme allows for the $\Oh(n^{2/3})$ \emph{boundary} vertices adjacent to the cuts to have shorter labels, of length only $(2/3+o(1))\log n$.  The cut vertices and the boundary vertices induce a bounded-treewidth graph of size $\Oh(n^{2/3})$.  The vertices in this graph receive secondary labels of length $(2/3+o(1))\log n$.  In this way, every vertex receives a label of length at most $(4/3 + o(1))\log n$.

\subsection{New Results}

The adjacency labelling scheme described in the current paper is also based on the product structure theorem for planar graphs, but it avoids cutting the path $P$, and thus avoids boundary vertices that take part in two different labelling schemes.  Instead, it uses a weighted labelling scheme on the rows $H_1,\ldots,H_h$ of $H\boxtimes P$ in which vertices that belong to $H_i$ receive a label of length $(1+o(1))\log n-\log W_i$ where $W_i$ is related to the number of vertices of $G$ contained in $H_i$ and $H_{i-1}$.  The vertices of $G$ in row $i$ participate in a secondary labelling scheme for the subgraph of $G$ contained in $H_i$ and $H_{i-1}$ and the labels in this scheme have length $\log W_i + o(\log n)$. Thus every vertex receives two labels, one of length $(1+o(1))\log n-\log W_i$ and another of length $\log W_i + o(\log n)$ for a total label length of $(1+o(1))\log n$.

The key new technique that allows all of this to work is that the labelling schemes of the rows $H_1,\ldots,H_h$ are not independent.  All of these labelling schemes are based on a single balanced binary search tree $T$ that undergoes insertions and deletions resulting in a sequence of related binary search trees $T_1,\ldots,T_h$ where each $T_i$ represents all vertices of $G$ in $H_{i}$ and $H_{i-1}$ and the label assigned to a vertex of $H_i$ is essentially based on a path from the root of $T_i$ to some vertex of $T_i$.  By carefully maintaining the binary search tree $T$, the trees $T_{i-1}$ and $T_{i}$ are similar enough so that the label for $v$ in $H_i$ can be obtained, with $o(\log n)$ additional bits from the label for $v$ in $H_{i-1}$.

The product structure theorem has been generalized to a number of additional graph families including bounded-genus graphs, apex-minor free graphs, bounded-degree graphs from minor-closed families, $k$-planar graphs, powers of bounded-degree bounded genus graphs, and $k$-nearest neighbour graphs of points in $\R^2$ \cite{dujmovic.joret.ea:planar,dujmovic.morin.ea:structure}. As a side-effect of designing a labelling scheme to work directly on subgraphs of a strong product $H\boxtimes P$, where $H$ has bounded treewidth and $P$ is a path,
we obtain $(1+o(1))\log n$-bit labelling schemes for all of these graph families.  All of these results are optimal up to the lower order term.

A graph is \emph{apex} if it has a vertex whose removal leaves a planar graph.
A graph is \emph{$k$-planar} if it has a drawing in the plane in which
each edge is involved in at most $k$ crossings. Such graphs provide a natural
generalisation of planar graphs, and have been extensively studied~\cite{kobourov.liotta.ea:annotated}.
%See the recent bibliography on 1-planar graphs with 140 references
The definition of $k$-planar graphs naturally generalises for other surfaces. A graph $G$ is
\emph{$(g,k)$-planar} if it has a drawing in some surface of Euler genus at most
$g$ in which each edge of $G$ is involved in at most $k$ crossings.
Note that already $1$-planar graphs are not minor closed.
The generalization of \thmref{main} provided by known product structure theorems is summarized in the following result:

\begin{thm}\thmlabel{main-all}
  For every fixed integer $t\geq 1$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some graph $H$ of treewidth $t$ and some path $P$ has a $(1+o(1))\log n$-bit adjacency labelling scheme.
  This includes the following graph classes:
  \begin{compactenum}
    \item graphs of bounded genus and, more generally, apex-minor free graphs;
    \item bounded degree graphs that exclude a fixed graph as a minor; and
    \item $k$-planar graphs and, more generally, $(g,k)$-planar graphs.
  \end{compactenum}
\end{thm}

The case of graphs of bounded degree from minor-closed classes (point~2 in \thmref{main-all}) is particularly interesting since, prior to the current work, the best known bound for adjacency labelling schemes in planar graphs of bounded degree was the same as for general planar graphs, i.e., $(4/3+o(1))\log n$. On the other hand, our \thmref{main-all} now gives an asymptotically optimal bound of $(1+o(1))\log n$ for graphs of bounded degree from any proper minor-closed class.




\subsection{Outline}

The remainder of the paper is organized as follows. \Secref{preliminaries} reviews some preliminary definitions and easy results.  \Secref{bulk-trees} describes a new type of balanced binary search tree that has the specific properties needed for our application. \Secref{pxp} solves a special case, where $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1$ and $P_2$ are both paths. We include it to highlight the generic idea behind our adjacency labelling scheme. \Secref{hxp} solves the general case in which $G$ is an $n$-vertex subgraph of $H\boxtimes P$ where $H$ has bounded treewidth and $P$ is a path.  \Secref{conclusion} concludes with a discussion of the computational complexity of assigning labels and testing adjacency and presents directions for future work.

% \subsection{Proof Overview}
%
% Like Bonamy \etal\ \cite{bonamy.gavoille.ea:shorter}.  Our starting point is a recent result that characterizes planar graphs in terms of the strong product of two simpler graphs.  The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
% \begin{enumerate}
%   \item  $v_1\neq v_2$; and
%   \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
%   \item $y_1=y_2$ or $y_1y_2\in E(B)$.
% \end{enumerate}
%
% \begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]
%   Every planar graph $G$ is the subgraph of a strong product $G^+:=H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
% \end{thm}
%
% \ldots


% For graph products like $G^+$, there is a natural labelling scheme: Compute a labelling scheme $\alpha:V(H)\to\{0,1\}^*$ for $H$ and a labelling scheme $\beta:V(P)\to\{0,1\}^*$ for $P$ and assign each vertex $v:=(x,y)\in V(G^*)$ the label $\mu(v):=\alpha(x),\beta(y)$.  Given two labels $\ell_1=\alpha(x_1),\beta(y_1)$ and $\ell_2=\alpha(x_2),\beta(y_2)$ for vertices $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ adjacency testing is done using the following formula whose three clauses follow from definition of strong product:
% \[
%     L(\ell_1,\ell_2):= (\ell_1\neq \ell_2) \wedge \A(\alpha(x_1),\alpha(x_2)) \wedge \A(\beta(y_1),\beta(y_2)) \enspace .
% \]
%
% \ldots



\section{Preliminaries}
\seclabel{preliminaries}

All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The \emph{size} of a graph $G$ is denoted by $|G|:=|V(G)|$.
\pnote{Pat: \sout{For convenience, we let $\log x := \log\max\{1,x\}$.} In the next section we use $\log x$ with $0<x<1$ so this is wrong.  At least this way it's just sloppy.}

For any graph $G$ and any vertex $v\in V(G)$, let $N_G(v):=\{w\in V(G): vw\in E(G)\}$ and $N_G[v]:=N_G(v)\cup\{v\}$ denote the open neighbourhood and closed neighbourhood of $v$ in $G$, respectively.

\subsection{Prefix-Free Codes}

For a string $s=s_1,\ldots,s_k$, we use $|s|:=k$ to denote the length of $s$.
%We denote the empty string by $\varepsilon$.
A string $s_1,\ldots,s_k$ is a \emph{prefix} of a string $t_1,\ldots,t_\ell$ if $k\le \ell$ and $s_1,\ldots,s_k=t_1,\ldots,t_k$.  A \emph{prefix-free code} $c:X\to\{0,1\}^*$ is a one-to-one function in which $c(x)$ is not a prefix of $c(y)$ for any two distinct $x,y\in X$.  Let $\N$ denote the set of non-negative integers.  The following is a classic observation of Elias from 1975.

% Louis. I reverted that back to a lemma... observation should be reserved for completely obvious things, right?  Pat: I agree.

% Cyril: I remove the $\in \Oh(log i)$ which is, this times, completey obvious. I would not write in a FOCS submission that "2n is in \Oh(n)". BTW, 

\begin{lem}[Elias \cite{elias:universal}]\lemlabel{elias}
    There exists a prefix-free code $\gamma:\N\to\{0,1\}^*$ such that, for each $i\in\N$, $|\gamma(i)|\le 2\lfloor\log(i+1)\rfloor + 1$.%\in \Oh(\log i)$.
  \end{lem}

  In the remainder of the paper, $\gamma$ (which we call an \emph{Elias encoding}) will be used extensively, without referring systematically to \lemref{elias}.

\subsection{Labelling Schemes Based on Binary Trees}

A \emph{binary tree} $T$ is a rooted tree in which each node except the root is either the \emph{left} or \emph{right} child of its parent and each node has at most one left and at most one right child.  For any node $x$ in $T$, $P_T(x)$ denotes the path from the root of $T$ to $x$.  The \emph{length} of a path $P$ is the number of edges in $P$, i.e., $|P|-1$.  The \emph{depth}, $d_T(x)$ of $x$ is the length of $P_T(x)$.  The \emph{height} of $T$ is $h(T):=\max_{x\in V(T)} d_T(x)$.  A \emph{perfectly balanced} binary tree is any binary tree $T$ of height $h(T)=\lfloor\log|T|\rfloor$.

A binary tree is \emph{full} if each non-leaf node has exactly two children. For a binary tree $T$, we let $T^+$ denote the full binary tree obtained by attaching to each node $x$ of $T$ $2-c_x$ leaves where $c_x \in\{0,1,2\}$ is the number of children of $x$.  We call the leaves of $T^+$ the \emph{external nodes} of $T$.  (Note that none of these external nodes are in $T$.)

A node $a$ in $T$ is a \emph{$T$-ancestor} of a node $x$ in $T$ if $a\in V(P_T(x))$. If $a$ is a $T$-ancestor of $x$ then $x$ is a \emph{$T$-descendant} of $a$. (Note that a node is a $T$-ancestor and $T$-descendant of itself.)  For a subset of nodes $X\subseteq V(T)$, the \emph{lowest common $T$-ancestor} of $X$ is the maximum-depth node $a\in V(T)$ such that $a$ is a $T$-ancestor of $x$ for each $x\in X$.

Let $P_T(x_r)=x_0,\ldots,x_{r}$ be a path from the root $x_0$ of $T$ to some node $x_r$ (possibly $r=0$).  Then the \emph{signature} of $x_r$ in $T$, denoted $\sigma_T(x_r)$ is a binary string $b_1,\ldots,b_r$ where $b_i=0$ if and only if $x_{i}$ is the left child of $x_{i-1}$.
Note that the signature of the root of $T$ is the empty string.

A \emph{binary search tree} $T$ is a binary tree whose node set $V(T)$ consists of distinct real numbers and that has the \emph{binary search tree property}:  For each node $x$ in $T$, $z<x$ for each node $z$ in $x$'s left subtree and $z>x$ for each node $z$ in $x$'s right subtree. For any $x\in\R\setminus V(T)$, the \emph{search path} $P_T(x)$ in $T$ is the unique root-to-leaf path $v_0,\ldots,v_r$ in $T^+$ such that adding $x$ as a (left or right, as appropriate) child of $v_{r-1}$ in $T$ would result in a binary search tree $T'$ with $V(T')=V(T)\cup\{x\}$.

The following observation allows us to compare values in a binary search tree just given their signatures in the tree.

\begin{obs}\obslabel{lexicographic}
  For any binary search tree $T$ and any nodes $x$, $y$ in $T$, we have $x<y$ if and only if $\sigma_T(x)$ is lexicographically less than $\sigma_T(y)$.
\end{obs}

Let $\R^+$ denote the set of positive real numbers. The following is a folklore result about biased binary search trees, but we sketch a proof here for completeness.

\begin{lem}\lemlabel{biased-bst}
  For any finite $S\subset \R$ and any function $w:S\to\R^+$, there exists a binary search tree $T$ with $V(T)=S$ such that, for each $y\in S$, $d_T(y)\le\log(W/w(y))$, where $W:=\sum_{y\in S} w(y)$.
\end{lem}

\begin{proof}
  The proof is by induction on $|S|$. The base case $|S|=0$ is vacuously true.
  For any $x\in\R$, let $S_{<x}:=\{y\in S: y < x\}$ and $S_{>x}:=\{y\in S: y>x\}$. For $|S|\ge 1$, choose the root of $T$ to be the unique node $y_0\in S$ such that $\sum_{z\in S_{<y_0}} w(z)\le W/2$ and $\sum_{z\in S_{>y_0}}< W/2$. Apply induction on $S_{<y_0}$ and $S_{>y_0}$ to obtain the left and right subtrees of $T$, respectively.

  Then $d_T(y_0)=0=\log 1\le \log (W/w(y_0))$.  For each $y\in S_{<y_0}$,
  \[
    d_T(y) \le 1 + \log\left(\frac{\sum_{z\in S_{<y_0}}w(z)}{w(y)}\right)
            \le 1 + \log \left(\frac{W/2}{w(y)}\right)
            = \log \left(\frac{W}{w(y)}\right) ,
  \]
  and the same argument shows that $d_T(y) < \log (W/w(y))$ for each $y\in S_{>y_0}$.
\end{proof}

The following fact about binary search trees is useful, for example, in the deletion algorithms for several types of balanced binary search trees \cite[Section~6.2.3]{morin:open}, see \figref{sigma-minus-one}:

\begin{figure}
  \begin{center}
    \includegraphics{figs/sigma-minus-one}
  \end{center}
  \caption{An illustration of \obsref{predecessor-encoding}: (1)~$\sigma_T(y_1)=11000$ and $\sigma_T(x_1)=1\mbox{\sout{1000}}$ (2)~$\sigma_T(y_2)=10\mbox{\sout{011}}$ and $\sigma_T(x_2)=10011$.}
  \figlabel{sigma-minus-one}
\end{figure}

\begin{obs}\obslabel{predecessor-encoding}
  Let $T$ be a binary search tree and let $x$, $y$ be nodes in $T$ such that $x<y$ and there is no node $z$ in $T$ such that $x<z<y$, i.e., $x$ and $y$ are consecutive in the sorted order of $V(T)$.  Then
  \begin{enumerate}
    \item (if $y$ has no left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by removing all trailing 0's and the last 1; or
    \item (if $y$ has a left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by appending a 0 followed by $d_T(y)-d_T(x)-1$ 1's.
  \end{enumerate}
Therefore, there exists a function $D:(\{0,1\}^*)^2\to{0,1}^*$ such that, for every binary search tree $T$ and for every $i$ such that $\{i-1,i\}\subseteq V(T)$, there exists $\delta_T(i) \in \{0,1\}^*$ with $|\delta_T(i)|=\Oh(\log h(T))$ such that
$D(\sigma_T(i),\delta_T(i))=\sigma_T(i-1)$.
\end{obs}

The bitstring $\delta_T(i)$ from \obsref{predecessor-encoding} is obtained as follows: It consists of a first bit indicating whether $i$ has a left child in $T$ or not and, in case $i$ does have a left child, an Elias encoding $\gamma(s)$ of the value $s:=d_T(i)-d_T(i-1)-1$.  More precisely, $\delta_T(i)=0$ or $\delta_T(i)=1,\gamma(s)$.

Putting some of the preceding results together we obtain the following useful coding result.

\begin{lem}\lemlabel{row-code}
  There exists a function $A:(\{0,1\}^*)^2\to\{-1,0,1,\perp\}$ such that, for any $h\in\N$, and any $w:\{1,\ldots,h\}\to\R^+$ there is a prefix-free code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that
  \begin{compactenum}
    \item for each $i\in\{1,\ldots,h\}$, $|\alpha(i)|=\log W -\log w(i) + \Oh(\log\log h)$;
    \item for any $i,j\in\{1,\ldots,h\}$,
    \[   A(\alpha(i),\alpha(j))
    = \begin{cases}
       0 & \text{if $j=i$;}\\
       1 & \text{if $j=i+1$;} \\
       -1 & \text{if $j=i-1$;} \\
       \perp & \text{otherwise.}
      \end{cases}
      \]
    \end{compactenum}
\end{lem}


\begin{proof}
  Define $w':\{1,\ldots,h\}\to \R^+$ as $w'(i)=w(i)+W/h$ and let $W':=\sum_{i=1}^h w'(i)=2W$.
  Using \lemref{biased-bst}, construct a biased binary search tree $T$ on $\{1,\ldots,h\}$ using $w'$ so that
  \[
    d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log w(i)+1
  \]
  and
  \[
  d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log (W/h)+1 \le \log h + 1,
  \]
  for each $i\in\{1,\ldots,h\}$.  This latter inequality implies that $h(T)\le\log h + 1$.

  The code $\alpha(i)$ for $i$ consists of three parts.  The first part, $\gamma(|\sigma_T(i)|)$, is the Elias encoding of the length of the path $P_T(i)$ from the root to $i$ in $T$. The second part $\sigma_T(i)$ encodes the left/right turns along this path. The third part, $\delta_T(i)$, is defined in \obsref{predecessor-encoding}.
  The length of $\delta_T(i)$ is $\Oh(\log h(T))=\Oh(\log\log h)$. Note that since $\gamma$ is prefix-free and two distinct sequences $\sigma_T(i)$ and $\sigma_T(j)$ of the same length cannot be prefix of one another, the code $\alpha$ is also prefix-free (and thus injective).

  The function $A$ is given by a simple algorithm: Given $\alpha(i)$ and $\alpha(j)$, first observe that the values of $\gamma(\cdot)$, $\sigma_T(\cdot)$, and $\delta_T(\cdot)$ can be extracted: $\gamma(\cdot)$ is first extracted using the fact that Elias encoding is prefix-free, this then gives us the length of $\sigma_T(\cdot)$, and finally $\delta_T(\cdot)$ consists of the remaining bits.
   The function $A$ extracts the values and lexicographically compares $\sigma_T(i)$ and $\sigma_T(j)$.  If $\sigma_T(i)=\sigma_T(j)$, then $A$ outputs $0$.
   Otherwise, assume for now that $\sigma_T(i)$ is lexicographically less than $\sigma_T(j)$ so that, by \obsref{lexicographic}, $i < j$.  Now $A$ computes $D(\sigma_T(j),\delta_T(j))=\sigma_T(j-1)$ as described in \obsref{predecessor-encoding}.
   If $\sigma_T(j-1)=\sigma_T(i)$ then $A$ outputs $1$, otherwise $A$ outputs $\perp$.
  In the case where $\sigma_T(i)$ is lexicographically greater than $\sigma_T(j)$, $A$ proceeds in the same manner, but reversing the roles of $i$ and $j$ and outputting $-1$ in the case where $\sigma_T(i-1)=\sigma_T(j)$.
\end{proof}

\subsection{Chunked Sets and Fractional Cascading}

For non-empty finite sets $X,Y\subset \R$ and an integer $a$, we say that $X$ \emph{$a$-chunks} $Y$ if, for any $a+1$-element subset $S\subseteq Y$, there exists $x\in X$, such that $\min S\le x\le \max S$. Observe that, if $X$ $a$-chunks $Y$, then $|Y\setminus X|\le a(|X|+1)\le 2a|X|$ so $|X\cup Y|\le (2a+1)|X|$.  A sequence $V_1,\dots,V_h\subset\R$ is \emph{$a$-chunking} if $S_y$ $a$-chunks $S_{y+1}$ and $S_{y+1}$ $a$-chunks $S_y$ for each $y\in\{0,\ldots,h-1\}$.

\begin{lem}\lemlabel{fractional}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exist sets $V_1,\ldots,V_{h}\subset\R$ such that
  \begin{compactenum}
    \item for each $y\in\{1,\ldots,h\}$, $V_y\supseteq S_y$;
    \item $V_1,\ldots,V_h$ is $3$-chunking;
    \item $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|$.
  \end{compactenum}
\end{lem}

A proof of a much more general version of \lemref{fractional} (with larger constants) is implicit in the iterated search structure of Chazelle and Guibas \cite{chazelle.guibas:fractional1}.   For the sake of completeness, \appref{fractional-proof} includes a proof of \lemref{fractional} that borrows heavily from the amortized analysis of partially persistent data structures \cite[Section~2.3]{driscoll.sarnak.ea:making}.


\subsection{Product Structure Theorems}

The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two distinct vertices $(x_1,y_1)$ and $(x_2,y_2)$ are adjacent if and only if:
\begin{enumerate}
  \item  $x_1x_2 \in E(A)$ and $y_1y_2 \in E(B)$; or
  \item $x_1=x_2$ and $y_1y_2\in E(B)$; or
  \item $x_1x_2 \in E(A)$ and $y_1=y_2$.
\end{enumerate}

\begin{thm}[Dujmović \etal\ \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure}
  Every planar graph $G$ is a subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
\end{thm}

\thmref{product-structure} can be generalized (replacing $8$ with a larger constant) to bounded genus graphs, and more generally to apex-minor free graphs.


%\begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure-apex-minor-free}
%  Let $\mathcal{G}$ be a minor-closed family of graphs that excludes some fixed apex graph.  Then every $G\in\mathcal{G}$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of bounded treewidth and $P$ is a path.
%\end{thm}
Dujmović, Morin, and Wood \cite{dujmovic.morin.ea:structure} gave analogous product structure theorems for some non-minor closed families of graphs including $k$-planar graphs,
%map graphs, Piotrek: I even dont know what are map graphs :)
powers of bounded-degree planar graphs, and $k$-nearest-neighbour graphs of points in $\R^2$. Dujmović, Esperet, Morin, Walczak, and Wood \cite{dujmovic.esperet.ea:clustered} proved that a similar product structure theorem holds for graphs of bounded degree from any (fixed) proper minor-closed class.  This is summarized in the following theorem:

\begin{thm}[\cite{dujmovic.joret.ea:planar},\cite{dujmovic.esperet.ea:clustered},\cite{dujmovic.morin.ea:structure}]\thmlabel{product-structure-all}
   Every graph $G$ in each of the following families of graphs is a subgraph of a
strong product $H\boxtimes P$ where $P$ is a path and $H$ is a graph of bounded
treewidth:

   \begin{compactitem}
   \item graphs of bounded genus and, more generally, apex-minor free graphs;%\cite{dujmovic.joret.ea:planar};
   %\footnote{A
%graph is an \emph{apex} if it has a vertex whose removal leaves a planar
%graph.} Piotrek: definition of apex is already somewhere before
     \item bounded degree graphs that exclude a fixed graph as
a minor;% \cite{dujmovic.esperet.ea:clustered};
   \item $k$-planar graphs and, more generally, $(g,k)$-planar graphs. %\cite{dujmovic.morin.ea:structure}.
 \end{compactitem}
   %Piotrek: I commented out citations. I think we give a precise description of all the contributions.
\end{thm}



%Our main result, which is a $(1+o(1))\log n$-bit adjacency labelling scheme for $n$-vertex subgraphs of $H\boxtimes P$, where $H$ has bounded treewidth and $P$ is a path, holds for all these classes of graphs.

%The case of graphs of bounded degree from minor-closed classes is particularly interesting,
%since the best known bound for adjacency labelling schemes in planar graphs of bounded degree was the same as for general planar graphs, i.e., $(4/3+o(1))\log n$. On the other hand, our main result implies an asymptotically optimal bound of $(1+o(1))\log n$ for graphs of bounded degree from any proper minor-closed class.
% Piotrek: Given that we put a whole thm in this section about the product thms, I find this paragraph to be too much now.

\section{Bulk Trees}
\seclabel{bulk-trees}

Our labelling scheme for a subgraph $G$ of $H \boxtimes P$ uses labels that depend in part on the rows ($H$-coordinates) of $G$, where each row corresponds to one vertex of $P$: Say $P$ consists of vertices $1, 2, \dots, h$ in this order, then the \emph{$i$-th row} of $G$ is the subgraph $H_i$ of $G$ induced by the vertex set $\{(v, i) \in V(G)\}$.
A naive approach to create labels for each $H_i$ is to use a labelling scheme for bounded treewidth graphs; roughly, this entails building a specific binary search tree $T_i$ and mapping each vertex $v$ of $H_i$ onto a node $x$ of $T_i$ that we call the \emph{position} of $v$ in $T_i$.
% roughly, this entails building a specific balanced binary search tree $T_i$ on the vertices of $H_i$ in such a way that the label of each vertex $(v, i)$ is of length $\log |T_i|$ plus a lower-order term.
The label of $(v, i)$ encodes the position of $v$ in $T_i$ plus some small extra information (see~\secref{hxp}).
This way, we can determine if two vertices $(v,i)$ and $(w,i)$ in the same row are adjacent.

The key problems that we face here though are queries of the type $(v,i)$ and $(w,i+1)$: We would like to determine adjacency on the $H$-coordinate using $T_i$ or $T_{i+1}$.
We could extend the node set of $T_{i+1}$ so that it represents all vertices from $H_{i}$. This way we know that both $v$ and $w$ are represented in $T_{i+1}$.
However, we still have a major issue: the label of $(v,i)$ describes the position of $v$ in $T_i$ but not in $T_{i+1}$.
In this setup, in order to determine if $v$ and $w$ are adjacent in $H$ we need to know their respective positions in the same binary search tree.
However, there is in principle no relation between the position of $v$ in $T_i$ and its position in $T_{i+1}$.

To circumvent this difficulty, we build the binary search trees $T_1,\ldots,T_h$ one by one, starting with a balanced binary search tree, in such a way that $T_{i+1}$ is obtained from $T_i$ by performing carefully structured changes. By storing some small extra information related to these changes in the label of $(v,i)$, this will allow us to obtain the position of $v$ in $T_{i+1}$.
Finally, we also need to guarantee that the binary search trees in our sequence are balanced so that the labels are of length $\log|T_i|$ plus a lower-order term.

In this section, we introduce three operations on a binary search tree that will allow us to carry out this plan.
These operations are called \emph{bulk insertion}, \emph{bulk deletion}, and \emph{rebalancing}.
Starting from a perfectly balanced binary search tree $T_1$, each tree $T_i$ in our sequence $T_1, \dots, T_h$ will be obtained from $T_{i-1}$ by applying these three operations.


%%% Old beginning of section
% The labelling scheme for planar graphs uses labels whose largest part comes from paths in a special type of balanced binary search tree that we call a \emph{bulk tree}.  The operations in a bulk tree proceed in \emph{rounds} where, in each round, two types of bulk operations are performed: \emph{bulk insertion}, in which a set $I\subset \R\setminus V(T)$ of new values are inserted into $T$, and \emph{bulk deletion}, in which a set $D\subseteq V(T)$ of values are removed from $T$. The sets $I$ and $D$ inserted into and deleted from $T$ in a single round must satisfy the following two restrictions: (i)~$V(T)$ $3$-chunks $I$; and (ii)~$V(T)\setminus D$ 3-chunks $D$.\footnote{There is nothing special about the constant $3$ here.  The data structure and its analysis work with $3$ replaced by any constant $a$. The constant $3$ comes from an application of~\lemref{fractional}.}  Note that (ii) implies that $|D|\le 6(|V(T)|-|D|)$, so $|D|\le (6/7)|V(T)|$.


\subsection{Bulk Insertion}

The bulk insertion operation, $\textsc{BulkInsert}(I)$,
in which a finite set $I\subset  \R\setminus V(T)$ of new values are inserted into a binary search tree $T$, is implemented as follows: Let $z_0,\ldots,z_{|T|}$ denote the external nodes of $T$.  For each $i\in\{0,\ldots,|T|\}$, let $I_i$ consist of all $x\in I$ such that $P_T(x)$ ends at $z_i$.
For each $i\in\{0,\ldots,|T|\}$, construct a perfectly balanced binary search tree $T_i$ with vertex set $I_i$.
For each $i\in\{1,\ldots,|T|\}$, replace $z_i$ with $T_i$ in $T^+$.
The resulting tree is the outcome of the operation.

\begin{lem}\lemlabel{insertion-depth}
  Let $T$ be any binary search tree and let $I$ be a finite set of values from $\R\setminus V(T)$ such that
  $V(T)$ $3$-chunks $I$.\footnote{There is nothing special about the constant $3$ here.  The data structure and its analysis work with $3$ replaced by any constant $a$. The constant $3$ comes from an application of~\lemref{fractional}.}
  Apply $\textsc{BulkInsert}(I)$ to $T$ to obtain $T'$.
  %Let $T'$ be the binary search tree obtained from a bulk insertion of $I$ into $T$.
  Then $T'$ is a supergraph of $T$ and $h(T')\le h(T)+2$.
\end{lem}

\begin{proof}
  That $T'$ is a supergraph of $T$ is obvious.  Note that $|I_i|\le 3$ since $V(T)$ $3$-chunks $I$.  Therefore, $h(T')\le h(T)+2$ since, for each $i\in\{0,\ldots,|T|\}$, $|T_i|=|I_i|\le 3$ and $T_i$ is perfectly balanced, so $h(T_i)\le\lfloor\log 3\rfloor = 1$.  Any root-to-leaf path in $T'$ consists of a root-to-leaf path in $T$ followed by at most 2 elements of $T_i$ for some $i\in\{1,\ldots,|T|\}$.  Therefore the length of any root-to-leaf path in $T'$ is at most $h(T)+2$.
\end{proof}

\begin{lem}\lemlabel{insertion-size}
  Let $T$ be any binary search tree and let $I$ be a finite set of values from $\R\setminus V(T)$ such that
  $V(T)$ $3$-chunks $I$.
  Apply $\textsc{BulkInsert}(I)$ to $T$ to obtain $T'$.
%  Let $T'$ be the binary search tree obtained from a bulk insertion of $I$ into $T$.
  Let $x$ be any node of $T$ and let $T_x$ and $T_x'$ be the subtrees of $T$ and $T'$, respectively, rooted at $x$.
  Then $|T_x|\le |T_x'|\le 8|T_x|$.
\end{lem}

\begin{proof}
We clearly have  $|T_x|\le |T_x'|$.  By definition, $V(T)$ 3-chunks $I:=V(T')\setminus V(T)$.  This implies that $V(T_x)$ 3-chunks $I_x:=V(T_x')\setminus V(T_x)$.  Therefore $|I_x|\le 3(|T_x|+1)$, so $|T_x'|=|T_x|+|I_x|\le 4|T_x|+3 \le 8|T_x|$.
\end{proof}


\subsection{Bulk Deletion}

The bulk deletion operation, $\textsc{BulkDelete(D)}$, of a subset $D$ of nodes of a binary search tree $T$ is implemented as a series of $|D|$ individual deletions, performed in any order. For each $x\in D$, the deletion of $x$ is implemented by running the following recursive algorithm:  If $x$ is a leaf, then simply remove $x$ from $T$.  Otherwise, $x$ has at least one child.  If $x$ has a left child, then recursively delete the largest value $x'$ in the subtree of $T$ rooted at the left child of $x$ and then replace $x$ with $x'$.  Otherwise $x$ has a right child, so recursively delete the smallest value $x'$ in the subtree of $T$ rooted at the right child of $x$ and then replace $x$ with $x'$.


\begin{lem}\lemlabel{deletion-signature}
  Let $T$ be any binary search tree and let $D$ be a finite set of values from $V(T)$.
  Apply $\textsc{BulkDelete}(D)$ to $T$ to obtain a new tree $T'$.
  Then, for any node $x$ in $T'$, $\sigma_{T'}(x)$ is a prefix of $\sigma_T(x)$.
  In particular, $h(T')\leq h(T)$.
\end{lem}

\begin{proof}
  This follows immediately from the fact the only operations performed during a bulk deletion are (i)~deletion of leaves and (ii)~using a value $x'$ to replace the value of one of its $T$-ancestors $x$.  The deletion of a leaf has no effect on $\sigma_{T'}(x)$ for any node $x$ in $T'$.  For any node $z$ in $T'$ other than $x'$, (ii) has no effect on $\sigma_T(z)$.  For the node $x'$, (ii) has the effect of replacing $\sigma_T(x')$ by its length-$d_T(x)$ prefix.
  % Therefore, for any node $z\in v(T)$, $\sigma_{T'}(z)$ is obtained by truncating $\sigma_{T}(z)$ zero or more times, so $\sigma_{T'}(x)$ is a prefix of $\sigma_T(z)$.
\end{proof}

\begin{lem}\lemlabel{deletion-size}
  Let $T$ be any binary search tree and let $D$ be a finite set of values from $V(T)$ such that $V(T)\setminus D$ $3$-chunks $D$.
  Apply $\textsc{BulkDelete}(D)$ to $T$ to obtain a new tree $T'$.
%  Let $T'$ be the binary search tree obtained by performing a bulk deletion of $D$ in $T$.
  Then $|T|/8 \le |T'|\le |T|$.
\end{lem}

\begin{proof}
 We clearly have $|T'|\le |T|$.  Since $V(T)\setminus D$ $3$-chunks $D$, we have $|D|\le 3(|V(T)|-|D| + 1) \le 6(|V(T)|-|D|)$, so $|D|\le (6/7)|V(T)|$. Thus $|T'| \ge |T| - 6/7|T| \geq |T|/7 \geq |T|/8$.
\end{proof}

\subsection{Rebalancing}

The rebalancing operation on a binary search tree $T$ uses several subroutines that we now discuss, beginning with the most fundamental one:  $\textsc{Split}(x)$.

\subsubsection{$\textsc{Split}(x)$}

The argument of $\textsc{Split}(x)$ is a node $x$ in $T$ and the end result of the subroutine is to split $T$ into two binary search trees $T_{<x}$ and $T_{>x}$ where $V(T_{<x})=\{z\in V(T): z<x\}$ and $V(T_{>x})=\{z\in V(T): z>x\}$. Refer to \figref{split}.  Let $P_T(x_r)=x_0,\ldots,x_r$ be the path in $T$ from the root $x_0$ of $T$ to $x=x_r$.  Partition $x_0,\ldots,x_{r-1}$ into two subsequences $a:=a_1,\ldots,a_s$ and $b:=b_1,\ldots,b_t$ where the elements of $a$ are less than $x$ and the elements of $b$ are greater than $x$.
Note that the properties of a binary search tree guarantee that
\[
a_1 < \cdots < a_s < x < b_t < \cdots < b_1.
\]
Make a binary search tree $T_0$ that has $x$ as root, the path $a_1,\ldots,a_s$ as the left subtree of $x$ and the path $b_1,\ldots,b_t$ as the right subtree of $x$.  Note that $a_{i+1}$ is the right child of $a_i$ for each $i\in\{1,\ldots,s-1\}$ and $b_{i+1}$ is the left child of $b_i$ for each $i\in\{1,\ldots,t-1\}$.

\begin{figure}
  \begin{center}
    \includegraphics{figs/split-1} \\[1ex]
    $\Downarrow$ \\[1ex]
    \includegraphics{figs/split-2}
  \end{center}
  \caption{The operation of $\textsc{Split}(x)$.}
  \figlabel{split}
\end{figure}

Next, consider the forest $F:=T-\{x_0,\ldots,x_r\}$. This forest consists of $r+2$ (possibly empty) trees $A_1,\ldots,A_{r-1},L,R$ where $L$ and $R$ are the subtrees of $T$ rooted at the left and right child of $x$ in $T_x$ and, for each $i\in\{1,\ldots,r-1\}$, $A_i$ is the subtree of $T$ rooted at the child $c_i\neq x_{i+1}$ of $x_i$ (if such a child exists, otherwise $A_i$ is empty).  Make a binary search tree $T_x$ by replacing each of the $r+2$ external nodes of $T_0^+$ with the corresponding tree in $F$.  Finally, let $T_{<x}$ be the subtree of $T_x$ rooted at the left child of $x$ and let $T_{>x}$ be the subtree of $T_x$ rooted at the right child of $x$ in $T_x$.

\begin{lem}\lemlabel{split-height}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\textsc{Split}(x)$ to obtain $T_{<x}$ and $T_{>x}$.
  Then $h(T_{<x})\le h(T)$ and $h(T_{>x})\le h(T)$.
\end{lem}

\begin{proof}
  Note that for each node $z$ of $T_{<x}$, we have $V(P_{T_{<x}}(z))\subseteq V(P_T(z))$,
  so $d_{T_{<x}}(z)\le d_T(z)$.
  Therefore $h(T_{<x})\le h(T)$. The argument for $T_{>x}$ is symmetric.
\end{proof}

The following observation shows that there is a simple relationship between a node's signature in $T$ before calling $\textsc{Split}(x)$ and its signature in $T_{<x}$ or $T_{>x}$.

\begin{obs}\obslabel{split-signature}
  Let $T$, $x$, $x_0,\ldots,x_r$, $A_1,\ldots,A_{r-1},L,R$, $a_1,\ldots,a_s$, and $b_1,\ldots,b_t$ be defined as above. Then
  \begin{compactenum}
    \item for each $j\in\{1,\ldots,s\}$ where $a_j=x_i$
    \begin{compactenum}
      \item $\sigma_{T_{<x}}(a_j)=1^{j-1}$, and
      \item $\sigma_{T_{<x}}(z) = 1^{j-1},0,\sigma_{A_i}(z)$ for each $z\in V(A_i)$;
    \end{compactenum}
    \item for each $j\in\{1,\ldots,t\}$ where $b_j=x_i$
    \begin{compactenum}
      \item $\sigma_{T_{>x}}(b_j)=0^{j-1}$, and
      \item $\sigma_{T_{>x}}(z) = 0^{j-1},1,\sigma_{A_i}(z)$ for each $z\in V(A_i)$;
    \end{compactenum}
    \item $\sigma_{T_{<x}}(z)=1^s,\sigma_L(z)$ for each $z\in V(L)$; and
    \item $\sigma_{T_{>x}}(z)=0^t,\sigma_R(z)$ for each $z\in V(R)$.
  \end{compactenum}
  In particular, for any $z\in V(T)\setminus\{x\}$, $\sigma_{T_{<x}}(z)$ or $\sigma_{T_{>x}}(z)$ can be obtained from $\sigma_T(z)$ by deleting a prefix and replacing it with one of the $4\cdot h(T)$ strings in $\Pi:=\bigcup_{j=0}^{h(T)-1}\{0^j,0^j1,1^j,1^j0\}$.
\end{obs}

\subsubsection{$\textsc{MultiSplit}(x_1,\ldots,x_c)$}

From the $\textsc{Split}(x)$ operation we build the $\textsc{MultiSplit}(x_1,\ldots,x_c)$ operation that takes as input a sequence of nodes $x_1<\cdots<x_c$ of $T$.  For convenience, define $x_0=-\infty$ and $x_{c+1}=\infty$.  The effect of $\textsc{MultiSplit}(x_1,\ldots,x_c)$ is to split $T$ into a sequence of binary search trees $T_0,\ldots,T_{c}$ where, for each $i\in\{0,\ldots,c\}$, $V(T_i)=\{z\in V(T): x_i< z<x_{i+1}\}$.

The implementation of $\textsc{MultiSplit}(x_1,\ldots,x_c)$ is straightforward divide-and-conquer:  If $c=0$, then there is nothing to do.  Otherwise, call $\textsc{Split}(x_{\lceil c/2\rceil})$ to obtain $T_{<x_{\lceil c/2\rceil}}$ and $T_{>x_{\lceil c/2\rceil}}$.  Next, apply $\textsc{MultiSplit}(x_1,\ldots,x_{\lceil c/2\rceil-1})$ to $T_{<x_{\lceil c/2\rceil}}$ to obtain $T_0,\ldots,T_{\lceil c/2\rceil-1}$ and then apply $\textsc{MultiSplit}(x_{\lceil c/2\rceil+1},\ldots,x_c)$ to $T_{>x_{\lceil c/2\rceil}}$ to obtain $T_{\lceil c/2\rceil},\ldots,T_c$.

The following lemma is immediate from \lemref{split-height}.
\begin{lem}\lemlabel{multisplit-height}
  Let $T$ be any binary search tree and apply $\textsc{MultiSplit}(x_1,\ldots,x_c)$ to $T$ to obtain $T_0,\ldots,T_c$.  Then $h(T_i)\le h(T)$ for each $i\in\{0,\ldots,c\}$.
\end{lem}

\subsubsection{$\textsc{Balance}(x,k)$}

The $\textsc{Balance}(x,k)$ operation operates on the subtree $T_x$ of $T$ rooted at some node $x$ in $T$.
The goal of this operation is to balance the size of all the subtrees rooted at nodes of depth $d_T(x)+k+1$ and contained in $T_x$.
Refer to \figref{balance-x}.

\begin{figure}
    \begin{center}
      \includegraphics{figs/balance-x-1} \\[-2ex]
      $\Downarrow$ \\[1ex]
      \includegraphics{figs/balance-x-2}
    \end{center}
  \caption{The operation of $\textsc{Balance}(x,k)$}
  \figlabel{balance-x}
\end{figure}

If $|V(T_x)|< 2^k$, then this operation simply replaces $T_x$ with a perfectly balanced binary search tree containing $V(T_x)$.  Otherwise, let $Z:=\{z\in V(T_x): d_{T_x}(z)< k\}$.  Call the $m\le 2^k-1$ elements of $Z$  $z_1<z_2<\cdots<z_{m}$ and, for convenience, define $z_0=-\infty$ and $z_{m+1}=\infty$.

Select the nodes $X:=\{x_1,\ldots,x_{2^k-1}\}$ of $T_x$ where each $x_j$ has rank $\lfloor j|V(T_x)|/2^k\rfloor$ in $V(T_x)$.\footnote{For a finite set $X\subset\R$, and $x\in\R$, the \emph{rank} of $x$ in $S$ is $|\{x'\in S: x'<x\}|$.}  The $\textsc{Balance}(x,k)$ operation will turn $T_x$ into a tree with a top part $\hat{T}_0$ that is a perfectly balanced binary search tree on $Z\cup X$.  We now describe how this is done.

$T_x-Z$ is a forest consisting of $m+1\le 2^{k}$ trees $T_0,\ldots,T_m$. (Some of these trees may be empty.)  Order $T_{0},\ldots,T_m$ so that, for each $i\in\{0,\ldots,m\}$ and each $x'\in V(T_i)$, $z_i< x' < z_{i+1}$.  For each $i\in\{0,\ldots,m\}$, let $\{x_{i,1},\ldots,x_{i,c_i}\}:=X\cap V(T_i)$ where $x_{i,1}<\cdots<x_{i,c_i}$ and define $x_{i,0}:=z_i$ and $x_{i,c_i+1}:=z_{i+1}$. Note that for each $i\in\{0,\ldots,m\}$, $c_i\le |X|\le 2^k-1$.

For each $i\in\{0,\ldots,m\}$, apply $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ to the tree $T_i$.  As a result of these calls, we obtain sequences of trees $T_{i,0},\ldots,T_{i,c_i}$ where, for each $i\in\{0,\ldots,m\}$, each $j\in\{0,\ldots,c_i\}$, and each $x'\in V(T_{i,j})$, we have $x_{i,j}<x'<x_{i,j+1}$.  Observe that $\bigcup_{i=0}^m\bigcup_{j=0}^{c_i} V(T_{i,j}) = V(T_x)\setminus (Z\cup X)$.

Let $p:=|Z\cup X|$, let $s_1<\cdots< s_p$ denote the elements of $Z\cup X$ and define $s_0:=-\infty$ and $s_{p+1}:=\infty$.  For each $\ell\in\{0,\ldots,p\}$, let $i_\ell:=|Z\cap \{s_1,\ldots,s_\ell\}|$ and $j_\ell:= \ell - \max\{ q\in\{1,\ldots,\ell\}: s_q\in Z\}$ and let $A_\ell:=T_{i_\ell,j_\ell}$.   Then, for each $\ell\in \{0,\ldots,p\}$ and each $x'\in V(A_\ell)$, we have $s_\ell < x' < s_{\ell+1}$.

Now construct a perfectly balanced tree $\hat{T}_0$ with vertex set $V(\hat{T}_0):=\{s_1,\ldots,s_p\}=Z\cup X$.  The tree $\hat{T}_0$ has $p+1$ external nodes $a_0,\ldots,a_p$.  We obtain a new tree $T_x'$ by replacing $a_\ell$ with $A_\ell$ for each $\ell\in\{0,\ldots,p\}$ in $\hat{T}_0^+$.  In the encompassing bulk tree $T$ we replace the subtree $T_x$ with $T_x'$.

\begin{lem}\lemlabel{multisplit-depth}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\textsc{Balance}(x,k)$ to $T$ to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{proof}
  Since $\textsc{Balance}(x,k)$ only affects the subtree $T_x$ rooted at $x$, it suffices to show that $h(T_x')\le h(T_x)+1$.  For each $i\in\{0,\ldots, m\}$, $T_i$ is rooted at a depth-$k$ node of $T_x$, so $h(T_i)\le h(T_x)-k$. For each $\ell \in\{0,\ldots,p\}$, $A_\ell$ is obtained by an application of $\textsc{MultiSplit}$ to $T_i$ for some $i\in\{0,\ldots,m\}$ so, by \lemref{multisplit-height}, $h(A_\ell)\le h(T_i)\le h(T_x)-k$.  Next, $|Z\cup X|\le |Z|+|X| \le 2^k-1 + 2^k-1 < 2^{k+1}-1$ and $\hat{T}_0$ is a perfectly balanced binary search tree of size $|\hat{T}_0|=|Z\cup X|$.  Therefore $h(\hat{T}_0)\le \lfloor\log|\hat{T}_0|\rfloor\le \lfloor\log(2^{k+1}-1)\rfloor = k$.  Finally, $h(T_x')\le h(\hat{T}_0)+1 +\max \{h(A_\ell):\ell\in\{0,\ldots,p\}\} \le k +1 + h(T_x) - k\le h(T_x)+1$.
\end{proof}

The following statement captures what we win after an application of $\textsc{Balance}(x,k)$ to a binary search tree.

\begin{lem}\lemlabel{balance-x-weight}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, let $T_x$ be the subtree of $T$ rooted at $x$, and apply $\textsc{Balance}(x,k)$ to $T$ to obtain a new tree $T'$.  Then, for each $T'$-descendant $z$ of $x$ with $d_{T'}(z)=d_{T}(x)+k+1$, the subtree of $T'$ rooted at $z$ has size at most $|T_x|/2^k$.
\end{lem}

\begin{proof}
  Each such subtree is a subtree of $A_\ell$ for some $\ell\in\{0,\ldots,p\}$. Now, $V(A_\ell)\subset (x_j,x_{j+1})$ for some $j\in\{1,\ldots,2^{k-1}\}$.  The values $x_j$ and $x_{j+1}$ have ranks $\lfloor j|T_x|/2^k\rfloor$ and $\lfloor (j+1)|T_x|/2^k\rfloor$ in the set $V(T_x)$.  Therefore, $|A_\ell|\le \lfloor (j+1)|T_x|/2^k\rfloor- \lfloor j|T_x|/2^k\rfloor -1 < |T_x|/2^k$.
\end{proof}

\subsubsection{$\textsc{BulkBalance}(\theta,k)$}

The ultimate restructuring operation in bulk trees is $\textsc{BulkBalance}(\theta,k)$.
It calls \textsc{Balance}$(x,k)$ for each node $x$ of depth $\theta$ in $T$.
(Note that this operation has no effect if there is no such node.)
%Note that this operation is well defined, since $\textsc{Balance}(x,k)$ only influences the subtree rooted in $x$, and the subtrees modified by $\textsc{BulkBalance}(\theta,k)$ are pairwise disjoint.
The following two lemmas are immediate consequences of \lemref{multisplit-depth} and \lemref{balance-x-weight}, respectively.

\begin{lem}\lemlabel{balance-depth}
  Let $T$ be any binary search tree and apply the $\textsc{BulkBalance}(\theta,k)$ operation to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{lem}\lemlabel{balance-weight}
  Let $T$ be any binary search tree and apply the $\textsc{BulkBalance}(\theta,k)$ operation to obtain a new tree $T'$.
  Let $x$ be any node of $T$ of depth $\theta$ and let $T_x$ be the subtree of $T$ rooted at $x$.
  Then, for each $T'$-descendant $z$ of $x$ with $d_{T'}(z)=\theta+k+1$, the subtree of $T'$ rooted at $z$ has size at most $|T_x|/2^k$.
\end{lem}



\subsection{Bulk Tree Sequences}



Let $k\ge 7$ be an integer\footnote{$k \geq 7$ is a technical requirement, to make sure that some inequalities hold later on.} and let $S_0,\ldots,S_q$ be a $3$-chunking sequence.
%with $q\leq y^*:=\left\lceil \frac{\log|S_0|}{k-3}\right\rceil$,
We define a \emph{one-phase $k$-bulk tree sequence} based on $S_0,\ldots,S_q$ to be a sequence $T_0, \dots, T_{q}$ of binary search trees such that $T_0$ is an arbitrary binary search tree on node set $S_0$ and,  for each $y\in \{0, \dots, q-1\}$, we have $h(T_y)>y\cdot(k+1)$ and
the tree $T_{y+1}$ is obtained from $T_y$ by applying
\begin{enumerate}[label={(\roman*)}, ref={\roman*}, noitemsep]
    \item $\textsc{BulkBalance}(y\cdot(k+1),k)$, then
    \item $\textsc{BulkInsert}(I)$ with $I:=S_{y+1} \setminus S_{y}$, and finally
    \item $\textsc{BulkDelete}(D)$ with $D:=S_{y} \setminus S_{y+1}$.
\end{enumerate}
Note that $V(T_y)=S_y$ for each $y \in \{0, \dots, q\}$.
The sequence is \emph{complete} if $h(T_q)\leq q\cdot(k+1)$.
%$q=y^*$.

For $k\geq 7$ and a $3$-chunking sequence $S_1,\ldots,S_h$, we define
a \emph{$k$-bulk tree sequence} based on $S_1,\ldots,S_h$ to be a sequence $T_1, \dots, T_h$ of binary search trees satisfying:
$T_1$ is a perfectly balanced binary search tree with $V(T_1)=S_1$, and
there exist indices $h_1,h_2,\ldots,h_{\ell}$ with $1=h_1 < h_2 < \cdots <h_{\ell} = h$  such that $T_{h_j}, T_{h_j+1},\ldots,T_{h_{j+1}}$ is a complete one-phase $k$-bulk tree sequence based on $S_{h_j}, S_{h_j+1},\ldots,S_{h_{j+1}}$
for each $j\in\{1,\ldots,\ell-2\}$, and $T_{h_{\ell-1}}, T_{h_{\ell-1}+1},\ldots,T_{h_{\ell}}$ is a (non-necessarily complete) one-phase $k$-bulk tree sequence based on $S_{h_{\ell-1}},S_{h_{\ell-1}+1},\ldots,S_{h_{\ell}}$.


This will not be needed until the final sections, but it is helpful to keep in mind that we will ultimately take $k=\left\lceil\sqrt{\log n / \log \log n}\right\rceil$ when considering a $k$-bulk tree sequence built for our $n$-vertex graph $G$, so that the expression $\Oh(k+k^{-1}\log n)$ (which appears many times in what follows), is $\omega(1)$ and $o(\log n)$.

\begin{lem}\lemlabel{bulktree-old-B-properties}
Let $T_0,\ldots,T_{q}$ be a one-phase $k$-bulk tree sequence.
Then, for each $y\in\{0,\ldots,q\}$
\begin{compactenum}[(i)]
\item $h(T_y)\le h(T_0) + 3y$;\label{lemma-item-B1}
\item each subtree of $T_y$ rooted at a node of depth $y\cdot (k+1)$ has size at most
%$|T_0|\cdot\left(7/2^k\right)^{y}$.\label{lemma-item-B2}
$|T_0|\cdot2^{-y(k-3)}$.\label{lemma-item-B2}
\end{compactenum}
\end{lem}
\begin{proof}
The proof is by induction on $y$.  For the base case $y=0$, both properties are trivial: \itemref{lemma-item-B1} asserts that $h(T_0)\le h(T_0)$ and \itemref{lemma-item-B2} asserts that the subtree of $T_0$ rooted at the root of $T_0$ has size at most $|T_0|$.

  For the inductive step, assume $y+1\ge 0$ and \itemref{lemma-item-B1} holds for $T_{y}$.
  In order to get $T_{y+1}$, we first apply $\textsc{BulkBalance}(y\cdot (k+1),k)$ to $T_y$ to obtain $T'$.
  By~\lemref{balance-depth}, we have $h(T') \le h(T_y)+1$.
  Let $I:=V(T_{y+1})\setminus V(T') = V(T_{y+1})\setminus V(T_y)$.
  Since $V(T_y)$ $3$-chunks $V(T_{y+1})$ we know that $V(T')$ $3$-chunks $I$.
  Next we apply $\textsc{BulkInsert}(I)$ to $T'$ to obtain $T''$.
  Thus, by~\lemref{insertion-depth} we have $h(T'') \le h(T')+2$.
  Finally, we apply $\textsc{BulkDelete}(D)$ to $T''$ and obtain $T_{y+1}$, where $D:=V(T_{y})\setminus V(T_{y+1})$.
  By~\lemref{deletion-signature}, we have $h(T_{y+1}) \le h(T'')$.
  Altogether we have
  \[
  h(T_{y+1}) \le h(T'') \le h(T') +2 \le h(T_y) +3 \le h(T_0) + 3y +3 = h(T_0) + 3(y+1).
  \]
  Thus, \itemref{lemma-item-B1} holds for $T_{y+1}$.

    Next we establish \itemref{lemma-item-B2}.
    Assume that \itemref{lemma-item-B2} holds for $T_{y}$.
    Thus, every subtree of $T_{y}$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|\cdot2^{-y(k-3)}$.
    Again, the first step when constructing $T_{y+1}$ from $T_{y}$ is to apply $\textsc{BulkBalance}(y(k+1),k)$ to $T_{y}$.  By \lemref{balance-weight}, this results in a tree $T'$ in which every subtree rooted at a node of depth $(y+1)(k+1)$ has size at most $|T_{0}|\cdot 2^{-y(k-3)}\cdot 2^{-k}$.  The second step is to apply $\textsc{BulkInsert}(I)$ to $T'$ to obtain a new tree $T''$.
    By \lemref{insertion-size}, every subtree of $T''$ rooted at a node of depth $(y+1)(k+1)$ has size at most $|T_{0}|\cdot 2^{-y(k-3)}\cdot 8 \cdot 2^{-k}$.  Finally, the third step is to perform $\textsc{BulkDelete}(D)$ on $T''$ to obtain $T_{y+1}$.  Bulk deletion does not increase the size of any subtree, so every subtree of $T_{y+1}$ rooted at a node of depth $(y+1)(k+1)$ has size at most $|T_{0}|\cdot 2^{-(y+1)(k-3)}$, as desired.
\end{proof}

\begin{cor}\corlabel{height-y-star}
Let $T_0,\ldots,T_{q}$ be a one-phase $k$-bulk tree sequence.
Then,
\[
q \leq \left\lceil\tfrac{\log|T_0|}{k-3}\right\rceil.
\]
%\[
%h(T_{y^*}) \leq y^*(k+1).
%\]
\end{cor}
\begin{proof}
%Recall that $y^* = \left\lceil\frac{\log|T_0|}{k-3}\right\rceil$.
Arguing by contradiction, suppose that $q > \left\lceil\tfrac{\log|T_0|}{k-3}\right\rceil$.
Note that when we take the logarithm of the upper bound in \lemref{bulktree-old-B-properties}\itemref{lemma-item-B2} for $y:=\left\lceil\tfrac{\log|T_0|}{k-3}\right\rceil$,  we have
\[
\log|T_0| - \left\lceil\tfrac{\log|T_0|}{k-3}\right\rceil\cdot(k-3)
\leq \log|T_0|-\tfrac{\log|T_0|}{k-3}\cdot(k-3)
\leq0.
\]
Thus, each subtree of $T_{y}$ rooted at a node of depth $y(k+1)$ has size at most
\[
|T_0|\cdot2^{-y(k-3)} \leq 1,
\]
and hence $h(T_y) \leq y(k+1)$, which violates the height condition in the definition of a one-phase $k$-bulk tree sequence.
%%% OLD MATERIAL TO BE DELETED
% \begin{align*}
% h(T_q) &\leq q\cdot(k+1)
% \leq \left\lceil\tfrac{\log|T_0|}{k-3}\right\rceil \cdot (k+1)
% \leq \left(\tfrac{\log|T_0|}{k-3}+1\right) \cdot (k+1)\\
% &\leq \log|T_0| + \tfrac{4}{k-3}\cdot\log|T_0| + k+1
% \leq \log|T_0| + 4\tfrac{k}{k-3}\tfrac{1}{k}\log|T_0|+k+1\\
% &\leq \log|T_0| + 4\tfrac{7}{4}\tfrac{1}{k}\log|T_0|+k+1&&\textrm{(as $k\geq7$)}\\
% &=\log|T_0|+\Oh(k+k^{-1}\log|T_0|)
% \end{align*}
% \pnote{I put the whole proof above. Not clear though if it is a good idea to include this inequality on height. Perhaps not. Will think about it.}
\end{proof}

\begin{lem}\lemlabel{bulktree-height-i}
Let $T_0,\ldots,T_{q}$ be a complete one-phase $k$-bulk tree sequence, and let $r_0=h(T_0)-\log|T_0|$.  Then, for each $y\in\{0,\ldots,q\}$,
\begin{compactenum}[(i)]
\item $ |T_0|/8^y\le |T_y|$, and thus $\log|T_0| \le \log|T_y| + 3y$;\label{height-diff}
  \item $q=\Oh(k^{-1}\log|T_y|)$; \label{ystar-bound}
    \item $h(T_y)= \log|T_y| + r_0+\Oh(k^{-1}\log|T_y|) $; and
    \label{bulktree-height-item-i}
    \item $h(T_{q}) = \log|T_{q}|+\Oh(k+k^{-1}\log|T_{q}|)$.\label{bulktree-height-item-ii}
  \end{compactenum}
\end{lem}
\begin{proof}
Let $I_0,\ldots,I_{q-1}$ and $D_0,\ldots,D_{q-1}$ be the sets so that $T_{y+1}$ is obtained from $T_y$ by
rebalancing and then applying $\textsc{BulkInsert}(I_y)$ and $\textsc{BulkDelete}(D_y)$, for each $y\in\{0,\ldots,q-1\}$.
First, recall that by \lemref{insertion-size} and \lemref{deletion-size} we have $|T_{y+1}|\ge |T_y|/8$.
Iterating this starting with $T_0$ implies that $    |T_0|/8^y\le |T_y|$, and thus $\log|T_0| \le \log|T_y| + 3y$ for each $y\in\{0,\ldots,q\}$, which proves (\ref{height-diff}). 

\noindent By~\corref{height-y-star}, we have $q \leq \left\lceil\frac{\log|T_0|}{k-3}\right\rceil$.
Note that, for each $y\in\{0,\ldots,q\}$,  we have
\begin{align}
q
&\le \tfrac{\log |T_0|}{k-3}+1\le \tfrac{\log |T_y|+3q}{k-3}+1,
&\text{(by (\ref{height-diff}), and since $y\leq q$)}\nonumber\\
\intertext{and rewriting this yields (using that $k\geq 7$)}
%&\nonumber\\
q
&\le \tfrac{\log |T_y|}{k-6}+ \tfrac{k-3}{k-6} \leq \tfrac{k}{k-6}\cdot\tfrac{\log |T_y|}{k} + \tfrac{k-3}{k-6}\nonumber\\
&\leq 7\cdot\tfrac{\log |T_y|}{k} + 4= \Oh(k^{-1}\log|T_y|), \nonumber
\intertext{which proves (\ref{ystar-bound}). (\ref{bulktree-height-item-i}) follows as for each $y\in\{0,\ldots,q\}$, we have}
h(T_y)
& \le h(T_0) + 3y \nonumber
&\text{(by~\lemref{bulktree-old-B-properties}\itemref{lemma-item-B1})}\\
&= \log|T_0| + 3y + r_0  \nonumber\\
&\le \log |T_y| + 6y + r_0
&\text{(by (\ref{height-diff}))} \nonumber\\
&\le \log |T_y| + 6q + r_0
&\text{(since $y\le q$)}\nonumber\\
&= \log |T_y| + \Oh(k^{-1}\log|T_y|) + r_0.
&\text{(by (\ref{ystar-bound}))}\nonumber\\
\intertext{(\ref{bulktree-height-item-ii}) follows from}
h(T_{q})
& \le (k+1)q
&\text{(since the sequence is complete)}\nonumber\\
&\le (k+1)\left(\tfrac{\log|T_0|}{k-3} + 1\right)
%&\text{(by \eqref{y-star-def})}\nonumber\\
\nonumber\\
& = \left(\tfrac{k+1}{k-3}\right)\cdot\log|T_0| + (k+1)\nonumber\\
& \le \left(\tfrac{k+1}{k-3}\right)\cdot(\log|T_{q}| + 3q) + (k+1)
&\text{(by (\ref{height-diff}))}\nonumber\\
& = \log|T_{q}| + \tfrac{4}{k-3}\log|T_{q}| + 3\cdot\tfrac{k+1}{k-3}q + k+1\nonumber\\
& = \log|T_{q}| + \Oh(k+k^{-1}\log |T_{q}|).
&\text{(as $\tfrac{k+1}{k-3}\leq\tfrac{8}{5}$, and by (\ref{ystar-bound}))}\nonumber
\end{align}
\end{proof}


The following lemma shows that trees in a bulk tree sequence are balanced at all times:

\begin{lem}\lemlabel{bulk-tree-height}
  Let $T_1,\ldots,T_h$ be a $k$-bulk tree sequence and let $y\in\{1,\ldots,h\}$.
  Then
\[
h(T_y)\le \log|T_y| + \Oh(k+k^{-1}\log|T_y|).
\]
\end{lem}

\begin{proof}
  By the definition of a $k$-bulk tree sequence, $T_1$ is a perfectly balanced binary tree so $h(T_1)=\lceil\log|T_1|\rceil$ and the statement is satisfied for $y=1$.
  Let $h_1,h_2,\ldots,h_{\ell}$ be indices with $1=h_1 < h_2 < \cdots <h_{\ell} = h$ such that $T_{h_j},\ldots,T_{h_{j+1}}$ is a complete one-phase $k$-bulk tree sequence for each $j\in\{1,\ldots,\ell-2\}$, and $T_{h_{\ell-1}},\ldots,T_{h_{\ell}}$ is a one-phase $k$-bulk tree sequence.
  Let $Y:= \{h_1,h_2,\ldots,h_{\ell-1}\}$.
  For $y\in Y\setminus\{1\}$,
  \lemref{bulktree-height-i}(\ref{bulktree-height-item-ii}) implies that $T_y$ satisfies the conditions of the lemma.

  All that remains is to show that the conditions of the lemma are satisfied for each $y\in\{1,\ldots,h\}\setminus Y$. To show this, let $y_0=\max\{ y'\in Y: y'<y\}$.  That is, $T_{y_0}$ is the tree that began the one-phase $k$-bulk tree sequence in which $T_y$ takes part.
  %Let $y^*$ be defined as before with respect to the tree $T_{y_0}$, i.e., $y^*=\left\lceil\tfrac{\log |T_{y_0}|}{k-3}\right\rceil$.
  %=(1+o(1))k^{-1}\log |T_{y_0}|$.
  In this case, \lemref{bulktree-height-i}(\ref{bulktree-height-item-i}) implies that
  \[  h(T_y) \le \log |T_y| + \Oh(k^{-1}\log |T_y|) + h(T_{y_0})-\log|T_{y_0}|.\]
  Thus, all that is required is to show that $r_0:=h(T_{y_0})-\log|T_{y_0}|\in \Oh(k+k^{-1}\log|T_y|)$ so that is what we do.
  Note that by~\ref{ystar-bound}
  we have $y-y_0 = \Oh(k^{-1}\log|T_y|)$.
  \begin{align*}
    r_0 &= h(T_{y_0})-\log|T_{y_0}| \\
       &= \Oh(k + k^{-1}\log|T_{y_0}|)
        & \text{(by \lemref{bulktree-height-i}(\ref{bulktree-height-item-ii}))}\\
       &= \Oh(k + k^{-1}(\log|T_{y}| + 3(y-y_0)))
        & \text{(by \lemref{bulktree-height-i}(\ref{height-diff}))} \\
%       &= \Oh(k + k^{-1}\log|T_{y}| + k^{-1}y^*)
%        & \text{(since $y-y_0 \le y^*$)} \\
       &= \Oh(k + k^{-1}\log|T_{y}| + k^{-2}\log|T_{y}|) & \text{(by \lemref{bulktree-height-i}(\ref{ystar-bound}))} \\
       &= \Oh(k + k^{-1}\log|T_{y}|).  &  & \qedhere
  \end{align*}
\end{proof}


\subsection{Transition Codes for Nodes}
\seclabel{node-transitions}

We now arrive at the \emph{raison d'être} of bulk tree sequences:  For two consecutive trees $T_y$ and $T_{y+1}$ in a bulk tree sequence and any $z\in V(T_y)\cap V(T_{y+1})$, the signatures $\sigma_{T_y}(z)$ and $\sigma_{T_{y+1}}(z)$ are so closely related that $\sigma_{T_{y+1}}(z)$ can be derived from $\sigma_{T_y}(z)$ and a short \emph{transition code} $\nu_y(z)$.  The following lemma makes this precise.

\begin{lem}\lemlabel{node-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each $k$-bulk tree sequence $T_1,\ldots,T_h$, each $y\in\{1,\ldots,h-1\}$, and each $z\in V(T_y)\cap V(T_{y+1})$, there exists $\nu_y(z)\in\{0,1\}^*$ with $|\nu_y(z)| = \Oh(k\log h(T_y))$ such that $B(\sigma_{T_y}(z), \nu_y(z)) = \sigma_{T_{y+1}}(z)$.
\end{lem}

Before continuing, we extend the $\sigma$ notation slightly so that for any node $z\in V(T)$ and any $T$-ancestor $x$ of $z$, $\sigma_T(x,z):=\sigma_{T'}(z)$ where $T'$ is the subtree of $T$ rooted at $x$.

\snote{signature of external nodes?}

\begin{proof}
  Let $T_1,\ldots,T_h$ be a $k$-bulk tree sequence and let $y\in\{1,\ldots,h-1\}$. Let $I:=V(T_{y+1})\setminus V(T_y)$ and $D:=V(T_y) \setminus V(T_{y+1})$.
  Recall that the transformation of $T_{y}$ into $T_{y+1}$ occurs in three steps:
  applying $\textsc{BulkBalance}(\theta,k)$ to $T_y$ with the appropriate value of $\theta$ to obtain $T'$,
  applying $\textsc{BulkInsert}(I)$ to $T'$ to obtain $T''$, and
  applying $\textsc{BulkDelete}(D)$ to $T''$ to obtain $T_{y+1}$.
  Recall that whenever $\textsc{BulkBalance}(\theta,k)$ is applied in this context we have $\theta < h(T_y)$.

  By \lemref{deletion-signature}, \lemref{insertion-depth}, and \lemref{balance-depth} we have  $h(T_{y+1}) \leq h(T'') \leq h(T')+1 \leq h(T_y)+3$.
  Thus the heights of all these trees are $\Oh(h(T_y))$.

  Recall also that $\gamma:\mathbb{N}\to\{0,1\}^*$ is a prefix-free encoding of the natural numbers such that $|\gamma(i)|=\Oh(\log i)$, for every natural number $i$ as in~\lemref{elias}.

  Given a node $z$ appearing in both $T_y$ and $T_{y+1}$ we are going to describe $\nu_y(z)$.
  The transition code $\nu_y(z)$ consists of two parts $\nu_y^{\textsc{Bal}}(z)$ and $\nu_y^{\textsc{Del}}(z)$ devoted to different steps of the transformation from $T_y$ to $T_{y+1}$.

  The first part $\nu_y^{\textsc{Bal}}(z)$ will serve to move from $\sigma_{T_y}(z)$ to $\sigma_{T'}(z)$.
  Recall that $\textsc{BulkBalance}(\theta,k)$ calls $\textsc{Balance}(x,k)$ for each node $x$ of depth $\theta$  in $T_y$.
  %Thus, when $\theta>h(T_y)$ the operation is vacuous.
  %In this case, $\nu^{\textsc{Bal}}_y(z)$ is defined to be $0$.
  %Assume now that $\theta\leq h(T_y)$.
  Recall that the changes caused by $\textsc{Balance}(x,k)$ are limited to the subtree of $T_y$ rooted at $x$.
  Thus, $\sigma_{T_y}(z)$ can be affected by $\textsc{Balance}(x,k)$ only if $x$ is a $T_y$-ancestor of $z$.
  In particular when $|\sigma_{T_y}(z)| = d_{T_y}(z) \leq \theta$, the signature of $z$ does not change, that is, $\sigma_{T_y}(z)=\sigma_{T'}(z)$. In this case,  $\nu_y^{\textsc{Bal}}(z)$ is defined to be $\gamma(\theta)$.
  Note that in this case $|\nu^{\textsc{Bal}}_y(z)|=\Oh(\log\theta) = \Oh(\log h(T_y))$.

  Assume now that $d_{T_y}(z) > \theta$ and let $x$ be the $T_y$-ancestor of $z$ at depth $\theta$.
  Recall that the application of $\textsc{Balance}(x,k)$ first identifies two sets of nodes $Z$ and $X$ that eventually form a perfectly balanced tree $\hat{T}_0$ which forms the top part of the subtree rooted at $x$ in $T'$.
  This means that if $z\in Z\cup X$ then $\sigma_{T'}(x,z) =\sigma_{\hat{T_0}}(z)$.
  In this case, we define $\nu_y^{\textsc{Bal}}(z)$ to be $\gamma(\theta),0,\gamma(|\sigma_{T'}(x,z)|),\sigma_{T'}(x,z)$.
  Note that in this case $|\nu^{\textsc{Bal}}_y(z)|=\Oh(\log\theta) + \Oh(\log k) + \Oh(k) = \Oh(\log h(T_y) + k)$.

  Now we are left with the case that $d_{T_y}(z)> \theta$ and $z\not\in Z\cup X$. In particular, the node $z$ lies in some tree $T_i$ of the forest $T_y - Z$.
  (With a slight abuse of notations, here and further on we reuse the notations $T_i$, $T_{i,0},\ldots,T_{i,c_i}$, etc.\ introduced in the definition of $\textsc{Balance}(x,k)$.)
  Recall that $\textsc{Balance}(x,k)$ calls $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ on $T_i$ to obtain a sequence of trees $T_{i,0},\ldots,T_{i,c_i}$ and the node $z$ ends up in one of these trees, say in $T_{i,a}$.
  Note that
  \begin{compactenum}[(i)]
  \item $\sigma_{T_i}(z)$ is just a suffix of $\sigma_{T_y}(z)$;
  \item the application of $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ to $T_i$ calls $\textsc{Split}(x_{
  \lceil c_i/2\rceil})$ (given $c_i>0$) to obtain two trees $T_{<x_{\lceil c_i/2\rceil}}$ and $T_{>x_{\lceil c_i/2\rceil}}$, and then recursively calls $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,\lceil c_i/2\rceil-1})$  on $T_{<x_{i,\lceil c_i/2\rceil}}$ and $\textsc{MultiSplit}(x_{i,\lceil c_i/2\rceil+1},\ldots,x_{i,c_i})$  on $T_{>x_{i,\lceil c_i/2\rceil}}$;
  the node $z$ lies in one of the trees $T_{<x_{i,\lceil c_i/2\rceil}}$, $T_{>x_{i,\lceil c_i/2\rceil}}$ and by~\obsref{split-signature} the signature of $z$ in the new tree can be obtained from $\sigma_{T_i}(z)$ by deleting a prefix and replacing it with one of the $4h(T_i)$ strings in $\bigcup_{j=0}^{h(T_i)-1}\{0^j,0^j1,1^j,1^j0\}$;
  \item the application of $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ thus defines a sequence of trees starting with $T_i$ and ending with $T_{i,a}$ that all contain $z$;
  by~\lemref{split-height} the height of each of these trees is at most $h(T_i)$;
  the signature of $z$ in these trees, which is $\sigma_{T_i}(z)$ at the beginning, undergoes at most $1+\log c_i \leq 1+k$ changes
  before becoming $\sigma_{T_{i,a}}(z)$; let $b$ denote the number of these changes and, for each $j\in\{1,\ldots,b\}$, let $d_j$ be the length of the prefix of the signature being deleted during the $j$-th change and let $q_j\in \{1, \dots, 4h(T_i)\}$ be a number identifying the string that this prefix is replaced with during the $j$-th change (here we use that all the trees in the sequence have height at most $h(T_i)$).
  \end{compactenum}

  Finally, $\textsc{Balance}(x,k)$ replaces the external nodes of $\hat{T_0}$ with the trees output by \textsc{MultiSplit}$(x_{i,1},\ldots,x_{i,c_i})$.
  Let $z'$ be the external node of $\hat{T_0}$ that is replaced with $T_{i,a}$.
  Therefore, the signature of $z$ in $T'$ is the concatenation of $\sigma_{T_y}(x)$, $\sigma_{\hat{T_0}}(z')$, and $\sigma_{T_{i,a}}(z)$.
  We define $\nu^{\textsc{Bal}}_y(z)$ in this case as follows.
    \[
  \nu^{\textsc{Bal}}_y(z) := \gamma(\theta),1,\gamma(|\sigma_{\hat{T_0}}(x,z')|),\sigma_{\hat{T_0}}(x,z'),\gamma(b),
  \gamma(d_1),\gamma(q_1),\ldots,\gamma(d_b),\gamma(q_b).
  \]
  Note that in this case $|\nu^{\textsc{Bal}}_y(z)|=\Oh(\log\theta) + \Oh(\log k) + \Oh(k) + \Oh(\log k) + \Oh(2k\cdot\log h(T_y))=\Oh(k\log h(T_y))$.
  This completes the definition of $\nu^{\textsc{Bal}}_y(z)$.  Recall that the transformation of $T_{y}$ into $T_{y+1}$ occurs in three steps:
  applying $\textsc{BulkBalance}(\theta,k)$ to $T_y$ with the appropriate value of $\theta$ to obtain $T'$,
  applying $\textsc{BulkInsert}(I)$ to $T'$ to obtain $T''$, and
  applying $\textsc{BulkDelete}(D)$ to $T''$ to obtain $T_{y+1}$.
  Recall that whenever $\textsc{BulkBalance}(\theta,k)$ is applied in this context we have $\theta < h(T_y)$.


 Recall that the bulk insertion of new nodes in $T'$ does not affect the signature of existing nodes in the tree, since new nodes are inserted at the leaves of $T'$. We next describe $\nu^{\textsc{Del}}_y(z)$ that serves to reconstruct $\sigma_{T_{y+1}}(z)$ from $\sigma_{T''}(z)$.
  This turns out to be fairly easy.
  By~\lemref{deletion-signature} we have that $\sigma_{T_{y+1}}(z)$ is just a prefix of $\sigma_{T''}(z)$.
  Therefore, it is enough to define $\nu^{\textsc{Del}}_y(z)$ to be $\gamma(|\sigma_{T_{y+1}}(z)|)$.

  Finally, we define $\nu_y(z)$ to be the concatenation of $\nu^{\textsc{Bal}}_y(z)$ and $\nu^{\textsc{Del}}_y(z)$.
  It follows from the discussion above that $|\nu_y(z)| = \Oh(k\log h(T_y))$.

  The function $B$ is defined as expected:
  Given $\sigma_{T_{y}}(z)$ and $\nu_y(z)$, the function $B$ first decodes $\theta$ and checks whether $|\sigma_{T_y}(z)| \leq \theta$. If this is the case then the signatures of $z$ in $T_{y}$ and $T''$ are the same, and $B$ reads the rest of $\nu_y(z)$, which corresponds to $\nu^{\textsc{Del}}_y(z)$, and outputs the correct prefix of $\sigma_{T''}(z) = \sigma_{T'}(z) =\sigma_{T_{y}}(z)$.
  Note that the bulk insertion operation has no effect on the signature of $z$.

  If $|\sigma_{T_y}(z)| > \theta$ then $B$ reads the next bit of $\nu_y(z)$. If it is $0$ then this corresponds to the case where $z\in Z\cup X$ described above, and the information encoded after is enough to recover  $\sigma_{T'}(z)=\sigma_{T''}(z)$. The function $B$ then reads the $\nu^{\textsc{Del}}_y(z)$ part and outputs the correct prefix of $\sigma_{T''}(z)$, exactly as before.

  If the bit under consideration was $1$, then this corresponds to the case where $z\not\in Z\cup X$. The function $B$ then reads the rest of the information $\nu^{\textsc{Bal}}_y(z)$, which allows it to compute $\sigma_{T'}(z)=\sigma_{T''}(z)$, and the bulk deletion is once more handled exactly as before.
\end{proof}


\section{Subgraphs of $P\boxtimes P$}
\seclabel{pxp}

Before continuing, we show that using the techniques developed thus far, we can already solve a non-trivial special case.  In particular, we consider the case in which $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1$ is a path on $m$ vertices and $P_2$ is a path on $h$ vertices.  Thus, we identify each vertex of $G$ with a point $(x,y)\in\{1,\ldots,m\}\times \{1,\ldots,h\}$ in the $m\times h$ grid with diagonals, and $G$ is just a subgraph of this grid, see \figref{pxp}.
Obviously, we may assume that $m\leq n$ and $h\leq n$.

Our motivation for considering this special case is expository: The vertices of $P_1$ are integers $1,\ldots,m$ that can be stored directly in a binary search tree. This makes it easier to understand the role that bulk tree sequences play in our solution.  The extension of this solution to subgraphs of $H\boxtimes P$, which is the topic of \secref{hxp}, uses exactly the same ideas but requires another level of indirection since there is no natural mapping from the vertices of $H$ onto real numbers.

\begin{figure}
  \begin{center}
    \includegraphics{figs/pxp}
  \end{center}
  \caption{The special case where $G$ is a subgraph of $P_1\boxtimes P_2$.}
  \figlabel{pxp}
\end{figure}


\subsection{The Labels}

For each $y\in\{1,\ldots,h\}$, we let
\begin{align*}
L_y&=\{x:(x,y)\in V(G)\}, \textrm{ and}\\
L^-_y&=L_y\cup\{x-1:(x,y)\in V(G)\}.
\end{align*}
Note that $\sum_{y=1}^h |L_y| = n$.
Note also that $|L^-_y|\le 2|L_y|$ and thus $\sum_{y=1}^h |L^-_y|\le 2n$.
Let $L^-_0:=\emptyset$.

Let $V_1,\ldots,V_{h}$ be the $3$-chunking sequence obtained by applying~\lemref{fractional} to the sequence $L^-_{1}\cup L^-_{0},\ldots,L^-_{h}\cup L^-_{h-1}$.
Thus for each $y\in\{1,\ldots,h\}$, we have
\begin{align*}
V_y&\supseteq L^-_{y}\cup L^-_{y-1}, \textrm{ and}\\
\textstyle\sum_{y=1}^h |V_y|&\le 2\textstyle\sum_{y=1}^h |L^-_{y}\cup L^-_{y-1}|\leq 8n.
\end{align*}
Next, let $T_1,\ldots,T_h$ be a $k$-bulk tree sequence based on $V_1,\ldots,V_{h}$.
We discuss the asymptotically optimal choice for the value of $k$ at the end of the section.
By~\lemref{bulk-tree-height}, for each $y\in\{1,\ldots,h\}$, we have
\begin{align*}
h(T_y)&=\log|T_y| + \Oh(k+k^{-1}\log |T_y|)\\
&\leq\log|T_y| + \Oh(k+k^{-1}\log n).
\end{align*}

%By construction and by \lemref{bulk-tree-height}, the following properties are satisfied.
%\begin{enumerate}[label={(PR\arabic*)}, ref={PR\arabic*}, noitemsep]
%  \item $V(T_y)\supseteq L^-_{y}\cup L^-_{y-1}$ for each $y\in\{1,\ldots,h\}$;
%  \item $h(T_y)=\log|T_y| + \Oh(k+k^{-1}\log n)$ for each $y\in\{1,\ldots,h\}$, and
%  \item $\sum_{y=1}^h|T_y| \le 8n$.
%\end{enumerate}

Let $A:(\{0,1\}^{*})^2\to\{0,1\}^*$ be the function, given by \lemref{row-code} such that
using the weight function $w(y):=|T_y|$ for each $y\in\{1,\ldots,h\}$,
we have a prefix-free code $\alpha:\{1,\ldots,h\}\to\{0,1\}^*$ such that
\begin{align*}
|\alpha(y)|&=\log\left(\textstyle\sum_{i=1}^h|T_i|\right) - \log|T_y| + \Oh(\log\log h)\\
&\leq \log n - \log|T_y| + \Oh(\log\log n),
\end{align*}
for each $y\in\{1,\ldots,h\}$, and $A(\alpha(i),\alpha(j))$ outputs $0$, $1$, $-1$, or $\perp$, depending whether the value of $j$ is $i$, $i+1$, $i-1$, or some other value, respectively.


Let $B:(\{0,1\}^{*})^2\to\{0,1\}^*$ be the function, given by \lemref{node-transitions}, such that
for each $y\in\{1,\ldots,h-1\}$ and each $x\in L_{y}$,
there exists a code $\nu_{y}(x)$ with $|\nu_{y}(x)|=\Oh(k\log h(T_{y}))=\Oh(k\log\log n+k \log k)$ such that $B(\sigma_{T_{y}}(x),\nu_{y}(x))=\sigma_{T_{y+1}}(x)$.

Let $D:(\{0,1\}^{*})^2\to\{0,1\}^*$ be the function, given by \obsref{predecessor-encoding}, such that for every binary search tree $T$, and every $i$ such that $i-1$ and $i$ are in $T$, there exists $\delta_T(i) \in \{0,1\}^*$ with $|\delta_T(i)|=\Oh(\log h(T))$ such that
$D(\sigma_T(i),\delta_T(i))=\sigma_T(i-1)$.

Finally, given a vertex $v=(x,y)$ of $G$, we define
an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$. Note that some of these $8$ vertices may not even be present in $G$ in which case the resulting bit is set to $0$ since the edge is not present in $G$.

Now, in the labelling scheme for $G$, each vertex $v=(x,y)\in V(G)$ receives the following label:
\[
\alpha(y), \gamma(|\sigma_{T_y}(x)|), \sigma_{T_y}(x), \delta_{T_y}(x), \delta_{T_{y+1}}(x), \nu_y(x), a(v).
\]
%\begin{enumerate}[label={(GC\arabic*)}, ref={GC\arabic*}, noitemsep]
%  \item $\alpha(y)$;
%  \item $\gamma(|\sigma_{T_y}(x)|)$ and $\sigma_{T_y}(x)$;
%  \item\label{itm:PxP-deltas} $\delta_{T_y}(x)$ and $\delta_{T_{y+1}}(x)$; %(where $\delta_T$ is the function  introduced in \obsref{predecessor-encoding});
%  \item\label{itm:PxP-nu} $\nu_y(x)$; and
%  \item\label{itm:PXP-array} an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$.  (Note that some of these 8 vertices may not even be present in $G$ in which case the resulting bit is set to 0 since the edge is not present in $G$.)
%\end{enumerate}
Two major components of this label are $\alpha(y)$, of length $\log n - \log|T_y| + \Oh(\log\log n)$,
and $\sigma_{T_y}(x)$, of length $\log|T_y| + \Oh(k+k^{-1}\log n)$.
Together they have length $\log n + \Oh(k+k^{-1}\log n+\log\log n)$.
The lengths of the remaining components are as follows:
$\gamma(|\sigma_{T_y}(x)|)$,
$\delta_{T_y}(x)$, and $\delta_{T_{y+1}}(x)$
 have length $\Oh(\log\log n + \log k)$, $\nu_y(x)$ has length $\Oh(k\log\log n + k\log k)$, and $a(v)$ has length $\Oh(1)$.
Thus, in total the label has length  $\log n+ \Oh(k\log\log n + k\log k + k^{-1}\log n)$.

\pnote{Pat: Why does $k\log k$ suddenly show up in $|\nu_y(x)|$?  It doesn't appear in \lemref{node-transitions}.}

\subsection{Adjacency Testing}

First note that from a given label of $v=(x,y) \in V(G)$, we can decode each block of the label.
This is because $\alpha(y)$ is prefix-free, $\gamma(|\sigma_{T_y}(x)|)$ is prefix-free so when we read it we know how long is $\sigma_{T_y}(x)$ and we can isolate it as well.
The $\delta$-codes are prefix-free again and $\nu_y(x)$ can be decoded as outlined in the proof of \lemref{node-transitions}.
Finally, the last $8$-bits correspond to $a(v)$.

Given the labels of two vertices $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ in $G$ we can test if they are adjacent as follows.

Looking up the value of $A(\alpha(y_1),\alpha(y_2))$, we determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case we immediately conclude that $v_1$ and $v_2$ are not adjacent in $G$ since they are not adjacent even in $P_1\boxtimes P_2$. %since $y_1\neq y_2$ and $y_1y_2\not\in E(P_1)$.

  \item $y_1=y_2$: In this case, let $y:=y_1=y_2$.
  If the two bitstrings $\sigma_{T_y}(x_1)$, $\sigma_{T_y}(x_2)$ are the same,
  we conclude that $x_1=x_2$ and $y_1=y_2$, so $v_1=v_2$ and we should output that they are not adjacent.
  Otherwise, we
  lexicographically compare $\sigma_{T_y}(x_1)$ and $\sigma_{T_y}(x_2)$.
  Without loss of generality, $\sigma_{T_y}(x_1)$ is smaller than $\sigma_{T_y}(x_2)$.
  Therefore, by \obsref{lexicographic}, $x_1<x_2$.
  Now we compute $D(\sigma_{T_y}(x_2),\delta_{T_y}(x_2))=\sigma_{T_y}(x_2-1)$. If $\sigma_{T_y}(x_2-1)\neq \sigma_{T_y}(x_1)$, then we immediately conclude that $x_2 < x_1-1$, so $v_1$ and $v_2$ are not adjacent in $G$, since they are not adjacent even in $P_1\boxtimes P_2$.  Otherwise, we know that
  $v_1=(x_2-1,y)$ and $v_2=(x_2,y)$ are adjacent in $P_1\boxtimes P_2$.
  Now we use the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine if $v_1$ and $v_2$ are adjacent in $G$.

  \item $y_1=y_2-1$:
  In this case, we compute $B(\sigma_{T_{y_1}}(x_1), \nu_{y_1}(x_1))=\sigma_{T_{y_2}}(x_1)$.
  Let $y:=y_2$.
  If the two bitstrings $\sigma_{T_y}(x_1)$, $\sigma_{T_y}(x_2)$ are the same,
  we conclude that $x_1=x_2$. Thus $v_1=(x_1,y-1)$ and $v_2=(x_1,y)$ are adjacent in $P_1\boxtimes P_2$.
  Now we look up the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine
  if $v_1$ and $v_2$ are adjacent in $G$.
  Otherwise, we lexicographically compare $\sigma_{T_y}(x_1)$ and $\sigma_{T_y}(x_2)$.
  If $\sigma_{T_y}(x_1)$ is smaller than $\sigma_{T_y}(x_2)$, then we conclude that $x_1<x_2$.
  We compute $D(\sigma_{T_y}(x_2),\delta_{T_y}(x_2))=\sigma_{T_y}(x_2-1)$.
  If $\sigma_{T_y}(x_2-1)\neq \sigma_{T_y}(x_1)$, then we immediately conclude that $v_1$ and $v_2$ are not adjacent in $G$, since they are not adjacent even in $P_1\boxtimes P_2$.  Otherwise, we know that
  $v_1=(x_2-1,y-1)$ and $v_2=(x_2,y)$ are adjacent in $P_1\boxtimes P_2$.
  Now we use the relevant bit of $a(v_1)$ (or $a(v_2)$) to determine if $v_1$ and $v_2$ are adjacent in $G$.
  If $\sigma_{T_y}(x_1)$ is larger than $\sigma_{T_y}(x_2)$, then we conclude that $x_1>x_2$.
  Using $\sigma_{T_y}(x_1)$ and $\delta_{T_y}(x_1)$, we compute $\sigma_{T_y}(x_1-1)$ and proceed as in the previous case.
  Note here that it is important that the label for $v_1=(x_1,y_1)$ contains $\delta_{T_{y_1+1}}(x_1)=\delta_{T_{y}}(x_1)$.

  \item $y_2=y_1-1$: In this case, we compute $B(\sigma_{T_{y_2}}(x_2),\nu_{y_2}(x_2))=\sigma_{T_{y_1}}(x_2)$.  Now we proceed as in the previous case.
\end{enumerate}

This establishes our first result:

\begin{thm}\thmlabel{pxp}
  The family $\mathcal{G}$ of $n$-vertex subgraphs of a strong product $P\boxtimes P$ where $P$ is a path has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

\begin{rem}
  The $o(\log n)$ term in the label length of \thmref{pxp} is $\Oh(k\log\log n + k \log k + k^{-1}\log n)$.  An asymptotically optimal choice of $k$ is therefore $k=\max\{7,\left\lceil\sqrt{\log n / \log\log n}\right\rceil\}$, yielding labels of length $\log n + \Oh\left(\sqrt{\log n\log\log n}\right)$.
\end{rem}

%==============
% Section 5
%==============

\section{Subgraphs of $H\boxtimes P$}
\seclabel{hxp}

In this section we describe adjacency labelling schemes for graphs $G$ that are subgraphs of $H\boxtimes P$ where $H$ is a graph of treewidth $t$ and $P=1,2,\ldots,h$ is a path.


Let $t$ be a positive integer.
A graph $H$ is a \emph{$t$-tree}\footnote{For convenience, we work with a slightly more general definition of a $t$-tree than the one usually in the literature.} if there is an ordering $v_1,\ldots,v_m$ of $V(H)$ such that 
for every $i\in\{1,\ldots,m\}$, the neighbors of $v_i$ earlier in the order, i.e.\ $N_H(v_i) \cap \{v_1,\ldots,v_{i-1}\}$ induce a clique of size at most $t$ in $H$.
It is well-known that every graph of treewidth $t$ is a subgraph of a $t$-tree. 
For this reason, we may restrict ourselves to the case where $H$ is a $t$-tree, which we do.


Given a $t$-tree $H$, we fix a witnessing vertex ordering $v_1,\ldots,v_m$.
For every $i\in\{1,\ldots,m\}$, the \emph{family clique} $C_H(v_i)$ is defined as
$N_H[v_i]\cap \{v_1,\ldots,v_{i}\}$. 
Note that $v_i \in C_H(v_i)$.

\subsection{$t$-Trees and Interval Graphs}

For two real numbers $a$ and $b$ with $a<b$ by $[a,b]$ we denote the set $\{ x\in\R: a\le x\le b\}$ also called an \emph{interval}.
For a (finite) set of intervals $S$, 
the \emph{interval intersection graph} $G_S$ of $S$ is the graph 
with vertex set $V(G_S):=S$ and in which there is an edge between two distinct intervals 
if and only if the intervals intersect.
The \emph{clique number} $\omega(G)$ of a graph $G$ is just the maximum size of a clique in $G$.
By Helly's property, for a family of intervals $S$, 
the clique number $\omega(G_S)$ 
is equal to $\max_{x\in\R}|\{v\in V(G_S):x\in v\}|$.

The following well-known result states that every $m$-vertex $t$-tree is a subgraph of an interval graph of clique number $\Oh(t\log m)$.\footnote{The specific value $\log_3 (2m+1)$ in \lemref{interval-representation} is obtained by applying a result of Scheffler \cite{scheffler:optimal} on the tree underlying the width-$t$ tree decomposition of $H$.}

\begin{lem}\lemlabel{interval-representation}
  For every $m$-vertex $t$-tree $H$, there exists a mapping $f$ assigning to every $v\in V(H)$ an interval $f(v)$ so that the following holds. Let $S:=\{f(v):v\in V(H)\}$. Then,
\begin{compactenum}
  \item $f(v)$ intersects $f(w)$, so $f(v)f(w)\in E(G_S)$, whenever $vw\in E(H)$, and 
  \item $\omega(G_S) \leq (t+1)\log_3(2m+1)$.
\end{compactenum}
%
%  Furthermore, for every proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$ of $H$, there exists a proper colouring $\varphi':V(G_S)\to\{1,\ldots,\lfloor\log_3(2m+1)\rfloor\}\times\{1,\ldots,t+1\}$ of $G_S$ where, for each $v\in V(H)$, $\varphi'(f(v))=(j,\varphi(v))$ for some $j\in\{1,\ldots,\lfloor\log_3(2m+1)\rfloor\}$.
\end{lem}

In light of \lemref{interval-representation}, 
we will fix the mapping $f$, as an \emph{interval representation} of our $t$-tree $H$, and we will not distinguish between a vertex $v\in V(H)$ and the interval $f(v):=[a_v,b_v]$. 
Furthermore, we assume that all the endpoints of intervals in the represention are distinct. 
This can be easilly achieved by local perturbations not changing the intersection graph.

A finite set $X\subset\R$ \emph{stabs} a family of intervals $S$, 
if $X\cap [a,b]\neq\emptyset$ for every $[a,b]\in S$. 
Consider a binary search tree $T$ such that $V(T)$ stabs a family of intervals $\{f(v):v\in V(H)\}$. 
Then, we say that $T$ \emph{stabs} $H$. 
For $v \in V(H)$, we let $x_T(v)$ denote the lowest common $T$-ancestor of $V(T)\cap f(v)$, see \figref{x}.
For $V \subseteq V(H)$, we let $x_T(V)$ denote the lowest common $T$-ancestor of $V(T)\cap \bigcup_{v\in V} f(v)$.

\begin{figure}
  \begin{center}
    \includegraphics{figs/x}
  \end{center}
  \caption{The definition of $x_T(v)$.}
  \figlabel{x}
\end{figure}


\begin{lem}\lemlabel{all-the-obs-about-bst-and-intervals}
%If $T$ is a binary search tree such that $V(T)$ stabs $v=[a_v,b_v]$, then  $x_T(v)\in [a_v,b_v]$.
Let $H$ be a $t$-tree with a fixed interval representation $v\to[a_v,b_v]$. 
Let $T$ be a binary search tree that stabs $H$. 
Then,
\begin{compactenum}
  \item for every $v$ in $H$, we have $x_{T}(v) \in [a_v,b_v]$; and
  \item for every clique $C$ in $H$, the set of nodes $\{x_T(v)\mid v\in C\}$ lie in a single root-to-leaf path in $T$.
\end{compactenum}
\end{lem}
\begin{proof}
  For the proof of the first item, consider $x:=x_T(v)$.
  Either we have $x\in V(T)\cap[a_v,b_v]$, in which case there is nothing to prove, 
  or there are two nodes $x_1,x_2\in V(T)\cap[a_v,b_v]$ such that $x_1$ is in the subtree of $T$ rooted at the left child of $x$ and $x_2$ is in the subtree of $T$ rooted at the right child of $x$.  
  By the binary search tree property, $x_1<x<x_2$. 
  But $x_1,x_2 \in [a_v,b_v]$, so $a_v\le x_1<x<x_2\le b_v$, so $x\in [a_v,b_v]$, as desired.

  For the proof of the second item, we just show it for $C$ being of size $2$, so inducing a single edge. 
  The statement for general cliques will follow immediately by induction.
  Thus, consider two adjacent vertices $u_1$ and $u_2$ in $H$ and 
  let $x_1=x_T(u_1)$ and $x_2=x_T(u_2)$.
  In order to get a contradiction, suppose that $x_1$ and $x_2$ do not lie on a single root-to-leaf path in $T$. 
  Then there exists $x$ in $T$ such that $x_1$ is in the left subtree of $x$ and $x_2$ is in the right subtree of $x$.
  In particulcar, $x_1 < x < x_2$ by the property of the binary search tree.
  Since $u_1u_2 \in E(H)$ the corresponsing intervals $[a_{u_1},b_{u_1}]$, $[a_{u_2}, b_{u_2}]$ intersect, so their union is an interval as well. 
  Since $x_1,x_2$ lies in the union and $x_1 < x < x_2$, the node $x$ lies in the union as well.
  Therefore $x\in[a_{u_1},b_{u_1}]$ or $x\in [a_{u_2}, b_{u_2}]$. 
  This contradicts the choice of $x_T(u_1)$ or $x_T(u_2)$ and completes the proof of the second item.
\end{proof}

\subsection{A Labelling Scheme for $t$-trees}

We describe a labelling scheme for $t$-trees that, like our labelling scheme for paths, is based on a binary search tree.  The ideas behind this scheme are not new; this is essentially the labelling scheme for $t$-trees described by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  However, we present these ideas in a manner that makes it natural to generalize the results of \secref{pxp}.


We are given a $t$-tree $H$ on $m$ vertices with a fixed witnessing vertex-ordering,
and an interval representation $v\to[a_v,b_v]$ as in~\lemref{interval-representation}. 
In particular, the clique number of obtained interval graph is at most $(t+1)\log_3 (2m+1)$.
Since interval graphs are perfect, their clique number coincides with their chromatic number.
Let $\varphi': V(H) \to [(t+1)\log_3 (2m+1)]$ be a coloring such that $u$ and $v$ have distinct colors, whenever the intervals of $u$ and $v$ intersect. 

The following easy observation shows that a vertex $v$ of $H$ is uniquely identified by 
$x_T(v)$ and $\varphi'(v)$. This gives ground for an adjacency labelling scheme.

\begin{obs}\obslabel{unique-id}
    Let $T$ be a binary search tree that stabs $H$.
    Let $u$ and $v$ be two distinct vertices in $H$. 
    Then, $x_T(u)\neq x_T(v)$ or $\varphi'(u)\neq\varphi'(v)$. 
    Consequently, $\sigma_T(x_T(v))\neq \sigma_T(x_T(w))$ or $\varphi'(v)\neq\varphi'(w)$.
\end{obs}

\begin{proof}
  If $x_T(u)=x_T(v)=:x$, the intervals $[a_u,b_u]$ and $[a_v,b_v]$ each contain $x$, 
  so they intersect. 
  Therefore, $\varphi'(v)\neq\varphi'(w)$.% since $\varphi'$ is a proper colouring of $G_S$.  The second, equivalent, statement of the observation is immediate from the fact that $\sigma_T: V(T)\to\{0,1\}^*$ is injective, so $\sigma_T(x)$ uniquely identifies $x$.
\end{proof}

Let $T$ be a binary search tree that stabs $H$ and let $v\in V(H)$.
%For any binary search tree that represents $v$, 
We define $P_T(v)$ to be the path in $T$ that begins at the root of $T$ and ends at the node in $x_T(C_H(v))$ of maximum depth. 
By \lemref{all-the-obs-about-bst-and-intervals}, $P_T(v)$ is well defined and contains every node in $x_T(C_H(v))$. 
Let $\sigma_T(v):=\sigma_T(x_T(C_H(v)))$.

Now, we define the label of a vertex $v$ in $H$. 
Let $d=|C_H(v)|$ and let $u_1,\ldots, u_d$ be the vertices in $C_H(v)$, so $v$ is one of them. 
Recall that $\gamma$ is the Elias encoding of natural numbers.
The label of $v$ is defined to be:
\[
\gamma(d_T(v)), \sigma_T(v), \gamma(\varphi'(v)), \gamma(d), 
\gamma(d_T(u_1)), \gamma(\varphi'(u_1)), \ldots,
\gamma(d_T(u_d)), \gamma(\varphi'(u_d)).
\]
To bound the length of the labels, note that 
$d_T(w) = |\sigma_T(w)|\leq h(T)$, for all $w$ in $T$. 
Moreover, $d\leq t+1$ and $\varphi'$ takes values bounded in $\Oh(t\log m)$. 
Thus, in total the label has length at most 
$h(T) + \Oh(t\cdot (\log h(T) + \log t + \log\log m))$.


For the adjacency testing, first note that from a given label of $v$ in $H$, we can decode each block of the label. 
This is just because $\gamma$, the Elias encoding, is prefix-free. 
Note also that given all the blocks of the label, 
we can determine $\sigma_T(x_T(v))$ and $\varphi'(v)$.

Given the labels of two vertices $v$ and $w$ in $H$ we can test if they are adjacent as follows.
\begin{enumerate}
  \item If $\sigma_T(x_T(v)) = \sigma_T(x_T(w))$ and $\varphi'(v)=\varphi'(w)$, we conclude that $v=w$ (by~\obsref{unique-id}) so they are not adjacent in $H$. 
  \item Let $d=|C_H(v)|$ and $u_1,\ldots, u_d$ be the vertices in $C_H(v)$. 
  From the label of $v$, we decode $\sigma_T(x_T(u_i))$ and $\varphi'(u_i)$ for each $i\in\{1,\ldots,d\}$.
  If $\sigma_T(x_T(w)) = \sigma_T(x_T(u_i))$ and $\varphi'(w)=\varphi'(u_i)$, for some $i\in\{1,\ldots,d\}$, then we conclude that $w=u_i$ and therefore $v$ and $w$ are adjacent in $H$.
  \item  Now, let $d=|C_H(w)|$ and let $u_1,\ldots, u_d$ be the vertices in $C_H(w)$. 
  From the label of $w$, we decode $\sigma_T(x_T(u_i))$ and $\varphi'(u_i)$ for each $i\in\{1,\ldots,d\}$.
  If $\sigma_T(x_T(v)) = \sigma_T(x_T(u_i))$ and $\varphi'(v)=\varphi'(u_i)$, for some $i\in\{1,\ldots,d\}$, then we conclude that $v=u_i$ and therefore $v$ and $w$ are adjacent in $H$.
  \item Otherwise, $v$ and $w$ are not adjacent in $H$. 
  This is because each edge in $H$ connects a vertex $u$ with a vertex in $C_H(u)$, for some $u$ in $H$.
\end{enumerate}

This proves the following result. 

\begin{lem}\lemlabel{t-tree-labelling}
  There exists a function $F:(\{0,1\}^2)\to\{0,1\}$ such that
  for any $t$-tree $H$ on $m$ vertices 
  with a proper vertex-coloring $\varphi'$ of its interval representation using $C$ colors,
  and any binary search tree $T$ stabbing $H$,
  there is a labelling $\tau_T(u)$ for $u$ in $H$ such that 
  $|\tau_T(u)| = h(T) + \log t + \Oh(t\cdot(\log C + \log h(T))$ for $u$ in $H$, and
  for every $v,w \in V(H)$, we have
  \[
      F(\tau_{T}(v),\tau_{T}(w)) = \begin{cases}
      0 & \text{if $v=w$;} \\
      -1 & \text{if $v$ and $w$ are adjacent in $H$, and $w\in C_H(v)$;} \\
      1 & \text{if $v$ and $w$ are adjacent in $H$, and $v\in C_H(w)$;} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{lem}
In particular, we can take $\varphi'$ using $\Oh(t\cdot\log m)$ colors and get labels of length 
$h(T)+\Oh(t\log t + t\log\log m + t\log h(T))$.


\subsection{Interval Transition Labels}

We now show that the solution presented in \secref{pxp} generalizes to the current setting.

% of subgraphs of $H\boxtimes P$.  The only additional complication comes from the fact that each node $x$ in the binary search tree $T$ is equipped with a set $B_x:=\{v\in V(H):x_T(v)=x\}$ of intervals.  Any structural changes that we make to $T$ may result in changes to $B_x$, which result in changes to the labels of any vertex $v\in V(H)$ such that an element of $C_H(v)$ leaves or enters $B_x$.  We must show that these changes can be encoded using few bits.  We now proceed.

Let $G$ be an $n$-vertex subgraph of $H\boxtimes P$ where $H$ is an $m$-vertex $t$-tree and $P=1,\ldots,h$ is a path. 
Fix an interval representation of $H$ with clique number at most $\lfloor\log_3 (2m+1)\rfloor\}$, see~\lemref{interval-representation}. 
As before, we often do not distinguish between a vertex $v$ in $H$ and its interval $[a_v,b_v]$.
Let $\varphi':V(H)\to\{1,\ldots,\lfloor\log_3 (2m+1)\rfloor\}$ be a proper colouring the interval representation of $H$.

For each $y\in\{1,\ldots,h\}$, let 
\begin{align*}
S_y&=\{v\in V(H): (v,y)\in V(G)\}, \text{ and}\\
S^-_y&=\textstyle\bigcup_{v\in S_y} C_H(v).
\end{align*}
Note that $\sum_{y=1}^h |S_y| =n$ and $|S_y^-| \leq (t+1)|S_y|$. 
Thus $\sum_{y=1}^h |S_y^-| \leq (t+1)n$. 
Let $S^-_0=\emptyset$. 
For each $y\in\{1,\ldots,h\}$, let $X_y\subset\R$ be the set of all endpoints of intervals in $S^-_y\cup S^-_{y-1}$. 
Observe that any binary search tree $T_y$ with $V(T_y)\supseteq X_y$ stabs every interval of a vertex $w\in C_H(v)$ for any $v\in S_y\cup S_{y-1}$.
Apply \lemref{fractional} to the sequence $X_1,\ldots,X_h$ to obtain a $3$-chunking sequence $V_1,\ldots,V_{h}$ such that $V_y\supseteq X_y$ for each $y\in\{1,\ldots,h\}$, and $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |X_y|$.
Let $T_1,\ldots,T_h$ be a $k$-bulk tree sequence based on $V_1,\ldots,V_{h}$ with $k=\max\{7,\left\lceil\sqrt{\log n / \log\log n}\right\rceil\}$.
By construction, we have
\[
\textstyle\sum_{y=1}^h |T_y| \le 2\textstyle\sum_{y=1}^h |X_y| \le 4\textstyle\sum_{y=1}^h |S^-_y\cup S^-_{y-1}| \le 8(t+1)n.
\]
By \lemref{bulk-tree-height}, for each $y\in\{1,\ldots,h\}$ we have
% and \lemref{node-transitions}, the following properties are satisfied.
\begin{align*}
h(T_y)&= \log |T_y| + \Oh(k+k^{-1}\log |T_y|)\\
&\leq \log |T_y| + \Oh(k+k^{-1}\log n).
\end{align*}

%\begin{compactenum}[(PR1)]  %[label={(PR1)}, noitemsep]
%  \item $V(T_y)\supseteq X_y$ for each $y\in\{1,\ldots,h\}$;
%  \item $h(T_y)= \log |T_y| + \Oh(k+k^{-1}\log |T_y|)= \log |T_y| + o(\log n)$ for each %$y\in\{1,\ldots,h\}$;
%  \item $W:=\sum_{y=1}^h |T_y|= \Oh(tn)$, and
%  \item There is a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each $y\in\{1,\ldots,h-1\}$ and each $x\in V(T_y)\cap V(T_{y+1})$, there is a string $\nu_y(x)$ such that $B(\sigma_{T_y}(x),\nu_y(x))=\sigma_{T_{y+1}}(x)$ and $|\nu_y(x)|=\Oh(k\log\log n)=o(\log n)$.
%\end{compactenum}

The following lemma, which is analogous to \lemref{node-transitions}, is the last piece of the puzzle needed for an adjacency labelling scheme for subgraphs of $H\boxtimes P$. Recall that the notation $\sigma_T(v)$ and $P_T(v)$, used below in the context of a vertex $v=[a_v,b_v]$ in a $t$-tree, has been introduced shortly after \obsref{unique-id}.

\begin{lem}\lemlabel{interval-transitions}
  There exists a function $J:(\{0,1\}^*)^2\to \{0,1\}^*$ such that, 
  for any $H$, $P$, $G$, $\varphi'$, $S_1,\ldots,S_h$, $X_1,\ldots,X_h$, and each $k$-bulk tree sequence $T_1,\ldots,T_h$ defined as above, for each $y\in\{1,\ldots,h-1\}$ and each $v\in S_y$, there exists $\mu_y(v)\in\{0,1\}^*$ with $|\mu_y(v)|= \Oh(k\log h(T_y))$ such that $J(\sigma_{T_y}(v), \mu_y(v))=\sigma_{T_{y+1}}(v)$.
\end{lem}

\begin{proof}
  First we recall that, if $v\in S_y$, 
  then $C_H(v) \subseteq S^-_y$. 
  Thus, $C_H(v)$ is stabbed by $V(T_y)$ and $V(T_{y+1})$.
  Let $I:=V(T_{y+1})\setminus V(T_{y})$ and $D:=V(T_y)\setminus V(T_{y+1})$.
  As in the proof of \lemref{node-transitions}, we must dig into the details of the three bulk tree operations that transform $T_y$ into $T_{y+1}$. 
  Recall that the three steps are: 
  applying $\textsc{BulkBalance}(\theta,k)$ to $T_y$ with the appropriate value of $\theta$ to obtain $T'$,
  applying $\textsc{BulkInsert}(I)$ to $T'$ to obtain $T''$, and
  applying $\textsc{BulkDelete}(D)$ to $T''$ to obtain $T_{y+1}$.
  Recall that whenever $\textsc{BulkBalance}(\theta,k)$ is applied in this context we have $\theta < h(T_y)$.

\snote{Piotrek: We shall still go over this proof. So far I just changed obvious typos/mistakes.}


  The bulk insertion that converts $T'$ into $T''$ is the simplest to handle.  For any $v\in S_y$, $P_{T'}(v)$ is the path from the root of $T'$ to the deepest node in $x_{T'}(C_H(v))$.  Furthermore, for each $w=[a_w,b_w]\in C_H(v)$, $x_{T'}(w)$ is the element of $w\cap V(T')$ that is closest to the root of $T'$. Since $T''$ is a supergraph of $T'$ obtained by adding small subtrees at the external nodes of $T'$, $x_{T''}(w)=x_{T'}(w)$ for each $w\in C_H(v)$.  Therefore $P_{T''}(x_{T''}(w))=P_{T'}(x_{T'}(w))$ and $\sigma_{T''}(x_{T''}(w))=\sigma_{T'}(x_{T'}(w))$ for each $w\in C_H(v)$, so $\sigma_{T''}(v)=\sigma_{T'}(v)$ for each $v\in S_y$.

  Next we consider the bulk deletion that converts $T''$ into $T_{y+1}$.  A bulk deletion consists of a sequence of individual deletions. Consider one such deletion and let $T$ and $\tilde{T}$ denote the tree before and after the deletion, respectively.

  \begin{clm}\clmlabel{deletion-ancestor}
    For any $v=[a_v,b_v]\in S_y$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))$ is a prefix of $\sigma_T(x_T(v))$.
  \end{clm}

  \begin{proof}[Proof of \clmref{deletion-ancestor}]
    See \figref{deletion-t-tree}.  At a global level, the deletion of a value $x$ from $T$ involves finding a sequence of consecutive values $x_0<x_1<\cdots<x_r$ or $x_0>x_1>\cdots>x_r$ where $x=x_0$, $x_r$ is a leaf and $x_{i-1}$ is a $T$-ancestor of $x_{i}$ for each $i\in\{1,\ldots,r\}$.  The leaf containing $x_r$ is deleted and, for each $i\in\{0,\ldots,r-1\}$, the (value of) $x_i$ is replaced with (the value in) node $x_{i+1}$.

    \begin{figure}
      \begin{center}
        \includegraphics{figs/deletion-t-tree-1}\\[1ex]
        $\Downarrow$\\[1ex]
        \includegraphics{figs/deletion-t-tree-2}
      \end{center}
      \caption{The effect of a single deletion on $x_T(v)$.}
      \figlabel{deletion-t-tree}
    \end{figure}

    If $x_T(v)=x_0$ then recall that $v\in S_y\subseteq S^-_y$ and $X_{y+1}\subseteq V(T_{y+1})$ contains both endpoints of each interval in $S^-_{y+1}\cup S^-_y$.  Therefore $a_v,b_v\in V(T_{y+1})$.  Therefore $r\ge 1$ and $x_1\in [a_v,b_v]$ so $x_{\tilde{T}}(v)=x_1$ and $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_T(x_T(v))$.

    If $x_T(v)=x_i$ for some $i\in\{1,\ldots,r\}$, then $x_{\tilde{T}}(v)=x_i$ (see the interval $v_1$ in \figref{deletion-t-tree}) and $\sigma_{\tilde{T}}(x_i)=\sigma_{T}(x_{i-1})$.  Since $x_{i-1}$ is a $T$-ancestor of $x_i$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_{\tilde{T}}(x_i)$ is a prefix of $\sigma_{T}(x_{T}(v))$, as required.

    Finally, if $x_T(v)\neq x_i$ for any $i\in\{0,\ldots,r\}$ and $x_T(v)\neq x_{\tilde{T}}(v)$, then the only possibility is that $x_{\tilde{T}}(v)=x_i$ for some $x_i\in [a_v,b_v]$ (see the interval $v_2$ in \figref{deletion-t-tree}).  This can only happen if $x_i$ is not a $T$-ancestor of $x_T(v)$, but $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$.  By \lemref{all-the-obs-about-bst-and-intervals}, $x_i$ is a $T$-descendant of $x_T(v)$.  Since $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$, $x_{i-1}$ is a $T$-ancestor of $x_T(v)$.  Therefore $\sigma_{\tilde{T}}(v)=\sigma_{\tilde{T}}(x_i)=\sigma_T(x_{i-1})$ is a prefix of $\sigma_T(x_T(v))$, as required.  This completes the proof of \clmref{deletion-ancestor}.
  \end{proof}

  For strings $a$ and $b$, let $a\preceq b$ denote that $a$ is a prefix of $b$.
  Since a bulk deletion is implemented as a sequence of individual deletions,
  \begin{align*}
    \sigma_{T_{y+1}}(v)
      & = \sigma_{T_{y+1}}(x_{T_{y+1}}(w)) & \text{(for some $w\in C_H(v)$)} \\
      & \preceq \sigma_{T''}(x_{T''}(w)) & \text{(by \clmref{deletion-ancestor})} \\
      & \preceq \sigma_{T''}(v). & \text{(by \lemref{all-the-obs-about-bst-and-intervals})}
  \end{align*}
  Therefore, by including $|\sigma_{T_{y+1}}(v)|$ in $\mu_y(v)$ we can derive $\sigma_{T_{y+1}}(v)$ from $\sigma_{T'}(v)$.  This requires only $\Oh(\log h({T_{y+1}}))=\Oh(\log h({T_y}))$ bits.

  Finally, we consider the rebalancing operation that takes $T_y$ onto $T'$ by calling \textsc{BulkBalance}$(\theta,k)$, which calls $\textsc{Balance}(x,k)$ on each depth-$\theta$ node $x$ of $T_y$ to restructure the subtree of $T_y$ rooted at $x$ (refer to \figref{rebalance-t-tree}). Therefore, for any $v\in S_y$, and any $\theta'\in\{0,\ldots,\theta\}$, the length-$\theta'$ prefix of $\sigma_{T_y}(v)$ and length-$\theta'$ prefix of $\sigma_{T'}(v)$ are the same.  By including the value of $\theta$ in $\mu_y(v)$, we then only need to consider the effect of the call to $\textsc{Balance}(x,k)$ where $x$ is the unique depth-$\theta$ node of $T_y$ contained in $P_{T_y}(v)$ (if any).

  \begin{figure}
    \begin{center}
      \includegraphics{figs/rebalance-t-tree}
    \end{center}
    \caption{Only the call to $\textsc{Balance}(x,k)$ on a node $x\in V(P_{T_y}(v))$ affects $\sigma_{T'}(v)$.}
    \figlabel{rebalance-t-tree}
  \end{figure}

  Let $T_*$ be the subtree of $T_y$ rooted at $x$ and let $T_*'$ be the new tree obtained after calling $\textsc{Balance}(x,k)$ on the root, $x$, of $T_*$. (So $T_*$ is a subtree of $T_y$ and $T_*'$ is a subtree of $T'$.)
  The transition code $\mu_y(v)$ will contain enough information to recover $\sigma_{T'}(v)$ from $\sigma_{T_y}(v)$.

  Now, $\textsc{Balance}(x,k)$ identifies two special node sets $Z$ and $X$ that it turns into a perfectly balanced binary search tree $\hat{T}_0$.  Eventually, $\hat{T}_0$ will become a subgraph of $T_*'$ that contains the root of $T_*'$.   In particular, every node in $V(T_*')$ has a $T_*'$-ancestor in $Z\cup X$.

  For any $v\in S_y$ such that $P_{T'}(v)$ ends at a vertex $z\in Z\cup X=V(\hat{T}_0)$, the problem is easy.  We include $\sigma_{\hat{T}_0}(z)$, which has length at most $h(\hat{T}_0)\le k$, in $\mu_y(v)$, and this (along with $\theta$) is sufficient to recover $\sigma_{T'}(v)$ from $\sigma_{T_y}(v)$.

  Thus, we only need to consider those $v\in S_v$ such that $P_{T'}(v)$ ends a vertex $z\not\in Z\cup X$ with $d_{T_y}(z)>\theta$.    By definition,  $z=x_{T'}(w)$ for some $w=[a_w,b_w]\in C_H(v)$.  By \lemref{all-the-obs-about-bst-and-intervals}, $z$ is the unique node of $P_{T'}(z)$ contained in $[a_w,b_w]$.  Therefore
  \begin{equation}
    [a_w,b_w]\cap (Z\cup X)=\emptyset \enspace . \eqlabel{empty}
  \end{equation}

  For each such node $v$, $P_{T_y}(v)$ has vertices (including $z$) in common with exactly one tree $T_{i}$ in the forest $T_*-Z$.  Then $\textsc{Balance}(x,k)$ calls $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ on the subtree $T_{i}$.  This, in turn results in zero or more calls to $\textsc{Split}(x)$ for nodes $x\in V(T_{i})$. The following claim explains the effect of one individual call to $\textsc{Split}(x)$:

  \begin{clm}\clmlabel{x-switch}
    Let $S$ be a set of intervals, let $T$ be a binary search tree where $V(T)$ stabs $S$, and let $T_{<x}$ and $T_{>x}$ be the two trees resulting from calling $\textsc{Split}(x)$ on $T$ for some $x\in V(T)$.  Then, for each $w=[a_w,b_w]\in S$ exactly one of the following is true:
    \begin{compactenum}
      \item $a_w\le x\le b_w$;
      \item $x< a_w$, in which case $x_{T_{>x}}(w)=x_T(w)$; or
      \item $b_w < x$, in which case $x_{T_{<x}}(w)=x_T(w)$.
    \end{compactenum}
  \end{clm}

  \begin{proof}
    That exactly one of the three cases applies is obvious.  Case~(1) has no specific requirements and Cases~(2) and (3) are symmetric, so we focus on Case~(2), so $x < a_w\le b_w$.

    By \lemref{all-the-obs-about-bst-and-intervals}, $z=x_T(v)$ is the unique node $z\in V(T)$ such that $P_T(z)$ has exactly one node $z\in [a_w,b_w]$.  Now $P_{T_{>x}}(z)$ is obtained from $P_T(z)$ by deleting all values less than or equal to $x$. Therefore $P_{T_{>x}}(z)$ has exactly one node in $[a_w,b_w]$, namely $z$, so $z=x_{T_{>x}}(w)$.  This completes the proof of \clmref{x-switch}.
  \end{proof}

  From \clmref{x-switch}, we can conclude that $P_{T'}(v)=P_{T'}(x_{T_y}(w))$ for some $w\in C_H(v)$.  Indeed, for the $w\in C_H(v)$ that determines $P_{T'}(v)=P_{T'}(x_{T'}(w))$ we have $x_{T'}(w)\not\in Z\cup X$ by \eqref{empty}. By \clmref{x-switch}, either $x_{T'}(w)=x_{T_y}(w)$ or at some point $\textsc{Split}(x)$ was called on some node $x\in[a_w,b_w]$.  But $\textsc{Split}(x)$ is only called on nodes $x\in X$ so, by \eqref{empty}, $x_{T'}(w)=x_{T_y}(w)$.

  Thus, for each $v\in S_y$ such that $x(v)\not\in Z\cup X$, there exists some $w\in C_H(v)$ with $x_{T'}(w)=x_{T_y}(w)$ such that $P_{T'}(v)=P_{T'}(x_{T_y}(w))$, so $\sigma_{T'}(v)=\sigma_{T'}(x_{T_y}(w))$.  By \lemref{all-the-obs-about-bst-and-intervals}, $\sigma_{T_y}(x_{T_y}(w))$ is a prefix of $\sigma_{T_y}(v)$ and the length of this prefix can be included in $\mu_y(v)$, which makes it possible to recover $\sigma_{T_y}(x_{T_y}(w))$ from $\sigma_{T_y}(v)$ .  By \lemref{node-transitions}, there exists a function $B$ and a string $\nu_y(x_{T_y}(w))$ of length $\Oh(k\log\log n)$ such that $B(\sigma_{T_y}(x_{T_y}(w)), \nu_y(x_{T_y}(w))) = \sigma_{T'}(x_{T_y}(w)) = \sigma_{T'}(v)$.

  Therefore, for any $v\in S_y$ there is a string $\mu_y(v)$ of length $\Oh(k\log h(T_y))$ that satisfies the conditions of the lemma.
\end{proof}

\subsection{The Labels}

We are read to combine everything together and devise labels for vertices of $G$.

Let $A:(\{0,1\}^{*})^2\to\{0,1\}^*$ be the function, given by \lemref{row-code} such that
using the weight function $w(y):=|T_y|$ for each $y\in\{1,\ldots,h\}$,
we have a prefix-free code $\alpha:\{1,\ldots,h\}\to\{0,1\}^*$ such that
\begin{align*}
|\alpha(y)|&=\log\left(\textstyle\sum_{i=1}^h|T_i|\right) - \log|T_y| + \Oh(\log\log h)\\
&\leq \log\bigl( 8(t+1)n\bigr) - \log|T_y| + \Oh(\log\log n)\\
&\leq \log n + \log t -\log|T_y| + \Oh(\log\log n),
\end{align*}
for each $y\in\{1,\ldots,h\}$, and $A(\alpha(i),\alpha(j))$ outputs $0$, $1$, $-1$, or $\perp$, depending whether the value of $j$ is $i$, $i+1$, $i-1$, or some other value, respectively.


Let $J:(\{0,1\}^{*})^2\to\{0,1\}^*$ be the function, given by \lemref{interval-transitions}, such that
for each $y\in\{1,\ldots,h-1\}$ and each $v\in S_{y}$,
there exists a code $\mu_{y}(x)$ with $|\mu_{y}(x)|=\Oh(k\log h(T_{y}))=\Oh(k\log\log n+k \log k)$ such that $J(\sigma_{T_{y}}(x),\mu_{y}(x))=\sigma_{T_{y+1}}(x)$.

%Piotrek: just copy-pasted stuff: ignore
%Finally, given a vertex $v=(x,y)$ of $G$, we define
%an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$. Note that some of these $8$ vertices may not even be present in $G$ in which case the resulting bit is set to $0$ since the edge is not present in $G$.

%Now, in the labelling scheme for $G$, each vertex $v=(x,y)\in V(G)$ receives the following label:
%\[
%\alpha(y), \gamma(|\sigma_{T_y}(x)|), \sigma_{T_y}(x), \delta_{T_y}(x), \delta_{T_{y+1}}(x), \nu_y(x), a(v).
%\]

\snote{Piotrek: I got here. Need to eat sth. Almost done.}

Summarizing, for any $n$-vertex subgraph $G$ of $H\boxtimes P$, each vertex $z=(v,y)\in V(G)$ has a label that contains the following information:

\begin{compactenum}[(PC1)]
  \item $\alpha(y)$ (given by \lemref{row-code});% of length $\log n-\log|T_y| + \Oh(\log\log n)$;
  \item $\sigma_{T_y}(v)$; % of length $\log|T_y| + \Oh(k+k^{-1}\log n)$;
  \item $d_{T_{y+b}}(x_{T_{y+b}}(p_j(v)))$ for each $j\in\{1,\ldots,t+1\}$ and $b\in\{0,1\}$;
    
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$;
  %\snote{L. I assume these $\varphi'$ should be replaced by $\tau$ of \lemref{t-tree-labelling}?}
  %\snote{Pat: No, just the colouring. $\tau_H(v)$ is the whole label.}
  \item $\varphi'(v)$;
  \item $\mu_y(v)$; and
  \item $a(z)$ (defined next).
  \end{compactenum}
  The only one of these quantities not yet defined is $a(z)$, which is a sequence of $3(t+1)$ bits that indicate which of the potential edges joining $z$ to elements of $\{(p_j(v),y+b): j\in\{1,\ldots,t+1\},\, b\in\{-1,0,1\}\}$ are actually present in $G$.

\subsection{Adjacency Testing}

Given the labels of $z_1:=(v_1,y_1)$ and $z_2:=(v_2,y_2)$ we test if $z_1z_2\in E(G)$ by first using $\alpha(y_1)$ and $\alpha(y_2)$ to determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case $y_1\neq y_2$ and $y_1y_2\not\in P$, so $z_1z_2\not\in E(H\boxtimes P)$, so $z_1z_2\not\in E(G)$.

  \item $y_1=y_2$.  Let $y=y_1=y_2$.  In this case (PC2)--(PC5) contains $\tau_{T_y}(v_1)$ and $\tau_{T_y}(v_2)$ (defined in \lemref{t-tree-labelling} using (TC1)--(TC4)) and we use this to test if $v_1v_2\in E(H)$.  If not, then $z_1z_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.

  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{T_y}(v_1)$ and $\tau_{T_y}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$ in $H$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=1$: Let $y=y_1$ (so that $y_2=y+1$).  We use $\mu_y(v_1)$ and $\sigma_{T_y}(v_1)$ to compute $\sigma_{T_{y+1}}(v_1)$.  Now, $\sigma_{T_{y+1}}(v_1)$ and (PC3)--(PC4) contains $\tau_{T_{y+1}}(v_1)$ and (PC2)--(PC4) contains $\tau_{T_{y+1}}(v_2)$.  We use these to test if $v_1=v_2$ or $v_1v_2\in E(H)$.  If not, then $z_1z_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.

  If $v_1=v_2$ or $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{T_{y+1}}(v_1)$ and $\tau_{T_{y+1}}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=-1$:  This case is symmetric to the preceding case, with the roles of $z_1$ and $z_2$ reversed.
\end{enumerate}

This completes the proof of our main result (note that in the previous section we assumed without loss of generality that $h\le n$ and $m\le n$, but here we can only assume that $h\le n$ and $m\le tn$, using the fact that every $n$-vertex graph of treewidth at most $t$ is a subgraph of a $t$-tree on at most $tn$ vertices).

\begin{thm}\thmlabel{main-product}
  For every fixed $t\in\N$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some $t$-tree $H$ and some path $P$ has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

\thmref{main} and \thmref{main-all} are immediate consequences of \thmref{main-product}, \thmref{product-structure}, and \thmref{product-structure-all}.



%======================
% original Section 5
%======================
\begin{comment}
\section{Subgraphs of $H\boxtimes P$}
\seclabel{hxp}

In this section we describe adjacency labelling schemes for graphs $G$ that are subgraphs of $H\boxtimes P$ where $H$ is a graph of treewidth $t$ and $P=1,2,\ldots,h$ is a path.
Note that every graph of treewidth $t$ is a subgraph of a $t$-tree (see below for the definition). For this reason, we may restrict ourselves to the case where $H$ is a $t$-tree, which we do.

\subsection{A Labelling Scheme for $t$-Trees}

We begin by describing a labelling scheme for $t$-trees that, like our labelling scheme for paths, is based on a binary search tree.  The ideas behind this scheme are not new; this is essentially the labelling scheme for $t$-trees described by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  However, we present these ideas in a manner that makes it natural to generalize the results of \secref{pxp}.

\subsubsection{$t$-Trees}

A graph $H$ is a \emph{$t$-tree} if $H$ is a clique on $t+1$ vertices or if $H$ contains a vertex $v$ of degree $t$ whose neighbours form a clique and $H-v$ is a $t$-tree.

Note that the recursive definition of $t$-trees implies that there is a vertex ordering $v_1,\ldots,v_{m}$ of $V(H)$ such that $v_1,\ldots,v_{t+1}$ form a clique and, for each $i\in\{t+2,\ldots,m\}$, $C_H(v_i):=N_H[v_i]\cap \{v_1,\ldots,v_{i}\}$ is a clique of size $t+1$.  We call $C_H(v_i)$ the \emph{family clique} of $v_i$ and $C_H(v_i)\setminus\{v_i\}$ the \emph{parent clique} of $v_i$. For each $i\in\{1,\ldots,t+1\}$, the family clique $C_H(v_i)$ of $v_i$ is defined simply as the initial clique $\{v_1,\ldots,v_{t+1}\}$, and $C_H(v_i)\setminus\{v_i\}$ is the parent clique of $v_i$. The order $v_1,\ldots,v_m$ is called a \emph{construction order} for $H$.

The order $v_1,\ldots,v_m$ (in particular, the fact that each $v_i$ has at most $t$ neighbours among $v_1,\ldots,v_{i-1}$) implies that $V(H)$ has a proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$.  When such a colouring of $H$ is given then, for each $i\in\{1,\ldots,m\}$ and each $j\in\{1,\ldots,t+1\}$ the \emph{$j$-parent} $p_j(v_i)$ of $v_i$ is the unique element $p\in C_H(v_i)$ with $\varphi(p)=j$.  Note that $v_i$ is the $j$-parent of itself for exactly one $j\in\{1,\ldots,t+1\}$.

\subsubsection{Interval Graphs}

For real numbers $a\le b$, let $[a,b]:=\{ x\in\R: a\le x\le b\}$, and let
$\mathbb{I}:=\{[a,b]: a,b\in\R,\, a\le b\}$ denote the set of closed real intervals.  For a finite set $S\subset\mathbb{I}$ of intervals, the \emph{interval intersection graph} $G_S$ is the graph with vertex set $V(G_S):=S$ and in which there is an edge between two distinct intervals $v, w\in S$ if and only if $v\cap w\neq \emptyset$.  The \emph{thickness} $\omega(G_S)$ of $S$ is the size of its largest clique, which (by Helly's Theorem) is equal to $\max_{x\in\R}|\{v\in V(G_S):x\in v\}|$.

% By Dilworth's Theorem (applied to the poset $(V(I),\prec)$ where $[a,b]\prec [c,d]$ iff $b<c$), the chromatic number $\chi(I)$ of $I$ is equal to its thickness, i.e., $\chi(I)=\omega(I)$.

The following well-known result states that every $m$-vertex $t$-tree is the subgraph of an interval graph with thickness $\Oh(t\log m)$:\footnote{The specific value $\log_3 (2m+1)$ in \lemref{interval-representation} is obtained by applying a result of Scheffler \cite{scheffler:optimal} on the tree underlying the width-$t$ tree decomposition of $H$.}

\begin{lem}\lemlabel{interval-representation}
  For every $m$-vertex $t$-tree $H$, there exists a mapping $f:V(H)\to\mathbb{I}$, such that the interval intersection graph $G_S$ with $S:=\{f(v):v\in V(H)\}$ has thickness at most $(t+1)\log_3(2m+1)$ and
  $vw\in E(G_S)$ for each $vw\in E(H)$. %$f(v)\cap f(w)\neq\emptyset$.

  Furthermore, for every proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$ of $H$, there exists a proper colouring $\varphi':V(G_S)\to\{1,\ldots,\lfloor\log_3(2m+1)\rfloor\}\times\{1,\ldots,t+1\}$ of $G_S$ where, for each $v\in V(H)$, $\varphi'(f(v))=(j,\varphi(v))$ for some $j\in\{1,\ldots,\lfloor\log_3(2m+1)\rfloor\}$.
\end{lem}

In light of \lemref{interval-representation} we will not distinguish between a vertex $v\in V(H)$ and the interval $f(v)$.  That is, we will treat the nodes of $H$ as intervals that satisfy the conditions of \lemref{interval-representation}.

A point $x\in\R$ \emph{stabs} an interval $[a,b]$ if $\{x\}\cap [a,b]=\{x\}$. A finite set $X\subset\R^2$ of points \emph{stabs} a set $S\subset\mathbb{I}$ of intervals if $X\cap [a,b]\neq\emptyset$ for every $[a,b]\in S$. For any $v=[a_v,b_v]\in\mathbb{I}$ and any binary search tree $T$ such that $V(T)$ stabs $v$, we let $x_T(v)$ denote the lowest common $T$-ancestor of $V(T)\cap v$ (see \figref{x}).

\begin{lem}\lemlabel{common-ancestor}
If $T$ is a binary search tree such that $V(T)$ stabs $v=[a_v,b_v]$, then  $x_T(v)\in [a_v,b_v]$.
\end{lem}

\begin{proof}
  Since $x:=x_T(v)$ is the lowest common $T$-ancestor of $V(T)\cap[a_v,b_v]$, either $x\in V(T)\cap[a_v,b_v]$, in which case there is nothing to prove, or there is some pair $x_1,x_2\in V(T)\cap[a_v,b_v]$ such that $x_1$ is in the subtree of $T$ rooted at the left child of $x$ and $x_2$ is in the subtree of $T$ rooted at the right child of $x$.  By the binary search tree property, $x_1<x<x_2$. But $x_1,x_2 \in [a_v,b_v]$, so $a_v\le x_1<x<x_2\le b_v$, so $x\in [a_v,b_v]$.
\end{proof}


\begin{figure}
  \begin{center}
    \includegraphics{figs/x}
  \end{center}
  \caption{The definition of $x_T(v)$.}
  \figlabel{x}
\end{figure}


\subsubsection{The Labelling Scheme}
\seclabel{$t$-tree-labelling}

We can use \lemref{common-ancestor} to create a labelling scheme for (an induced subgraph of) a $t$-tree based on any binary search tree containing an appropriate stabbing set.  Let $H$ be a $t$-tree whose vertex set $V(H):=S$ consists of the intervals described by \lemref{interval-representation}, let $v_1,\ldots,v_m$ be a construction order for $H$, let $\varphi:V(H)\to\{1,\ldots,t+1\}$ be a proper colouring of $H$, and let $\varphi':V(H)\to\{1,\ldots,\lfloor\log_3 (2m+1)\rfloor\}\times\{1,\ldots,t+1\}$ be the extension of $\varphi$ to a proper colouring of $G_S$ described in \lemref{interval-representation}.

% Let $X\subset\R$ be any set of points that stab $S$, let $T$ be a binary search tree with $V(T):=X$.
% , and let $\varphi:V(H)\to\{1,2,\ldots,\lfloor t\log n\rfloor\}$ be a proper colouring of the interval graph with vertex set $S$.

We say that a binary search tree $T$ \emph{represents} some $v\in V(H)$ if $V(T)$ stabs the family clique, $C_H(v)$, of $v$.   For any subset $C\subseteq \mathbb{I}$, such that $V(T)$ stabs $C$, we define $x_T(C):=\{x_T(x):x\in C\}$.

\begin{lem}\lemlabel{one-path}
  Let $T$ be any binary search tree that represents some $v\in V(H)$.  Then the set of nodes $x_T(C_H(v))$ are all contained in a single root-to-leaf path in $T$.
\end{lem}

% \begin{lem}\lemlabel{one-path}
%   For any $v\in V(H)$ with family clique $C_H(v)$, the set of nodes $x_T(C_H(v))$ are all contained a single root-to-leaf path in $T$.
% \end{lem}

\begin{proof}
  Suppose for the sake of contradiction that this is not true, so there are $x_1,x_2\in x_T(C_H(v))$ neither of which is an ancestor of the other.  Then consider the lowest common $T$-ancestor $x$ of $x_1$ and $x_2$.  Assume without loss of generality that $x_1$ is in the subtree of $T$ rooted at $x$'s left child and $x_2$ is in the subtree of $T$ rooted at $x$'s right child, so $x_1<x<x_2$. Then $x_1=x_T(v_1)$ for some $v_1:=[a_1,b_1]\in C_H(v)$ and $x_2=x_T(v_2)$ for some $v_2:=[a_2,b_2]\in C_H(v)$.  Since $v_1$ and $v_2$ are both in the family clique $C_H(v)$, the vertices $v_1$ and $v_2$ are adjacent in $H$, and therefore $[a_1,b_1]\cap[a_2,b_2]\neq\emptyset$.  This implies that $x\in [a_i,b_i]$ for at least one $i\in\{1,2\}$.  But this is a contradiction since $x_T(v_i)$ is supposed to be the lowest common ancestor of $[a_i,b_i]\cap V(T)$.
\end{proof}

The following observation shows that a vertex $v$ of $H$ is uniquely identified by $x_T(v)$ and $\varphi'(v)$.

\begin{obs}\obslabel{unique-id}
    Let $T$ be a binary search tree that represents two distinct vertices $v,w\in V(H)$.  Then, $x_T(v)\neq x_T(w)$ or $\varphi'(v)\neq\varphi'(w)$.  Consequently, $\sigma_T(x_T(v))\neq \sigma_T(x_T(w))$ or $\varphi'(v)\neq\varphi'(w)$.
\end{obs}

\begin{proof}
  If $x_T(v)=x_T(w)=x$, the intervals $v=[a_v,b_v]$ and $w=[a_w,b_w]$ each contain $x$, so $vw\in E(G_S)$.  Therefore $\varphi'(v)\neq\varphi'(w)$ since $\varphi'$ is a proper colouring of $G_S$.  The second, equivalent, statement of the observation is immediate from the fact that $\sigma_T: V(T)\to\{0,1\}^*$ is injective, so $\sigma_T(x)$ uniquely identifies $x$.
\end{proof}

For any binary search tree that represents $v$, let $P_T(v)$ denote the path in $T$ that begins at the root of $T$ and ends at the node in $x_T(C_H(v))$ of maximum depth.  By \lemref{one-path}, $P_T(v)$ is well defined and contains every node in $x_T(C_H(v))$.  Let $\sigma_T(v):=\sigma_T(z)$ where $z$ is the node of maximum depth in $x_T(C_H(v))$.

For any $Q\subseteq V(H)$ we can obtain a labelling scheme for the subgraph $H[Q]$ induced by $Q$ by using any binary search tree $T$ that represents $v$ for each $v\in Q$.  The label for a vertex $v\in Q$ consists of the following (in addition to the integers $t$, $|\sigma_T(v)|$, and $\lfloor\log_3 (2m+1)\rfloor$, that can be encoded in a prefix-free manner using \lemref{elias} and contribute at most $\Oh(\log t + \log h(T) + \log\log m)$ to the length of each label):

\begin{enumerate}[label={(TC\arabic*)}, ref={TC\arabic*}, noitemsep]
  \item $\sigma_T(v)$;
  \item $d_T(x_T(p_j(v)))$ for each $j\in\{1,\ldots,t+1\}$;
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; and
  \item $\varphi'(v)$.
\end{enumerate}

Given the labels of two vertices $v,w\in Q$, we test if $v$ and $w$ are adjacent as follows:
\begin{enumerate}[label={(A\arabic*)}, ref={A\arabic*}, noitemsep]
  \item If the labels of $v$ and $w$ are identical then $v=w$, so return false.

  \item (uniquely identify $v$) From (TC4) extract $j:=\varphi(v)$ (which is contained in $\varphi'(v)$).  From (TC2) extract $d:=d_T(x_T(p_j(v)))=d_T(x_T(v))$. Take the length-$d$ prefix of $\sigma_T(v)$ to get $\sigma_T(x_T(v))$.

  \item (check if $v$ is the $j$-parent of $w$) From~(TC2), extract $d:=d_T(x_T(p_j(w)))$ and take the length-$d$ prefix of $\sigma_T(w)$ to get $\sigma_T(x_T(p_j(w)))$.  If $\sigma_T(x_T(v))=\sigma_T(x_T(p_j(w)))$ and $\varphi'(v)=\varphi'(p_j(w))$ then, by \obsref{unique-id}, $v$ is the $j$-parent of $w$ and $vw\in E(H)$, so return true.

  \item Repeat (A2) and (A3) with the roles of $v$ and $w$ reversed. %\snote{Piotrek: this ref was (A4,A5) ...} \note{Pat:removed the only reference to A5}

  \item Return false
\end{enumerate}

The correctness of this adjacency test can be seen as follows:
\begin{itemize}
  \item Given the labels of $v$ and $w$ we can recover $\sigma_T(x_T(v))$, $\varphi'(v)$, $\sigma_T(x_T(w))$, and $\varphi'(w)$ so, by \obsref{unique-id}, the label of $v$ and the label of $w$ are identical if and only if $v=w$, so the negative result in (A1) is never incorrect;
  \item from \obsref{unique-id}, positive results in (A3) and (A4) are never incorrect; and
  \item for every $vw\in E(H)$, there exists a $j\in\{1,\ldots,t+1\}$ such that $v$ is the $j$-parent of $w$ or $w$ is the $j$-parent of $v$, so the negative result in (A5) is never incorrect.
\end{itemize}
In fact, this labelling scheme proves the following slightly stronger result. 

\begin{lem}\lemlabel{t-tree-labelling}
  Let $H$, $\varphi$, $\varphi'$, $Q$, and $T$ be defined as above, and let $\tau_T:Q\to\{0,1\}^*$ be the prefix-free labelling of $H[Q]$ given by (TC1)--(TC4) above.  Then $|\tau_{T}(v)|=h(T) + \Oh(t(\log t + \log h(T))+\log\log m)$ for every $v\in Q$  and there exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that  for every $v,w\in Q$,
  \[
      \mathds{T}(\tau_{T}(v),\tau_{T}(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{lem}

\begin{proof}
  Most of the details of this labelling are described above, though we have thus far ignored the length of the labels, which we analyze now.

  Part (TC1) of each label has length $|\sigma_T(v)|\le h(T)$.  For each $x\in V(T)$, $d_T(x)\le h(T)$, so part~(TC2) of each label requires $\Oh(t\log h(T))$ bits.  Part~(TC3) of each label requires $\Oh(t\log t + t\log h(T))$ bits.  Part~(TC4) of each label requires $\Oh(\log t + \log h(T))$ bits.
  The unmentioned part of each label, which includes Elias encodings of the values $t$, $|\sigma_T(V)|$, and $\lfloor\log_3(2m+1)\rfloor$, requires $\Oh(\log t+\log h(T) + \log\log m)$ bits.
\end{proof}

% Taking $X$ to be a minimal set that stabs $S$ (so $|X|\le |S|=m$) and taking $T$ to be a perfectly balanced binary search tree (so $h(T)\le \log|X|\le\log m$) we obtain the following corollary.
%
% \begin{cor}\corlabel{t-tree-labelling}
%   There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that, for any $m$-vertex $t$-tree $H$ there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=\log m + \Oh(t(\log t + \log\log m))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$,
%   \[
%       \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
%       0 & \text{if $v=w$} \\
%       -j & \text{if $v$ is the $j$-parent of $w$} \\
%       j & \text{if $w$ is the $j$-parent of $v$} \\
%       \perp & \text{otherwise.}
%     \end{cases}
%   \]
% \end{cor}

\subsection{Interval Transition Labels}

% We point out again that the result in \corref{t-tree-labelling} is not new and the labelling scheme is just a reformulation of the one given by Gavoille and Labourel \cite{gavoille.labourel:shorter} that happens to be convenient for what we are going to do next. Most important for us is that the largest part of the codes come from paths in the binary search tree $T$ that contains the stabbing set $X$.

We now show that the solution presented in \secref{pxp} generalizes to the current setting of subgraphs of $H\boxtimes P$.  The only additional complication comes from the fact that each node $x$ in the binary search tree $T$ is equipped with a set $B_x:=\{v\in V(H):x_T(v)=x\}$ of intervals.  Any structural changes that we make to $T$ may result in changes to $B_x$, which result in changes to the labels of any vertex $v\in V(H)$ such that an element of $C_H(v)$ leaves or enters $B_x$.  We must show that these changes can be encoded using few bits.  We now proceed.

Let $G$ be an $n$-vertex subgraph of $H\boxtimes P$ where $H$ is an $m$-vertex $t$-tree and $P=1,\ldots,h$ is a path. Let $\varphi:V(H)\to\{1,\ldots,t+1\}$ be a proper colouring of $H$, and let $\varphi':V(H)\to\{1,\ldots,\lfloor\log_3 (2m+1)\rfloor\}\times\{1,\ldots,t+1\}$ be the extension of $\varphi$ described in \lemref{interval-representation}.

For each $y\in\{1,\ldots,h\}$, let $S_y:=\{v\in V(H): (v,y)\in V(G)\}$ and let $S^-_y:=\bigcup_{j=1}^{t+1}\{p_j(v):v\in S_y\}$.
Note that $|S^-_y|\le (t+1)|S_y|$.
Let $S^-_0:=\emptyset$.
For each $y\in\{1,\ldots,h\}$, let $X_y\subset\R$ be the set of all endpoints of intervals in $S^-_y\cup S^-_{y-1}$.  Observe that any binary search tree $T_y$ with $V(T_y)\supseteq X_y$ represents each $v\in S_y\cup S_{y-1}$.
Apply \lemref{fractional} to the sequence $X_1,\ldots,X_h$ to obtain a $3$-chunking sequence $V_1,\ldots,V_{h}$ such that $V_y\supseteq X_y$ for each $y\in\{1,\ldots,h\}$, and $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |X_y|$.
Let $T_1,\ldots,T_h$ be a $k$-bulk tree sequence based on $V_1,\ldots,V_{h}$ with $k:=\lceil \sqrt{\log n / \log \log n}\rceil$.
By construction, \lemref{bulk-tree-height}, and \lemref{node-transitions}, the following properties are satisfied.
\begin{compactenum}[(PR1)]  %[label={(PR1)}, noitemsep]
  \item $V(T_y)\supseteq X_y$ for each $y\in\{1,\ldots,h\}$;
  \item $h(T_y)= \log |T_y| + \Oh(k+k^{-1}\log |T_y|)= \log |T_y| + o(\log n)$ for each $y\in\{1,\ldots,h\}$;
  \item $W:=\sum_{y=1}^h |T_y|= \Oh(tn)$, and
  \item There is a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each $y\in\{1,\ldots,h-1\}$ and each $x\in V(T_y)\cap V(T_{y+1})$, there is a string $\nu_y(x)$ such that $B(\sigma_{T_y}(x),\nu_y(x))=\sigma_{T_{y+1}}(x)$ and $|\nu_y(x)|=\Oh(k\log\log n)=o(\log n)$.
\end{compactenum}

The following lemma, which is analogous to \lemref{node-transitions}, is the last piece of the puzzle needed for an adjacency labelling scheme for subgraphs of $H\boxtimes P$. Recall that the notation $\sigma_T(v)$ and $P_T(v)$, used below in the context of a vertex $v=[a_v,b_v]$ in a $t$-tree, has been introduced shortly after \obsref{unique-id}.

\begin{lem}\lemlabel{interval-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to \{0,1\}^*$ such that, for any
  $H$, $G$, $S_1,\ldots,S_h$, $X_1,\ldots,X_h$, $T_1,\ldots,T_h$ defined as above, for each $y\in\{1,\ldots,h-1\}$ and each $v\in S_y \cup S_{y+1}$, there exists $\mu_y(v)\in\{0,1\}^*$ with $|\mu_y(v)|= \Oh(k\log\log n)=o(\log n)$ such that $B(\sigma_{T_y}(v), \mu_y(v))=\sigma_{T_{y+1}}(v)$.
\end{lem}

\begin{proof}
  First we recall that, if $v\in S_y\cup S_{y+1}$, then $T_y$ and $T_{y+1}$ each represent $v$.  As in the proof of \lemref{node-transitions}, we must dig into the details of the three bulk tree operations that transform $T_y$ into $T_{y+1}$. These are rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion of $D_y$, which takes $T_y''$ onto $T_{y+1}$.

  The bulk insertion that converts $T_y'$ into $T_y''$ is the simplest to handle.  For any $v\in S_y$, $P_{T_y'}(v)$ is the path from the root of $T_y'$ to the deepest node in $x_{T_y'}(C_H(v))$.  Furthermore, for each $w=[a_w,b_w]\in C_H(v)$, $x_{T_y'}(w)$ is the element of $w\cap V(T_y')$ that is closest to the root of $T_y'$. Since $T_y''$ is a supergraph of $T_y'$ obtained by adding small subtrees at the external nodes of $T_y'$, $x_{T_y''}(w)=x_{T_y'}(w)$ for each $w\in C_H(v)$.  Therefore $P_{T_y''}(x_{T_y''}(w))=P_{T'}(x_{T_y'}(w))$ and $\sigma_{T_y''}(x_{T_y''}(w))=\sigma_{T'}(x_{T_y'}(w))$ for each $w\in C_H(v)$, so $\sigma_{T_y''}(v)=\sigma_{T_y'}(v)$ for each $v\in S_y$.

  Next we consider the bulk deletion that converts $T_y''$ into $T_{y+1}$.  A bulk deletion consists of a sequence of individual deletions. Consider one such deletion and let $T$ and $\tilde{T}$ denote the tree before and after the deletion, respectively.

  \begin{clm}\clmlabel{deletion-ancestor}
    For any $v=[a_v,b_v]\in S_y$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))$ is a prefix of $\sigma_T(x_T(v))$.
  \end{clm}

  \begin{proof}[Proof of \clmref{deletion-ancestor}]
    See \figref{deletion-t-tree}.  At a global level, the deletion of a value $x$ from $T$ involves finding a sequence of consecutive values $x_0<x_1<\cdots<x_r$ or $x_0>x_1>\cdots>x_r$ where $x=x_0$, $x_r$ is a leaf and $x_{i-1}$ is a $T$-ancestor of $x_{i}$ for each $i\in\{1,\ldots,r\}$.  The leaf containing $x_r$ is deleted and, for each $i\in\{0,\ldots,r-1\}$, the (value of) $x_i$ is replaced with (the value in) node $x_{i+1}$.

    \begin{figure}
      \begin{center}
        \includegraphics{figs/deletion-t-tree-1}\\[1ex]
        $\Downarrow$\\[1ex]
        \includegraphics{figs/deletion-t-tree-2}
      \end{center}
      \caption{The effect of a single deletion on $x_T(v)$.}
      \figlabel{deletion-t-tree}
    \end{figure}

    If $x_T(v)=x_0$ then recall that $v\in S_y\subseteq S^-_y$ and $X_{y+1}\subseteq V(T_{y+1})$ contains both endpoints of each interval in $S^-_{y+1}\cup S^-_y$.  Therefore $a_v,b_v\in V(T_{y+1})$.  Therefore $r\ge 1$ and $x_1\in [a_v,b_v]$ so $x_{\tilde{T}}(v)=x_1$ and $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_T(x_T(v))$.

    If $x_T(v)=x_i$ for some $i\in\{1,\ldots,r\}$, then $x_{\tilde{T}}(v)=x_i$ (see the interval $v_1$ in \figref{deletion-t-tree}) and $\sigma_{\tilde{T}}(x_i)=\sigma_{T}(x_{i-1})$.  Since $x_{i-1}$ is a $T$-ancestor of $x_i$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_{\tilde{T}}(x_i)$ is a prefix of $\sigma_{T}(x_{T}(v))$, as required.

    Finally, if $x_T(v)\neq x_i$ for any $i\in\{0,\ldots,r\}$ and $x_T(v)\neq x_{\tilde{T}}(v)$, then the only possibility is that $x_{\tilde{T}}(v)=x_i$ for some $x_i\in [a_v,b_v]$ (see the interval $v_2$ in \figref{deletion-t-tree}).  This can only happen if $x_i$ is not a $T$-ancestor of $x_T(v)$, but $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$.  By \lemref{common-ancestor}, $x_i$ is a $T$-descendant of $x_T(v)$.  Since $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$, $x_{i-1}$ is a $T$-ancestor of $x_T(v)$.  Therefore $\sigma_{\tilde{T}}(v)=\sigma_{\tilde{T}}(x_i)=\sigma_T(x_{i-1})$ is a prefix of $\sigma_T(x_T(v))$, as required.  This completes the proof of \clmref{deletion-ancestor}.
  \end{proof}

  For strings $a$ and $b$, let $a\preceq b$ denote that $a$ is a prefix of $b$.
  Since a bulk deletion is implemented as a sequence of individual deletions,
  \begin{align*}
    \sigma_{T_y''}(v)
      & = \sigma_{T_y''}(x_{T_y''}(w)) & \text{(for some $w\in C_H(v)$)} \\
      & \preceq \sigma_{T_y'}(x_{T_y'}(w)) & \text{(by \clmref{deletion-ancestor})} \\
      & \preceq \sigma_{T_y'}(v) \enspace . & \text{(by \lemref{one-path})}
  \end{align*}
  Therefore, by including $|\sigma_{T_y''}(v)|$ in $\mu_y(v)$ we can derive $\sigma_{T_y''}(v)$ from $\sigma_{T_y'}(v)$.  This requires only $\Oh(\log h({T_y'}))=\Oh(\log\log n)$ bits.

  Finally, we consider the rebalancing operation that takes $T_y$ onto $T_y'$ by calling \textsc{BulkBalance}$(\theta,k)$, which calls $\textsc{Balance}(x,k)$ on each depth-$\theta$ node $x$ of $T_y$ to restructure the subtree of $T_y$ rooted at $x$ (refer to \figref{rebalance-t-tree}). Therefore, for any $v\in S_y$, and any $\theta'\in\{0,\ldots,\theta\}$, the length-$\theta'$ prefix of $\sigma_{T_y}(v)$ and length-$\theta'$ prefix of $\sigma_{T_y'}(v)$ are the same.  By including the value of $\theta$ in $\mu_y(v)$, we then only need to consider the effect of the call to $\textsc{Balance}(x,k)$ where $x$ is the unique depth-$\theta$ node of $T_y$ contained in $P_{T_y}(v)$ (if any).

  \begin{figure}
    \begin{center}
      \includegraphics{figs/rebalance-t-tree}
    \end{center}
    \caption{Only the call to $\textsc{Balance}(x,k)$ on a node $x\in V(P_{T_2}(v))$ affects $\sigma_{T_2'}(v)$.}
    \figlabel{rebalance-t-tree}
  \end{figure}

  Let $T_*$ be the subtree of $T_y$ rooted at $x$ and let $T_*'$ be the new tree obtained after calling $\textsc{Balance}(x,k)$ on the root, $x$, of $T_*$. (So $T_*$ is a subtree of $T_y$ and $T_*'$ is a subtree of $T_y'$.)
  The transition code $\mu_y(v)$ will contain enough information to recover $\sigma_{T_y'}(v)$ from $\sigma_{T_y}(v)$.

  Now, $\textsc{Balance}(x,k)$ identifies two special node sets $Z$ and $X$ that it turns into a perfectly balanced binary search tree $\hat{T}_0$.  Eventually, $\hat{T}_0$ will become a subgraph of $T_*'$ that contains the root of $T_*'$.   In particular, every node in $V(T_*')$ has a $T_*'$-ancestor in $Z\cup X$.

  For any $v\in S_y$ such that $P_{T_y'}(v)$ ends at a vertex $z\in Z\cup X=V(\hat{T}_0)$, the problem is easy.  We include $\sigma_{\hat{T}_0}(z)$, which has length at most $h(\hat{T}_0)\le k$, in $\mu_y(v)$, and this (along with $\theta$) is sufficient to recover $\sigma_{T_y'}(v)$ from $\sigma_{T_y}(v)$.

  Thus, we only need to consider those $v\in S_v$ such that $P_{T_y'}(v)$ ends a vertex $z\not\in Z\cup X$ with $d_{T_y}(z)>\theta$.    By definition,  $z=x_{T_y'}(w)$ for some $w=[a_w,b_w]\in C_H(v)$.  By \lemref{common-ancestor}, $z$ is the unique node of $P_{T_y'}(z)$ contained in $[a_w,b_w]$.  Therefore
  \begin{equation}
    [a_w,b_w]\cap (Z\cup X)=\emptyset \enspace . \eqlabel{empty}
  \end{equation}

  For each such node $v$, $P_{T_y}(v)$ has vertices (including $z$) in common with exactly one tree $T_{i}$ in the forest $T_*-Z$.  Then $\textsc{Balance}(x,k)$ calls $\textsc{MultiSplit}(x_{i,1},\ldots,x_{i,c_i})$ on the subtree $T_{i}$.  This, in turn results in zero or more calls to $\textsc{Split}(x)$ for nodes $x\in V(T_{i})$. The following claim explains the effect of one individual call to $\textsc{Split}(x)$:

  \begin{clm}\clmlabel{x-switch}
    Let $S$ by a set of intervals, let $T$ be a binary search tree where $V(T)$ stabs $S$, and let $T_{<x}$ and $T_{>x}$ be the two trees resulting from calling $\textsc{Split}(x)$ on $T$ for some $x\in V(T)$.  Then, for each $w=[a_w,b_w]\in S$ exactly one of the following is true:
    \begin{compactenum}
      \item $a_w\le x\le b_w$;
      \item $x< a_w$, in which case $x_{T_{>x}}(w)=x_T(w)$; or
      \item $b_w < x$, in which case $x_{T_{<x}}(w)=x_T(w)$.
    \end{compactenum}
  \end{clm}

  \begin{proof}
    That exactly one of the three cases applies is obvious.  Case~(1) has no specific requirements and Cases~(2) and (3) are symmetric, so we focus on Case~(2), so $x < a_w\le b_w$.

    By \lemref{common-ancestor}, $z=x_T(v)$ is the unique node $z\in V(T)$ such that $P_T(z)$ has exactly one node $z\in [a_w,b_w]$.  Now $P_{T_{>x}}(z)$ is obtained from $P_T(z)$ by deleting all values less than or equal to $x$. Therefore $P_{T_{>x}}(z)$ has exactly one node in $[a_w,b_w]$, namely $z$, so $z=x_{T_{>x}}(w)$.  This completes the proof of \clmref{x-switch}.
  \end{proof}

  From \clmref{x-switch}, we can conclude that $P_{T_y'}(v)=P_{T_y'}(x_{T_y}(w))$ for some $w\in C_H(v)$.  Indeed, for the $w\in C_H(v)$ that determines $P_{T_y'}(v)=P_{T'}(x_{T_y'}(w))$ we have $x_{T_y'}(w)\not\in Z\cup X$ by \eqref{empty}. By \clmref{x-switch}, either $x_{T_y'}(w)=x_{T_y}(w)$ or at some point $\textsc{Split}(x)$ was called on some node $x\in[a_w,b_w]$.  But $\textsc{Split}(x)$ is only called on nodes $x\in X$ so, by \eqref{empty}, $x_{T_y'}(w)=x_{T_y}(w)$.

  Thus, for each $v\in S_y$ such that $x(v)\not\in Z\cup X$, there exists some $w\in C_H(v)$ with $x_{T_y'}(w)=x_{T_y}(w)$ such that $P_{T_y'}(v)=P_{T_y'}(x_{T_y}(w))$, so $\sigma_{T_y'}(v)=\sigma_{T_y'}(x_{T_y}(w))$.  By \lemref{one-path}, $\sigma_{T_y}(x_{T_y}(w))$ is a prefix of $\sigma_{T_y}(v)$ and the length of this prefix can be included in $\mu_y(v)$, which makes it possible to recover $\sigma_{T_y}(x_{T_y}(w))$ from $\sigma_{T_y}(v)$ .  By \lemref{node-transitions}, there exists a function $B$ and a string $\nu_y(x_{T_y}(w))$ of length $\Oh(k\log\log n)$ such that $B(\sigma_{T_y}(x_{T_y}(w)), \nu_y(x_{T_y}(w))) = \sigma_{T_y'}(x_{T_y}(w)) = \sigma_{T_y'}(v)$.

  Therefore, for any $v\in S_y$ there is a string $\mu_y(v)$ of length $\Oh(k\log\log n)$ that satisfies the conditions of the lemma.
\end{proof}

\subsection{The Labels}

Summarizing, for any $n$-vertex subgraph $G$ of $H\boxtimes P$, each vertex $z=(v,y)\in V(G)$ has a label that contains the following information:

\begin{compactenum}[(PC1)]
  \item $\alpha(y)$ (given by \lemref{row-code});% of length $\log n-\log|T_y| + \Oh(\log\log n)$;
  \item $\sigma_{T_y}(v)$; % of length $\log|T_y| + \Oh(k+k^{-1}\log n)$;
  \item $d_{T_{y+b}}(x_{T_{y+b}}(p_j(v)))$ for each $j\in\{1,\ldots,t+1\}$ and $b\in\{0,1\}$;
    
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$;
  %\snote{L. I assume these $\varphi'$ should be replaced by $\tau$ of \lemref{t-tree-labelling}?}
  %\snote{Pat: No, just the colouring. $\tau_H(v)$ is the whole label.}
  \item $\varphi'(v)$;
  \item $\mu_y(v)$; and
  \item $a(z)$ (defined next).
  \end{compactenum}
  The only one of these quantities not yet defined is $a(z)$, which is a sequence of $3(t+1)$ bits that indicate which of the potential edges joining $z$ to elements of $\{(p_j(v),y+b): j\in\{1,\ldots,t+1\},\, b\in\{-1,0,1\}\}$ are actually present in $G$.

\subsection{Adjacency Testing}

Given the labels of $z_1:=(v_1,y_1)$ and $z_2:=(v_2,y_2)$ we test if $z_1z_2\in E(G)$ by first using $\alpha(y_1)$ and $\alpha(y_2)$ to determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case $y_1\neq y_2$ and $y_1y_2\not\in P$, so $z_1z_2\not\in E(H\boxtimes P)$, so $z_1z_2\not\in E(G)$.

  \item $y_1=y_2$.  Let $y=y_1=y_2$.  In this case (PC2)--(PC5) contains $\tau_{T_y}(v_1)$ and $\tau_{T_y}(v_2)$ (defined in \lemref{t-tree-labelling} using (TC1)--(TC4)) and we use this to test if $v_1v_2\in E(H)$.  If not, then $z_1z_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.

  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{T_y}(v_1)$ and $\tau_{T_y}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$ in $H$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=1$: Let $y=y_1$ (so that $y_2=y+1$).  We use $\mu_y(v_1)$ and $\sigma_{T_y}(v_1)$ to compute $\sigma_{T_{y+1}}(v_1)$.  Now, $\sigma_{T_{y+1}}(v_1)$ and (PC3)--(PC4) contains $\tau_{T_{y+1}}(v_1)$ and (PC2)--(PC4) contains $\tau_{T_{y+1}}(v_2)$.  We use these to test if $v_1=v_2$ or $v_1v_2\in E(H)$.  If not, then $z_1z_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.

  If $v_1=v_2$ or $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{T_{y+1}}(v_1)$ and $\tau_{T_{y+1}}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=-1$:  This case is symmetric to the preceding case, with the roles of $z_1$ and $z_2$ reversed.
\end{enumerate}

This completes the proof of our main result (note that in the previous section we assumed without loss of generality that $h\le n$ and $m\le n$, but here we can only assume that $h\le n$ and $m\le tn$, using the fact that every $n$-vertex graph of treewidth at most $t$ is a subgraph of a $t$-tree on at most $tn$ vertices).

\begin{thm}\thmlabel{main-product}
  For every fixed $t\in\N$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some $t$-tree $H$ and some path $P$ has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}

\thmref{main} and \thmref{main-all} are immediate consequences of \thmref{main-product}, \thmref{product-structure}, and \thmref{product-structure-all}.
\end{comment}
\section{Conclusion}
\seclabel{conclusion}

We conclude with a few remarks on the computational complexity of our labelling scheme.  Given an $n$-vertex planar graph $G$, finding an 8-tree $H$ (with mappings $f$, $\phi$ and $\phi'$ as in \lemref{interval-representation}), a path $P$, and a mapping of $G$ into a subgraph of $H\boxtimes P$ can be done in $\Oh(n\log n)$ time \cite{morin:fast}.  The process of computing the labels of $V(G)$ as described in \secref{pxp} and \secref{hxp} has a straightforward $\Oh(n\log n)$ time implementation.  Thus, the adjacency labels described in \thmref{main} are computable in $\Oh(n\log n)$ time for $n$-vertex planar graphs.

The adjacency testing function is quite simple. Even without using word parallelism, this function is straightforward to implement in $\Oh(tk\log n)$ time.  Note that this already allows a tradeoff between the (lower order term in the) code length and the complexity of adjacency testing.
In the case of planar graphs $t=8$ and, if we use the shortest possible code length, $k=\Oh(\sqrt{\log n / \log\log n})$, the adjacency testing procedure can be implemented in $\Oh(\log^{3/2} n\sqrt{\log\log n})$ time.

In a realistic $\log n$-bit word RAM model of computation with bitwise logical operations, bitwise shift operations, and a most-significant-bit\footnote{The only purpose of the most-significant-bit operation is allow decoding of the Elias $\gamma$ code in constant time.} operation the adjacency test, as described, can be implemented in $\Oh(k)$ time.  The bottleneck in such an implementation is the need to evaluate the function $B$ described in \lemref{interval-transitions} and the bottleneck there is the need to evaluate the function $B$ described in \lemref{node-transitions}.  The bottleneck in evaluating this latter function $B$ is the fact that, up to $k+1$ times, this replaces a prefix of $\sigma_T(x)$ with a string in $\Pi$.  The end result of all of these replacements is that a prefix of $\sigma_T(x)$ is replaced with a bitstring of length $\Oh(\log n)$ that has a run-length encoding of size $\Oh(k\log\log n)$.  This is, of course, easily implemented in $\Oh(k)$ time, but perhaps a faster implementation is possible.

% \snote{If we want to bother, we could probably do this in $\Oh(\log n)$ time.}
The current result leaves two obvious directions for future work:
\begin{enumerate}
  \item The precise length of the labels in \thmref{main} is $\log n + \Oh(\sqrt{\log n\log\log n})$.  The only known lower bound is $\log n + \Omega(1)$.  Closing the gap in the lower-order term remains an open problem.

  \item \thmref{main-product} implies a $(1+o(1))\log n$-bit labelling schemes for any family of graphs that excludes an apex graph as a minor.  Can this be extended to any $K_t$-minor free family of graphs?
\end{enumerate}

\section*{Acknowledgement}

Part of this research was conducted during the Eighth Workshop on Geometry and Graphs, held at the Bellairs Research Institute, January~31--February~7, 2020.  We are grateful to the organizers and participants for providing a stimulating research environment.  The authors are particularly grateful to Tamara~Mchedlidze and David~Wood for helpful discussions.


\bibliographystyle{plainurl}
\bibliography{labelling}

\newpage
\appendix

\section{Proof of \lemref{fractional}}
\applabel{fractional-proof}


\begin{proof}[Proof of \lemref{fractional}]
  $V_1,\ldots,V_{h}$ are constructed incrementally by a procedure $\textsc{BuildV}(S_1,\ldots,S_h)$ that makes use of a recursive subroutine $\textsc{Add}(x, y)$.  In the following code, $V_0$ and $V_{h+1}$ act as sentinels whose only purpose to eliminate distracting boundary cases.

  \noindent$\textsc{BuildV}(S_1,\ldots,S_h)$:
  \begin{algorithmic}[1]
    \STATE{$V_0\gets V_{h+1}\gets\Z$}
    \STATE{$V_y\gets\emptyset$ for each $y\in\{1,\ldots,h\}$}
    \FOR{$x= 1,\ldots,m$}
      \FOR{$y = 1,\ldots,h$}
        \IF{$x\in S_y\setminus V_y$}
          \STATE{$\textsc{Add}(x, y)$}
        \ENDIF
      \ENDFOR
    \ENDFOR
 % (L. to be removed)   \STATE{$V_y\gets V_y\setminus \{0\}$ for each $y\in\{1,\ldots,h\}$}
  \end{algorithmic}

  \noindent$\textsc{Add}(x, y)$:
  \begin{algorithmic}[1]
    \IF{$y\in\{1,\ldots,h\}$}
      \STATE{$V_y\gets V_y\cup\{x\}$}
      \IF{$|V_y|\ge 4$}
        \STATE{let $x_{-1}>x_{-2}>\cdots>x_{-4}$ be the 4 largest elements in $V_y$ (so $x_{-1}=x$)}
        \IF{$\{x_{-1},\ldots,x_{-4}\}\cap V_{y-1}=\emptyset$ or
            $\{x_{-1},\ldots,x_{-4}\}\cap V_{y+1}=\emptyset$}
            \STATE{$\textsc{Add}(x,y-1)$}
            \STATE{$\textsc{Add}(x,y+1)$}
        \ENDIF
      \ENDIF
    \ENDIF
  \end{algorithmic}

  % % \snote{L. Is $x_{-5}$ really necessary here?}
  % % \pnote{Pat: I suppose not.  I was worried about a boundary condition.  Let's see:  $V_1=\{0\}$, $V_2=\{0,1,2,3,4\}$ seems not need $y_{-5}$.  In fact, maybe we don't need to include $0$ either.  It should be enough to require $|V_y|\ge 4$ in Line~3 and then work only with $y_{-1},\ldots,y_{-4}$.
  %
  % Summary:
  % \begin{compactenum}
  %   \item The text about including 0 should be removed.
  %   \item Line~2 of BuildV should be deleted.
  %   \item References to Line~6 should be changed to Line~5.
  %   \item Line~3 of Add should be: {$|V_y|\ge 4$}
  %   \item Line~4 of Add should be: {let $x_{-1}>x_{-2}>x_{-3}>x_{-4}$ be the 4 largest elements in $V_y$ (so $x_{-1}=x$)}
  % \end{compactenum}
  % That's everything, right?
  % }
  It is easiest to think of the sets $V_y$ as sequences, sorted in increasing order, so that Line~2 in $\textsc{Add}(x,y)$ appends $x$ to $V_y$.

  That the procedure produces sets $V_1,\ldots,V_h$ such that $V_y\supseteq S_y$ for each $y\in\{1,\ldots,h\}$ is obvious.  So the resulting sets $V_1,\ldots,V_h$ satisfy the first condition of the lemma.

  To prove that $V_1,\ldots,V_h$ satisfy the second condition, we establish the loop invariant that, outside of $\textsc{Add}(x,y)$, $V_{y-1}$ and $V_{y+1}$ each 3-chunk  $V_y$ for each $y\in\{1,\ldots,h\}$.  Indeed, the only instant at which $V_{y-1}$ fails to 3-chunk $V_y$ is immediately after appending some value $x$ to $V_y$ in Line~2 of $\textsc{Add}(x,y)$.  If this occurs, it is immediately detected in Lines~3--5 and corrected in Line~6.  Similarly, if $V_{y+1}$ fails to $3$-chunk $V_y$ then this is immediately detected and corrected in Line~7.

  Finally, we need to argue that $V_1,\ldots,V_h$ satisfy the third condition.
  For convenience, define $n:=\sum_{y=1}^h |S_y|$ so that our task is to show that $\sum_{y=1}^h |V_y|\le 2n$.

  We do this with a \emph{credit scheme} that maintains the following invariant  during the execution of the algorithm:  For each $V_y$, let $c_y$ be the length the longest suffix $x_{-k},\ldots,x_{-1}$ of $V_y$ that does not intersect $V_{y-1}$ or does not intersect $V_{y+1}$.  Except during the execution of $\textsc{Add}(x,y)$, $c_y\le 3$, since $V_{y-1}$ and $V_{y+1}$ each 3-chunk $V_y$.  We maintain the invariant that $V_{y}$ stores $c_y$ credits at all times.  When we append to the list $V_y$ in Line~2 of $\textsc{Add}(x,y)$ we will pay with one credit that is spent and can never be used again.

  To maintain our credit invariant, we will create 2 credits each time $\textsc{BuildV}$ calls $\textsc{Add}(x,y)$ in Line~6.  Line~6 executes at most once for each of the $n$ values in $S_1,\ldots,S_h$.  Therefore Line~6 executes at most $n$ times and at most $2n$ credits are created.  Since each execution of Line~2 in $\textsc{Add}(x,y)$ takes away one credit, this means that the total number of times we append to lists in $V_1,\ldots,V_h$ is at most $2n$. Therefore, $\sum_{y=1}^h |V_y|\le 2n$.

  To manage these credits, we will pass two credits into each invocation of $\textsc{Add}(x,y)$, including the recursive invocations.  For the invocations of $\textsc{Add}(x,y)$ in Line~6 of \textsc{BuildV}, the two credits passed in are the two newly-created credits.

  When $\textsc{Add}(x,y)$ executes, one of the two credits passed to it is used to pay for the execution of Line~2, and this credit disappears forever, leaving one extra credit that we add to $V_y$ since the newly-added value $x\in V_y$ may have increased $c_y$ by 1. Thus far the credit invariant is maintained.

  If no further recursive invocations of $\textsc{Add}(x,y)$ are made, then there is nothing further to do, so we consider the case where the two recursive invocations in Lines~6 and 7 are made.  In this case, $c_y=4$ before these recursive invocations are made.  Afterwards, $c_y=0$ since these invocations add $x$ to $V_{y-1}$ and $V_{y+1}$.  This frees 4 credits.  We pass 2 of these free credits into the recursive invocation of $\textsc{Add}(x,y-1)$ and the other 2 free credits into the recursive invocation of $\textsc{Add}(x,y+1)$.
\end{proof}

\end{document}
