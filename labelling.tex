\documentclass[kpfonts]{patmorin}
\usepackage{pat}
\usepackage{paralist}
\usepackage{dsfont}  % for \mathds{A}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}
\usepackage[noend]{algorithmic}

\newcommand{\snote}[1]{\fcolorbox{red}{yellow}{#1}}
\newcommand{\pnote}[1]{\ \newline\noindent\fcolorbox{red}{yellow}{\begin{minipage}{\textwidth}#1\end{minipage}}}
\setlength{\parskip}{1ex}

\DeclareMathOperator{\A}{\mathds{A}}
\DeclareMathOperator{\sn}{sn}
\DeclareMathOperator{\qn}{qn}

\renewcommand{\SS}{\mathcal{S}}


\newcommand{\aref}[1]{(X\ref{a:#1})}
\newcommand{\alabel}[1]{\label{a:#1}}

\title{\MakeUppercase{Refactoring: Optimal Adjacency-Labelling Schemes for Planar Graphs}}
\author{Barbados Folks}

\begin{document}
\begin{titlepage}
\maketitle

\begin{abstract}
  We show that there exists an \emph{adjacency labelling scheme} for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(n))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  This is optimal up to the lower order term and is the first such optimal result.  An alternative, but equivalent, interpretation of this result is that, for every $n$, there exists a graph $U_n$ with $n^{1+o(1)}$ vertices such that every $n$-vertex planar graph is an induced subgraph of $U$.  This is the first near-linear upper bound on the size of $U_n$.
  
  This result is a consequence of a more general result on graphs with a certain product structure (Dujmović \etal FOCS~2019) that is exhibited by planar graphs, bounded genus graphs, apex-minor free graphs, and related graphs obtained by so-called shortcut systems (Dujmović, Morin, and Wood arXiv:1907.05168).
\end{abstract}
\end{titlepage}
\pagenumbering{roman}
\tableofcontents

\newpage

\setcounter{page}{0}
\pagenumbering{arabic}
\section{Introduction}

In this paper, which is concerned with binary encodings, $\log x:=\log_2 x$ denotes the binary logarithm of $x$ and, for convenience, $\lg x := \log\max\{1,x\}$.  All graphs we consider are finite and simple.  The vertex and edge sets of a graph $G$ are denoted by $V(G)$ and $E(G)$, respectively.  The size of a graph $G$ is denoted by $|G|:=|V(G)|$.

A family $\mathcal{G}$ of graphs has an \emph{$f(n)$-bit adjacency-labelling scheme} if there exists a function $A:(\{0,1\}^*)^2\to \{0,1\}$ such that for every $n$-vertex graph $G\in \mathcal{G}$ there exists $\ell:V(G)\to\{0,1\}^*$ such that $\ell(v)\le f(n)$ for each $v\in V(G)$ and such that, for any two vertices $v,w\in V(G)$,
\[  A(\ell(v),\ell(w)) = 
      \begin{cases} 
        0 & \text{if $vw\not\in E(G)$} \\
        1 & \text{if $vw\in E(G)$}
      \end{cases}
\]

We prove the following:
\begin{thm}\thmlabel{main}
  The family of planar graphs has a $(1+o(1))\log n$-bit labelling scheme.
\end{thm}

% We show that there exists an \emph{adjacency labelling scheme} for planar graphs where each vertex of an $n$-vertex planar graph $G$ is assigned a $(1+o(1))\log n$-bit label and the labels of two vertices $u$ and $v$ are sufficient to determine if $uv$ is an edge of $G$.  

\thmref{main} is optimal up to the lower order term.  An alternative, but equivalent, interpretation of \thmref{main} is that, for every integer $n\ge 1$, there exists a graph $U_n$ with $n^{1+o(1)}$  vertices such that every $n$-vertex planar graph is isomorphic to some vertex-induced subgraph of $U_n$.\footnote{There is a small technicality that the equivalence between adjacency-labelling schemes and universal graphs requires that $\ell:V(G)\to\{0,1\}^*$ be injective.  The labelling schemes we discuss satisfy this requirement.  For more details about the connection between labelling schemes and universal graphs, the reader is directed to Spinrad's monograph \cite[Section~2.1]{spinrad:efficient}.} 

\subsection{Previous Work}

The current paper is the latest in a series of results dating back to Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit0,kannan.naor.ea:implicit} and Muller \cite{muller:local} who defined adjacency-labelling schemes\footnote{There are some small technical differences between the two definitions that have to do with the computability of $\ell:=\ell(G)$ of $A(\cdot,\cdot)$.} and described $O(\log n)$-bit adjacency labelling schemes for several classes of graphs, including planar graphs.  Since this initial work, adjacency labelling schemes and, more generally, informative labelling schemes have remained a very active area of research \cite{alstrup.kaplan.ea:adjacency,abrahamsen.alstrup.ea:near-optimal,alstrup.dahlgaard.ea:sublinear,alstrup.gortz.ea:distance,alstrup.gavoille.ea:simpler,alstrup.rauhe:improved,X,X,X,X,X}. Here we review results most relevant to the current work, namely results on planar graphs and their supporting results on trees and bounded-treewidth graphs.

Muller's scheme for planar graphs \cite{muller:local} is based on the fact that planar graphs are 5-degenerate and uses labels of length $6\lceil\log n\rceil$.  Kannan, Naor, and Rudich \cite{kannan.naor.ea:implicit} use the fact that planar graphs have arboricity 3 (so their edges can be partitioned into three forests \cite{nash-williams:edge-disjoint}) to devise an adjacency labelling scheme for planar graphs whose labels have length at most $4\lceil\log n\rceil$.  

A number of $(1+o(1))$-bit adjacency-labelling schemes for forests have been devised \cite{chung:universal, alstrup.rauhe:improved,alstrup.dahlgaard.ea:optimal}, culminating with a recent $(\log n + O(1))$-bit adjacency labelling scheme \cite{alstrup.dahlgaard.ea:optimal} for forests.  Combined with the fact that planar graphs have arboricity 3, these schemes imply $(3+o(1))$-bit adjacency labelling schemes for planar graphs.  Schnyder's representation of planar graphs in terms of dimension-3 posets \cite{schnyder:planar} also implies a $3\lceil\log n\rceil$-bit labelling scheme for planar graphs.

A further improvement, also based on the idea of partitioning the edges of a planar graph into simpler graphs was obtained by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  Generalizing the results for forests, they describe a $(1+o(1))$-bit adjacency labelling scheme for $n$-vertex graphs of bounded treewidth.  The edges of a planar graph can be partitioned into two sets, each of which induces a bounded treewidth graph.  This results in a $(2+o(1))\log n$-bit adjacency labelling scheme for planar graphs.

Very recently, Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter} described a $(4/3+o(1))\log n$-bit adjacency labelling scheme for planar graphs based on a recent \emph{graph product structure theorem} of Dujmović \etal\ \cite{dujmovic.joret.ea:planar}.  This product structure theorem states that any planar graph is a subgraph of a strong product $H\boxtimes P$ where $H$ is a bounded-treewidth graph and $P$ is a path. See \figref{product}. It is helpful to think of $H\boxtimes P$ as a graph whose vertices can be partitioned into $h:=|V(P)|$ \emph{rows} $H_1,\ldots,H_{h}$, each of which induces a copy of $H$ and with vertical and diagonal edges joining corresponding and adjacent vertices between consecutive rows.  
% We now quickly sketch the construction of Bonamy, Gavoille, and Pilipczuk \cite{bonamy.gavoille.ea:shorter}.

\begin{figure}[htbp]
  \begin{center}
    \includegraphics{figs/product}
  \end{center}
  \caption{The strong product $H\boxtimes P$ of a tree $H$ and a path $P$.}
  \figlabel{product}
\end{figure}  
% In the following two paragraphs we omit $o(\log n)$ terms.

The product structure theorem quickly leads to a $(1+o(1))\log(mh)$-bit labelling scheme where $m:=|V(H)|$ and $h:=|V(P)|$ by using a $(1+o(1))\log m$-bit labelling scheme for $H$ (a bounded treewidth graph) and a $(1+o(1))\log h$-labelling scheme for $P$ (a path).  However, in the worst case $m$ and $h$ are each $\Omega(n)$, so this offers no immediate improvement over the existing $(2+o(1))\log n$-bit scheme.

Bonamy, Gavoille, and Pilipczuk improve upon this by cutting $P$ (and hence $G$) into subpaths of length $n^{1/3}$ in such a way that this corresponds to removing $O(n^{2/3})$ vertices of $G$ that have a neighbourhood of size $O(n^{2/3})$. The resulting (cut) graph is a subgraph of $H'\boxtimes P'$ where $H'$ has bounded treewidth, $|H'|\in O(n)$, and $P'$ is a path of length $O(n^{1/3})$ so it has a labelling scheme in which each vertex has a label of length $(1+o(1))\log (|H'|\cdot|P'|) \le (4/3+o(1))\log n$.  A slight modification of this scheme allows for the $O(n^{2/3})$ \emph{boundary} vertices adjacent to the cuts to have shorter labels, of length only $(2/3+o(1))\log n$.  The cut vertices and the boundary vertices induce a bounded-treewidth graph of size $O(n^{2/3})$.  The vertices in this graph receive secondary labels of length $(2/3+o(1))\log n$.  In this way, every vertex receives a label of length at most $(4/3 + o(1))\log n$.

\subsection{The New Result}

The adjacency labelling scheme described in the current paper is also based on the product structure theorem for planar graphs, but it avoids cutting the path $P$, and thus avoids boundary vertices that take part in two different labelling schemes.  Instead, it uses a weighted labelling scheme on the rows of $H\boxtimes P$ in which vertices that belong to $H_i$ receive a label of length $(1+o(1))\log n-\log W_i$ where $W_i$ is related to the number of vertices of $G$ contained in $H_i$ and $H_{i-1}$.  The vertices of $G$ in row $i$ participate in a secondary labelling scheme for the subgraph of $G$ contained in $H_i$ and $H_{i-1}$ and the labels in this scheme have length $\log W_i + o(\log n)$. Thus every vertex receives two labels, one of length $(1+o(1))\log n-\log W_i$ and another of length $\log W_i + o(\log n)$ for a total label length of $(1+o(1))\log n$.  

The key new technique that allows all of this to work is that the labelling schemes of the rows are not independent.  All of these labelling schemes are based on a single balanced binary search tree $T$ that undergoes insertions and deletions resulting in a sequence of related binary search trees $T_1,\ldots,T_h$ where each $T_i$ contains all vertices of $G$ in $H_{i}$ and $H_{i-1}$ and the label assigned to a vertex of $H_i$ is (essentially) based on a path from the root of $T_i$ to some vertex of $T_i$.  By carefully designing these trees, the tree $T_{i-1}$ and $T_{i}$ can be similar enough so that the labels for $v$ in $H_i$ can be obtained, with $o(\log n)$ additional bits from the label for $v$ in $H_{i-1}$.

The product structure theorem has been generalized to a number of additional graph families including bounded-genus graphs, apex minor free graphs, $k$-planar graphs, powers of bounded-degree bounded genus graphs, and $k$-nearest neighbour graphs of points in $\R^2$. As a side-effect of designing a labelling scheme to work directly on subgraphs of a strong product, we obtain labelling schemes for all of these classes of graphs in which vertices in any $n$-vertex member of this graph are assigned labels of length $(1+o(1))\log n$.  All of these results are optimal up to the lower order term.

\subsection{Outline}

The remainder of the paper is organized as follows. \Secref{preliminaries} reviews some preliminary definitions and easy results.  \Secref{bulk-trees} describes a new type of balanced binary search tree that has the specific properties need for our application. \Secref{pxp} solves a special case, where $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1$ and $P_2$ are both paths.  \Secref{hxp} extends this solution to the case where $G$ is an $n$-vertex subgraph of $H\boxtimes P$.  \Secref{conclusion} summarizes and concludes with directions for future work.

% \subsection{Proof Overview}
% 
% Like Bonamy \etal\ \cite{bonamy.gavoille.ea:shorter}.  Our starting point is a recent result that characterizes planar graphs in terms of the strong product of two simpler graphs.  The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
% \begin{enumerate}
%   \item  $v_1\neq v_2$; and
%   \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
%   \item $y_1=y_2$ or $y_1y_2\in E(B)$.
% \end{enumerate}
% 
% \begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]
%   Every planar graph $G$ is the subgraph of a strong product $G^+:=H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
% \end{thm}
% 
% \ldots

% \snote{TODO: Gwen and Piotr's comments.}

% For graph products like $G^+$, there is a natural labelling scheme: Computer a labelling scheme $\alpha:V(H)\to\{0,1\}^*$ for $H$ and a labelling scheme $\beta:V(P)\to\{0,1\}^*$ for $P$ and assign each vertex $v:=(x,y)\in V(G^*)$ the label $\mu(v):=\alpha(x),\beta(y)$.  Given two labels $\ell_1=\alpha(x_1),\beta(y_1)$ and $\ell_2=\alpha(x_2),\beta(y_2)$ for vertices $v_1=(x_1,y_1)$ and $v_2=(x_2,y_2)$ adjacency testing is done using the following formula whose three clauses follow from definition of strong product:
% \[
%     L(\ell_1,\ell_2):= (\ell_1\neq \ell_2) \wedge \A(\alpha(x_1),\alpha(x_2)) \wedge \A(\beta(y_1),\beta(y_2)) \enspace .
% \]
% 
% \ldots



\section{Preliminaries}
\seclabel{preliminaries}

For any graph $G$ and any vertex $v\in V(G)$, let $N_G(v):=\{w\in V(G): vw\in E(G)\}$ and $B_G(v):=N_G(v)\cup\{v\}$ denote the open neighbourhood and closed neighbourhood of $v$ in $G$, respectively.

\subsection{Prefix-Free Codes}

For a string $s=s_1,\ldots,s_k$, we use $|s|:=k$ to denote the length of $s$. A string $s_1,\ldots,s_k$ is \emph{prefix} of a string $t_1,\ldots,t_\ell$ if $k\le \ell$ and $s_1,\ldots,s_k=t_1,\ldots,t_k$.  A \emph{prefix-free code} $c:X\to\{0,1\}^*$ is a one-to-one function in which $c(x)$ is not a prefix of $c(y)$ for any two distinct $x,y\in X$.  Let $\N$ denote the set of non-negative integers.  The following is an old result of Elias:

\begin{lem}[Elias \cite{elias:universal}]\lemlabel{elias}
    There exist a prefix-free code $\gamma:\N\to\{0,1\}^*$ such that, for each $i\in\N$, $|\gamma(i)|\le 2\lfloor\log(i+1)\rfloor + 1\in O(\lg i)$.
\end{lem}

\subsection{Labelling Schemes Based on Binary Trees}

A \emph{binary tree} $T$ is a rooted tree in which each node except the root is either the \emph{left} or \emph{right} child of its parent and each node has at most one left and at most one right child.  For any node $x$ in $T$, $P_T(x)$ denotes the path from the root of $T$ to $x$.  The \emph{length} of a path $P$ is the number of edges in $P$, i.e., $|P|-1$.  The \emph{depth}, $d_T(x)$ of $x$ is the length of $P_T(x)$.  The \emph{height} of $T$ is $h(T):=\max_{x\in V(T)} d_T(x)$.  A \emph{perfectly balanced} binary tree is any binary tree $T$ of height $h(T)=\lfloor\log|T|\rfloor$.

A binary tree is \emph{full} if each non-leaf node has exactly two children. For a binary tree $T$, we let $T^+$ denote the full binary tree obtained by attaching $2-c$ leaves to each node of $T$ with $c$ children.  We call the leaves in $V(T^+)\setminus V(T)$ the \emph{external nodes} of $T$.  (Note that the external nodes of $T$ are leaves of $T^+$ that are not actually in $T$.)

A node $a\in V(T)$ is a \emph{$T$-ancestor} of $x\in V(T)$ if $a\in V(P_T(x))$. If $a$ is a $T$-ancestor of $x$ then $x$ is a \emph{$T$-descendant} of $a$. (Note that $x$ is a $T$-ancestor and $T$-descendant of itself.)  For a node subset $X\subseteq V(T)$, the \emph{lowest common $T$-ancestor} of $X$ is the maximum-depth node $a\in V(T)$ such that $a$ is a $T$-ancestor of $x$ for each $x\in X$.  

Let $x_0,\ldots,x_{r}$ be a path from the root $x_0$ of $T$ to some node $x_r$ (possibly $r=0$).  Then the \emph{signature} of $x_r$ in $T$, denoted $\sigma_T(x_r)$ is a binary string $b_1,\ldots,b_r$ where $b_i=0$ if and only if $x_{i}$ is the left child of $x_{i-1}$.  (Note that the signature of the root $x_0$ of $T$ is the empty string,  $\sigma_T(x_0)=\varepsilon$.)

A \emph{binary search tree (BST)} $T$ is a binary tree  whose node set $V(T)\subset\R$ consists of real numbers and that has the \emph{BST property}:  For each node $x$, $z<x$ for each node $z$ in $x$'s left subtree and $z>x$ for each node $z$ in $x$'s right subtree. For any $x\in\R\setminus V(T)$, the \emph{search path} $P_T(x)$ in $T$ is the unique root-to-leaf path $v_0,\ldots,v_r$ in $T^+$ such that adding $x$ as a (left or right, as appropriate) leaf child of $v_{r-1}$ in $T$ would result in a binary search tree $T'$ with $V(T')=V(T)\cup\{x\}$.

The following observation allows us to replace (possibly large) numbers with (potentially shorter) binary strings:

\begin{obs}\obslabel{lexicographic}
  For any binary search tree $T$ and any $x,y\in V(T)$, $x<y$ if and only if $\sigma_T(x)$ is lexicographically less than $\sigma_T(y)$.
\end{obs}

Let $\R^+$ denote the set of positive real numbers. The following is an easy and often-used result about biased binary search trees:

\begin{lem}\lemlabel{biased-bst}
  For any $h\in\N^+$ and any function $w:\{1,\ldots,n\}\to\R^+$, there exists a binary search tree $T$ containing $\{1,\ldots,h\}$ such that, for each $i\in\{1,\ldots,h\}$, $d_T(i)\le\log(W/w(i))$, where $W:=\sum_{y=1}^h w(y)$.
\end{lem}

To construct the tree in \lemref{biased-bst}, choose the root of $T$ to be the unique node $y\in\{1,\ldots,h\}$ such that $\sum_{z=1}^{y-1} w(z)\le W/2$ and $\sum_{z=y+1}^{h} w(z)< W/2$.  Then recurse on $\{1,\ldots,y-1\}$ and $\{y+1,\ldots,n\}$ to obtain the left and right subtrees of $y$, respectively.

The following fact about binary search trees is useful, for example, in the deletion algorithms for several types of balanced binary search trees \cite[Section~6.2.3]{morin:open}:

\begin{lem}\lemlabel{predecessor-encoding}
  Let $T$ be a binary search tree and let $x,y\in V(T)$ be such that $x<y$ and there is no node $z\in V(T)$ such that $x<z<y$ (i.e., $x$ and $y$ are consecutive in the sorted order of $V(T)$).  Then
  \begin{enumerate}
    \item (if $y$ has no left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by removing all trailing 0's and the last 1; or
    \item (if $y$ has a left child) $\sigma_T(x)$ is obtained from $\sigma_T(y)$ by appending a 0 followed by $s:=d_T(y)-d_T(x)-1$ 1's.
  \end{enumerate}
\end{lem}

Putting some of the preceding results together we obtain the following useful coding result:

\begin{lem}\lemlabel{row-code}
  The exists a function $A:(\{0,1\}^*)^2\to\{-1,1,\perp\}$ such that, for any $h\in\N$, and any $w:\{1,\ldots,h\}\to\R^+$ there is a prefix-free code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that 
  \begin{compactenum}
    \item for each $i\in\{1,\ldots,h\}$, $|\alpha(i)|=\log W -\log w(i) + O(\lg\lg h)$; and
    \item for each distinct $i,j\in\{1,\ldots,h\}$, 
    \[   A(\alpha(i),\alpha(j)) 
    = \begin{cases}
       1 & \text{if $j=i+1$} \\
       -1 & \text{if $j=i-1$} \\
       \perp & \text{otherwise}
      \end{cases}
      \]
    \end{compactenum}
\end{lem}


\begin{proof}
  Define $w':\{1,\ldots,h\}\to \R^+$ as $w'(i)=w(i)+W/h$ and let $W':=\sum_{i=1}^h w'(i)=2W$.
  Using \lemref{biased-bst}, construct a biased binary search tree $T$ on $\{1,\ldots,h\}$ using $w'$ so that 
  \[   
    d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log w(i)+1
  \]
  and
  \[
  d_T(i)\le\log (2W)-\log(w(i)+W/h) \le \log W-\log (W/h)+1 \le \log h + 1\enspace ,
  \]
  for each $i\in\{1,\ldots,h\}$.  The code $\alpha(i$) for $i$ consists of three parts.  The first part, $\gamma(|\sigma_T(i)|)$, encodes the length of the path from the root to $i$ in $T$. The second part $\sigma_T(i)$ encodes the left/right turns along this path.  
  
  The third part $\delta(i)$ of $\alpha(i)$ is the encoding implicit in \lemref{predecessor-encoding}.  That is $\delta(i)$ consists of
  a single bit indicating whether $i$ has a left-child in $T$ and, in case $i$ does have a left-child, an Elias encoding $\gamma(s)$ of the value $s:=d_T(i-i)-d_T(i)-1$.  More precisely, $\delta(i)=0$ or $\delta(i)=1,\gamma(s)$.  The length of $\delta(i)$ is at most $1+O(\lg s)=O(\lg\lg h)$.

  The function $A$ is given by a simple algorithm: Given $\alpha(i)$ and $\alpha(j)$ we extract and lexicographically compare $\sigma_T(i)$ and $\sigma_T(j)$.  Assume, for now that $\sigma_T(i)$ is lexicographically less than $\sigma_T(j)$ so that, by \obsref{lexicographic}, $i < j$.  Now using $\sigma_T(j)$ and $\delta(j)$, compute $\sigma_T(j-1)$.  If $\sigma_T(j-1)=\sigma_T(i)$ then output $1$, otherwise output $\perp$.
  In the case where $\sigma_T(i)$ is lexicographically greater than $\sigma_T(j)$ we proceed in the same manner, but reversing the roles of $i$ and $j$ and outputting $-1$ in the case where $\sigma_T(i-1)=\sigma_T(j)$.
\end{proof}

\subsection{Chunked Sets and Fractional Cascading}

For non-empty sets $X,Y\subset \R$ and an integer $a$, we say that $X$ \emph{$a$-chunks} $Y$ if, for any $a+1$-element subset $S\subseteq Y$, there exists $x\in X$, such that $\min S\le x\le \max S$. Observe that, if $X$ $a$-chunks $Y$, then $|Y|\le a(|X|+1)\le 2a|X|$.

\begin{lem}\lemlabel{fractional}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exists sets $V_0,\ldots,V_{h+1}$ such that
  \begin{compactenum}
    \item for each $y\in\{1,\ldots,h\}$, $V_y\supseteq S_y$;
    \item for each $y\in\{1,\ldots,h\}$, $V_{y-1}$ 3-chunks $V_y$ and $V_{y+1}$ 3-chunks $V_y$;
    \item $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|$.
  \end{compactenum}
\end{lem}

A proof of a much more general version of \lemref{fractional} (with larger constants) is implicit in the iterated search structure of Chazelle and Guibas \cite{chazelle.guibas:fractional1}.   For the sake of completeness, \appref{fractional-proof} includes a proof that borrows heavily from the amortized analysis of partially persistent data structures \cite[Section~2.3]{driscoll.sarnak.ea:making}.


\subsection{Product Structure Theorems}

The \emph{strong product} $A\boxtimes B$ of two graphs $A$ and $B$ is the graph whose vertex set is the Cartesian product $V(A\boxtimes B):=V(A)\times V(B)$ and in which two vertices $v_1:=(x_1,y_1)$ and $v_2:=(x_2,y_2)$ are adjacent if and only if:
\begin{enumerate}
  \item  $v_1\neq v_2$; and
  \item $x_1=x_2$ or $x_1x_2\in E(A)$; and
  \item $y_1=y_2$ or $y_1y_2\in E(B)$.
\end{enumerate}

\begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure}
  Every planar graph $G$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of treewidth at most 8 and $P$ is a path.
\end{thm}

\thmref{product-structure} has a number of generalizations to other minor-closed families of graphs including bounded genus graphs.  The most general of these applies to apex-minor free graphs:

\begin{thm}[Dujmović \etal \cite{dujmovic.joret.ea:planar}]\thmlabel{product-structure-apex-minor-free}
  Let $\mathcal{G}$ be a minor-closed family of graphs that excludes some fixed apex graph.  Then every $G\in\mathcal{G}$ is the subgraph of a strong product $H\boxtimes P$ where $H$ is a graph of bounded treewidth and $P$ is a path.
\end{thm}

Dujmović, Morin, and Wood \cite{dujmovic.morin.ea:structure} give analogous product structure theorems for some non-minor closed families of graphs based on so-called $(k,d)$-shortcut systems.  Such graphs include $k$-planar graphs, map graphs, powers of bounded-degree planar graphs, and $k$-nearest-neighbour graphs of points in $\R^2$.  Our main result, which is a labelling scheme for subgraphs of $H\boxtimes P$ where $H$ has bounded treewidth and $P$ is a path holds for all these classes of graphs.


\section{Bulk Trees}
\seclabel{bulk-trees}

The labelling scheme for planar graphs uses labels whose largest part comes from paths in a special type of balanced binary search tree that we call a \emph{bulk tree}.  The operations in a bulk tree proceed in \emph{rounds} where, in each round, two types of bulk operations are performed: \emph{bulk insertion}, in which a set $I\subset \R\setminus V(T)$ of new values are inserted into $T$, and \emph{bulk deletion}, in which a set $D\subseteq V(T)$ of values are removed from $T$. The sets $I$ and $D$ inserted into and deleted from $T$ in a single round must satisfy the following two restrictions: (i)~$V(T)$ $3$-chunks $I$; and (ii)~$V(T)\setminus D$ 3-chunks $D$.\footnote{There is nothing special about the constant $3$ here.  The data structure and its analysis work with $3$ replaced by any constant $a$.}  Note that (ii) implies that $|D|\le 6|V(T)|-|D|$, so $|D|\le (6/7)|V(T)|$.

\subsection{Phases}

A bulk tree is parameterized by an integer $k\ge 1$.  The rounds of a bulk tree are broken up into \emph{phases} that are kept track of using two integer values.  At the beginning of a phase, a counter $y$ is initialized to $0$ and a value $y^*$ is computed:
\[  
  y^* := \left\lceil \frac{\log|T|}{k-\log 7}\right\rceil 
\]
After each round, the value $y$ is incremented.  When $y=y^*$, a new phase begins, so $y$ is reset to 0 and a new value of $y^*$ is computed using the current size of $T$.

\subsection{Bulk Insertion}

The bulk insertion operation is implemented as follows: Let $z_0,\ldots,z_{|T||}$ denote the external nodes of $T$.  For each $i\in\{0,\ldots,|T|\}$, let $I_i:=\{x\in I: P_T(x)=z_i\}$. Since $V(T)$ $3$-chunks $I$, $|I_i|\le 3$ for each $i\in\{0,\ldots,|T|\}$. For each $i\in\{0,\ldots,|T|\}$, construct a perfectly balanced binary search tree $T_i$. For each $i\in\{1,\ldots,|T|\}$, replace $z_i$ with $T_i$ in $T^+$.

\begin{lem}\lemlabel{insertion-depth}
  Let $T$ be any binary tree and perform a bulk insertion on $T$ to obtain a new tree $T'$.  Then $T'$ is a supergraph of $T$ and $h(T')\le h(T)+2$.
\end{lem}

\begin{proof}
  That $T'$ is a supergraph of $T$ is obvious.  That $h(T')\le h(T)+2$ comes from the fact that, for each $i\in\{0,\ldots,|T|\}$, $|T_i|=|I_i|\le 3$ and $T_i$ is perfectly balanced, so $h(T_i)\le\lfloor\log 3\rfloor = 1$. Recall that $h(T')$ is the length of the longest root-to-leaf in $T'$. Any root-to-leaf path in $T'$ consists of a root-to-leaf path in $T$ followed by at most 2 elements of $T_i$ for some $i\in\{1,\ldots,|T|\}$.  Therefore the length of any root-to-leaf path in $T'$, and therefre $h(T')$, is at most $h(T)+2$.
\end{proof}

\begin{lem}\lemlabel{insertion-size}
  Let $T$ be any binary tree and perform a bulk insertion on $T$ to obtain a new tree $T'$.  Let $x\in V(T)$ be any node of $T$ and let $T_x$ and $T_x'$ be the subtrees of $T$ and $T'$, respectively, rooted at $x$.  Then $|T_x'|\le 7|T_x|$.
\end{lem}

\begin{proof}
  By definition, $V(T)$ 3-chunks $I:=V(T')\setminus V(T)$.  This implies that $V(T_x)$ 3-chunks $I_x:=V(T_x')\setminus V(T_x)$.  Therefore $|I_x|\le 3(|T_x|+1)\le 6|T_x|$, so $|T_x'|=|T_x|+|I_x|\le 7|T_x|$.
\end{proof}


\subsection{Bulk Deletion}

The bulk deletion operation is implemented as a series of $|D|$ individual deletions, performed in any order, each implemented by running the following recursive algorithm for each $x\in D$:  If $x$ is a leaf, then simply remove $x$ from $T$.  Otherwise, $x$ has at least one child.  If $x$ has a left child, then recursively delete the largest value $x'$ in the subtree of $T$ rooted at the left child of $x$ and then replace $x$ with $x'$.  Otherwise $x$ has a right child, so recursively delete the smallest value $x'$ in the subtree of $T$ rooted at the right child of $x$ and then replace $x$ with $x'$.


\begin{lem}\lemlabel{deletion-signature}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, for any $x\in V(T')$, $\sigma_{T'}(x)$ is prefix of $\sigma_T(x)$.
\end{lem}

\begin{proof}
  This follows immediately from the fact the only operations performed during a bulk deletion are (i)~deletion of leaves and (ii)~using a value $x'$ to replace the value of one of its $T$-ancestors $x$.  The deletion of a leaf has no effect on $\sigma_{T'}(x)$ for any $x\in V(T')$ since the deleted leaf is not in $V(T')$.  For any node $z$ other than $x'$, (ii) has no effect on $\sigma_T(z)$.  For the node $x'$, (ii) has the effect of replacing $\sigma_T(x')$ by its length-$d_T(x)$ prefix.  
  % Therefore, for any node $z\in v(T)$, $\sigma_{T'}(z)$ is obtained by truncating $\sigma_{T}(z)$ zero or more times, so $\sigma_{T'}(x)$ is a prefix of $\sigma_T(z)$.
\end{proof}

The following consequence of \lemref{deletion-signature} follows immediately from the fact, for any node $z$ in a binary search tree $T$, $d_T(z)=|\sigma_T(z)|$.

\begin{lem}\lemlabel{deletion-depth}
  Let $T$ be any binary search tree and perform a bulk deletion on $T$ to obtain a new tree $T'$.  Then, $h(T')\le h(T)$.
\end{lem}


\subsection{Rebalancing}

At the beginning of a round, before bulk insertion and bulk deletion, a rebalancing operation is performed.  This operation uses several subroutines that we now discuss, beginning with the most fundamental one:  $\mathrm{split}(x)$.

\subsubsection{$\mathrm{split}(x)$}

The argument of $\mathrm{split}(x)$ is a node $x\in V(T)$ and the end result of the subroutine is to split $T$ into two subtrees $T_{<x}$ and $T_{>x}$ where $V(T_{<x})=\{z\in V(T): z<x\}$ and $V(T_{>x})=\{z\in V(T): z>x\}$. Refer to \figref{split}.  Let $x_0,\ldots,x_r$ be the path in $T$ from the root $x_0$ of $T$ to $x=x_r$.  Partition $x_0,\ldots,x_{r-1}$ into two subsequences $a:=a_0,\ldots,a_\iota$ and $b:=b_0,\ldots,b_\kappa$ where the elements of $a$ are less than $x$ and the elements of $b$ are greater than $x$.

\begin{figure}
  \begin{center}
    \includegraphics{figs/split-1} \\[1ex]
    $\Downarrow$ \\[1ex]
    \includegraphics{figs/split-2}
  \end{center}
  \caption{The operation of $\mathrm{split}(x)$.}
  \figlabel{split}
\end{figure}

Make a binary search tree $T_0$ that has $x$ as root, the path $a_0,\ldots,a_t$ as the left subtree of $x$ and the path $b_0,\ldots,b_s$ as the right subtree of $x$.  Note that $a_{i+1}$ is the right child of $a_i$ for each $i\in\{1,\ldots,\iota-1\}$ and $b_{i+1}$ is the left child of $b_i$ for each $i\in\{1,\ldots,\kappa-1\}$. 

Next, consider the forest $F:=T-\{x_0,\ldots,x_r\}$. This forest consist of $r+2$ (possibly empty) trees $A_1,\ldots,A_{r-1},L,R$ where $L$ and $R$ are the subtrees of $T$ rooted at the left and right child of $x$ and, for each $i\in\{1,\ldots,r-1\}$, $A_i$ is the subtree of $T$ rooted at the child $c_i\neq x_{i+1}$ of $x_i$.  Make a binary search tree $T_x$ by replacing each of the $r+2$ external nodes of $T_0^+$ with the appropriate tree in $F$.  Finally, let $T_{<x}$ be the subtree of $T_x$ rooted at the left child of $x$ and let $T_{>x}$ be the subtree of $T_x$ rooted at the right child of $x$.

\begin{lem}\lemlabel{split-height}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\mathrm{split}(x)$ to obtain $T_{<x}$ and $T_{>x}$.  
  Then $h(T_{<x})\le h(T)$ and $h(T_{>x})\le h(T)$.
\end{lem}

\begin{proof}
  We consider only $T_{<x}$ since the argument for $T_{>x}$ is the same.
  Recall that $h(T_{<x})=\max_{z\in V(T_{<x})} d_{T_{<x}}(z)$.  For each node $z\in V(T_{<x})$, $V(P_{T_{<x}}(z))\subseteq V(P_T(z))$, so $d_{T_{<x}}(z)\le d_T(z)$.
\end{proof}

\subsubsection{$\textrm{multisplit}(x_1,\ldots,x_c)$}

From the $\mathrm{split}(x)$ operation we build the $\textrm{multisplit}(x_1,\ldots,x_c)$ operation that takes as input a sequence of nodes $x_1<\cdots<x_c$ of $T$.  For convenience, define $x_0=-\infty$ and $x_{c+1}=\infty$.  The effect of $\textrm{multisplit}(x_1,\ldots,x_c)$ is to split $T$ into a sequence of binary search trees $T_0,\ldots,T_{c}$ where, for each $i\in\{0,\ldots,c\}$, $V(T_i)=\{z\in V(T): x_i< z<x_{i+1}\}$.

The implementation of $\textrm{multisplit}(x_1,\ldots,x_c)$ is straightforward divide-and-conquer:  If $c=0$, then there is nothing to do.  Otherwise, call $\mathrm{split}(x_{\lceil c/2\rceil})$ to obtain $T_{<x_{\lceil c/2\rceil}}$ and $T_{>x_{\lceil c/2\rceil}}$.  Next, apply $\textrm{multisplit}(x_1,\ldots,x_{\lceil c/2\rceil-1})$ to $T_{<x_{\lceil c/2\rceil}}$ to obtain $T_0,\ldots,T_{\lceil c/2\rceil-1}$ and then apply $\textrm{multisplit}(x_{\lceil c/2\rceil+1},\ldots,x_c)$ to $T_{>x_{\lceil c/2\rceil}}$ to obtain $T_{\lceil c/2\rceil},\ldots,T_c$.

The following lemma is immediate from \lemref{split-height} 
\begin{lem}\lemlabel{multisplit-height}
  Let $T$ be any binary search tree and apply the $\textrm{multisplit}(x_1,\ldots,x_c)$ to $T$ to obtain $T_0,\ldots,T_c$.  Then $h(T_i)\le h(T)$ for each $i\in\{0,\ldots,c\}$.
\end{lem}

\subsubsection{$\mathrm{balance}(x)$}

The $\mathrm{balance}(x)$ operation operates on the subtree $T_x$ of $T$ rooted at some node $x\in V(T)$.  If $|V(T_x)|< 2^k$, then this operation is simply replaces $T_x$ with a perfectly balanced binary search tree containing $V(T_x)$.  

If $|V(T_x)|\ge 2^k$, let $Z\subset V(T_x)$ be the set of at most $2^k-1$ nodes of $T_x$ of depth less than $k$.  Then $T_x-Z$ is a forest consisting of $m\le 2^{k}$ trees $T_1,\ldots,T_m$.  
% Each such tree $T_i$ has height at most $h(T)-k$.

Select the nodes $X:=\{x_1,\ldots,x_{2^k-1}\}$ of $T$ where each $x_j$ has rank $\lfloor j|T_x|/2^k\rfloor$ in $V(T_x)$.\footnote{For a finite $X\subset\R$, and $x\in\R$, the \emph{rank} of $x$ in $S$ is $|\{x'\in S: x'<x\}|$.}  For each $j\in\{1,\ldots,m\}$, apply $\mathrm{multisplit}(K_j)$ to the subtree $T_j$ with with the values $K_j:=X\cap V(T_j)$.  The end result of doing this for each $j\in\{1,\ldots,m\}$ is a collection $T^@_0,\ldots,T^@_\rho$ of subtrees where, for each $i\in\{0,\ldots,\rho\}$, $Z\cup X$ is disjoint from $[\min(V(T^@_i)), \max(V(T^@_i))]$.

Now construct a perfectly balanced tree $T_0$ on $Z\cup X$ and, for each $i\in\{0,\ldots,\rho\}$ replace the appropriate external node of $T_0$ with $T^@_i$ to obtain the new binary search tree $T_x'$.  In $T$, replace $T_x$ with $T_x'$.

\begin{lem}\lemlabel{multisplit-depth}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, and apply $\mathrm{balance}(x)$ to $T$ to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{proof}
  Since $\mathrm{balance}(x)$ only affects the subtree $T_x$ rooted at $x$, it suffices to show that $h(T_x')\le h(T_x)+1$.  For each $i\in\{1,\ldots, m\}$,$T_i$ is rooted at a depth-$k$ node of $T$, so $h(T_i)\le h(T)-k$. For each $j\in\{0,\ldots,\rho\}$, $T^@_j$ is obtained by an application of the multisplit operation to $T_i$ for some $i\in\{1,\ldots,m\}$ so, by \lemref{multisplit-height}, $h(T^@_j)\le h(T_i)\le h(T)-k$.  Next, $|Z\cup Y|\le |Z|+|Y| \le 2^k-1 + 2^k-1 < 2^{k+1}-1$ and $T_0$ is a perfectly balanced binary search tree of size $|T_0|=|Z\cup X|$.  Therefore $h(T_0)\le \lfloor\log|T_0|\rfloor\le \lfloor\log(2^{k+1}-1)\rfloor = k$.  Finally, $h(T')\le h(T_0)+1 +\max\{h(T^@_j):j\in\{1,\ldots,\rho\} \le h(T)+1$.  
\end{proof}

\begin{lem}\lemlabel{balance-x-weight}
  Let $T$ be any binary search tree, let $x$ be any node of $T$, let $T_x$ be the subtree of $T$ rooted at $x$, and apply $\mathrm{balance}(x)$ to $T$ to obtain a new tree $T'$.  Then, for each $T'$-descendant $z$ of $x$ with $d_{T'}(z)=d_{T}(x)+k+1$, the subtree of $T$ rooted at $z$ has size at most $|T_x|/2^k$.
\end{lem}

\begin{proof}
  Each such subtree is a subtree of $T^@_\iota$ for some $\iota\in\{0,\ldots,\rho\}$. Now, $V(T^@_\iota)\subset (x_j,x_{j+1})$ for some $j\in\{1,\ldots,2^{k-1}\}$.  The values $x_j$ and $x_{j+1}$ have ranks $\lfloor j|T_x|/2^k\rfloor$ and $\lfloor (j+1)|T_x|/2^k\rfloor$ in the set $V(T_x)$.  Therefore, $|T^@_\iota|\le \lfloor (j+1)|T_x|/2^k\rfloor- \lfloor j|T_x|/2^k\rfloor -1 < |T_x|/2^k$.
\end{proof}

\subsubsection{$\mathrm{bulkbalance}(\theta)$}

The ultimate restructuring operation in bulk trees is $\mathrm{bulkbalance}(\theta)$, and it is easy to describe.  It calls $\mathrm{balance}(z)$ for each node $z$ of depth $\theta$ in $T$.
The following two lemma are immediate consequences of \lemref{multisplit-depth} and \lemref{balance-x-weight}, respectively.

\begin{lem}\lemlabel{balance-depth}
  Let $T$ be a bulk tree and apply the $\mathrm{bulkbalance}(\theta)$ operation to obtain a new tree $T'$.  Then $h(T')\le h(T)+1$.
\end{lem}

\begin{lem}\lemlabel{balance-weight}
  Let $T$ be a bulk tree and apply the $\mathrm{bulkbalance}(\theta)$ operation to obtain a new tree $T'$.  Then every subtree $T_z$ of $T'$ rooted at a node $z$ of depth $\theta+(k+1)$ has size at most $|T_x|/2^k$, where $x$ is the depth-$\theta$ $T$-ancestor of $z$ and $T_x$ is the subtree of $T$ rooted at $x$.
\end{lem}

Finally, recall that a bulk tree works in phases and, within a phase, maintains a counter $y$ that counts the rounds of the phase from $0$ to $y^*$.  The $\mathrm{balance}(\theta)$ operation executes once, at the beginning of each round, with the argument $\theta=y(k+1)$.

\subsection{Analysis of Height}

In this section we show that a bulk tree always has a height that is close to optimal.

\begin{lem}\lemlabel{bulktree-height-i}
  Let $T$ be a bulk tree, let $T_0,\ldots,T_{y^*}$ be the states of $T$ before the first round ($T_0$) and after each round ($T_1,\ldots,T_{y^*}$) of a phase, and let $r_0=h(T_0)-\log|T_0|$.  Then,
  \begin{compactenum}[(i)]
    \item for each $y\in\{0,\ldots,y^*\}$, $h(T_y)\le (1+O(1/k))\log|T_y| + r_0$.
    \item $h(T_{y^*}) = \log|T_{y^*}|+O(k+k^{-1}\log|T_{y^*}|)$; and 
  \end{compactenum}
\end{lem}

\begin{proof}
  Let $I_0,\ldots,I_{y^*-1}$ and $D_0,\ldots,D_{y^*-1}$ be the sets inserted and deleted so that $I_y$ and $D_y$ are the bulk insertions and bulk deletions performed in round $y$.  First, recall that $|D_y|\le (6/7)|T_y|$, which implies that $|T_{y+1}|\ge |T_y|-|D_y|\ge |T_y|/7$.  Iterating this beginning with $T_0$ implies that 
  \begin{equation}
    |T_y|\ge |T_0|/7^y \quad \Leftrightarrow \quad \log|T_0| \le \log|T_y| + y\log 7 \enspace . \eqlabel{height-diff}
  \end{equation}
  for each $y\in\{0,\ldots,y^*\}$. 


  We will prove the lemma by establishing the following two invariants:
  \begin{enumerate}[(B1)]
    \item $h(T_y)\le h(T_0) + 3y$;
    \item each subtree of $T_y$ rooted at a node of depth $y(k+1)$ has size at most $|T_0|(7/2^k)^{y}$.
  \end{enumerate}

  First we show that (B1) implies (i). For each  $y\in\{0,\ldots,y^*\}$, (B1) gives the upper bound
  \begin{align}
       h(T_y) & \le h(T_1) + 3y \nonumber \\
              &= \log|T_1| + 3y + r_0 \nonumber \\
              &\le \log |T_y| + (3+\log 7)y + r_1 \nonumber \\
              &\le \log |T_y| + (3+\log 7)y^* + r_1 \nonumber \\
              &\le \log |T_y| + O(k^{-1}\log|T_y|) + r_1 \enspace .
  \end{align}

  Next we show that (B2) implies (ii).  Recall that $y^*=\lceil\log|T_0|/(\log(2^k/7))\rceil$ so
  $|T_{0}|(7/2^k)^{y^*} \le 1$.  Therefore, by (B2) every subtree of $T_{y^*}$ of depth $y^*(k+1)$ has size at most 1.  A subtree of size 1 has height 0.  Therefore,
  \begin{align*}
    h(T_{y^*}) & \le (k+1)y^* \\
    & = (k+1)\left\lceil \frac{\log|T_1|}{k-\log 7}\right\rceil \\
    & \le (k+1)\left(\frac{\log|T_1|}{k-\log 7 } + 1\right)\\
    & = \left(\frac{k+1}{k-\log 7}\right)\left(\log|T_1|\right) + (k+1)\\
    & = (1+O(1/k))\cdot(\log|T_1|) + (k+1) \\
    & \le (1+O(1/k))\cdot(\log|T_{y^*}| + y^*\log 7) + (k+1) \\
    & = \log|T_{y^*}| + O(k+k^{-1}\log |T_{y^*}|) \enspace .
  \end{align*}
  for $k\in\omega(1)$.  \snote{Quantify?}


  All that remains is to show that invariants (B1) and (B2) are indeed satisfied for all $y\in\{0,\ldots,y^*\}$.  The proof is by induction on $y$.  For the base case $y=0$, both properties are trivial: (B1) asserts that $h(T_0)\le h(T_0)$ and (B2) asserts that the subtree of $T_0$ rooted at the root of $T_0$ has size at most $|T_0|$.

  For the inductive step, assume $y\ge 1$ and invariants (B1) and (B2) hold for $T_{y-1}$.  First we establish invariant (B1) as follows:
  Lemmas~\ref{lem:insertion-depth}, \ref{lem:deletion-depth}, and \ref{lem:balance-depth} imply that $h(T_y)\le h(T_{y-1})+3$.  
  By the inductive hypothesis (B1) is satisfied for $T_{y-1}$, so $h(T_{y-1})\le 3(y-1) + r_0$.  Thus $h(T_y)\le h(T_{y-1}) + 3 \le 3y+r_0$.
  
  Next we establish (B2).  By (B2) applied to $T_{y-1}$, every subtree of $T_{y-1}$ rooted at a node of depth $(y+1)(k+1)$ has size at most $|T_{1}|(2a/2^k)^{y-1}$.  The first step in round $y-1$ is to execute $\mathrm{bulkbalance}((y-1)(k+1))$.  By \lemref{balance-weight}, this results in a tree $T_{y-1}'$ in which every subtree rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y-1}/2^k$.  The second step in round $y-1$ is perform a bulk insertion on $T_{y-1}'$ to obtain a new tree $T_{y-1}''$.  
  % The fact that $V(T_{y-1})$ 3-chunks the newly inserted set $I_{y-1}$ ensures that the size of any subtree increases by a factor of at most $6$.  
  By \lemref{insertion-size}, every subtree of $T_{y-1}''$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y}$.  Finally, third step in round $y-1$ is to perform a bulk deletion on $T_{y-1}''$ to obtain $T_{y}$.  Bulk deletion does not increase the size of any subtree, so every subtree of $T_{y}$ rooted at a node of depth $y(k+1)$ has size at most $|T_{0}|(7/2^k)^{y}$, as required.
\end{proof}

A \emph{bulk tree sequence} $T_1,\ldots,T_h$ is a sequence of binary search trees where $T_1$ is a perfectly balanced binary search tree and for each $y\in\{2,\ldots,h\}$, $T_y$ is obtained from $T_{y-1}$ by a round of bulk tree operations (rebalance, bulk insert, bulk delete).  Note that any bulk tree sequence also defines sequences $I_1,\ldots,I_{h-1}$ and $D_1,\ldots,D_{h-1}$ of insertion and deletion sequences, respectively, where $I_y:=V(T_{y+1})\setminus V(T_y)$ and $D_y:=V(T_{y})\setminus V(T_{y+1})$ for each $y\in\{1,\ldots,h-1\}$. 
The following lemma shows that bulk trees are balanced at all times:
\begin{lem}\lemlabel{bulk-tree-height}
  For each bulk tree sequence $T_1,\ldots,T_h$ and each $y\in\{1,\ldots,h\}$,  $h(T_y)\le \log|T_y| + O(k+k^{-1}\log|T_y|)$.
\end{lem}

\begin{proof}
  % This lemma follows almost immediately from \lemref{bulktree-height-i}(ii) except for the additional $r_0$ term. 
  Let $Y\subseteq\{1,\ldots,h\}$ be the set of indices containing exactly those indices $y$ where $T_y$ begins a new phase. By definition $1\in Y$ and, since $T_1$ is a perfectly balanced binary tree it certainly satisfies the conditions of the lemma.  For $y\in Y\setminus\{1\}$, 
  \lemref{bulktree-height-i}(ii) implies that $T_y$ satisfies the conditions of the lemma.  
  
  All that remains is to show that the conditions of the lemma are satisfied for each $y\in\{1,\ldots,h\}\setminus Y$. To show this, let $y_0=\max\{ y'\in Y: y'<y\}$.  That is, $T_{y_0}$ is the tree that began the phase in which $T_y$ takes part.  In this case \lemref{bulktree-height-i}(i) implies that
  \[  h(T_y) \le (1+O(1/k))\log |T_y| + h(T_{y_0})-\log|T_{y_0}| \]  
  Thus, all all that is required is to show that $r_0:=h(T_{y_0})-\log|T_{y_0}|\in O(k^{-1}\log|T_y|)$ so that is what we do:
  \begin{align*}
    r_0 &= h(T_{y_0})-\log|T_{y_0}| \\
       &\le O(k + k^{-1}\log|T_{y_0}|) 
        & \text{(by \lemref{bulk-tree-height}(ii))}\\
       &\le O(k + k^{-1}(\log|T_{y}| + (y-y_0))) 
        & \text{(by \eqref{height-diff})} \\
       &\le O(k + k^{-1}\log|T_{y}| + k^{-2}\log|T_0|) 
        & \text{(since $y-y_0 < y^*$)}\\
       &= O(k + k^{-1}\log|T_{y}|) \enspace ,
  \end{align*}
  for $k\in\omega(1)$. \snote{Again: quantify?}
\end{proof}

Definition: A \emph{bulk tree sequence} is a sequence of trees $T_0,\ldots,T_h$ such that $T_0$ is a perfectly balanced binary search tree and, for each $y\in\{1,\ldots,h\}$, $I_y:=V(T_y)\setminus V(T_{y-1})$ and $D_y:= V(T_{y-1})\setminus V(T_y)$.  ....

\subsection{Making Bulk Tree Sequences}

Although the 3-chunking requirements on the insertion and deletion sets of bulk trees seems restrictive, the following lemma allows us to store any sequence of subsets of $\R$ in a bulk tree sequence that is not much larger.

\begin{lem}\lemlabel{chunked-bulk-trees}
  For any finite sets $S_1,\ldots,S_h\subset\R$, there exists a bulk tree sequence $T_1,\ldots,T_h$ such that $\sum_{y=1}^h |T_y|\le 2\sum_{y=1}^h |S_i|$ and, for each $y\in\{1,\ldots,h\}$, $V(T_y)\supseteq S_y$.
\end{lem}

\begin{proof}
  Apply \lemref{fractional} to the sequence $S_1,\ldots,S_h$ in order to obtain $V(T_1),\ldots,V(T_h)$ satisfying the conditions of the lemma and satisfying the 3-chunking requirement of bulk trees, namely that $V(T_y)$ 3-chunks $I_y:=V(T_{y+1})\setminus V(T_y)$ and that $V(T_{y+1})$ 3-chunks $D_y:=V(T_y)\setminus V(T_{y+1})$.
\end{proof}

\subsection{Transition Codes for Nodes}
\seclabel{node-transitions}

We are now getting to the main point of bulk trees:  For two consecutive trees $T_y$ and $T_{y+1}$ in a bulk tree sequence and any $x\in V(T_y)\cap V(T_{y+1})$, the signatures $\sigma_{T_y}(x)$ and $\sigma_{T_{y+1}}(x)$ are so closely related that $\sigma_{T_{y+1}}(x)$ can be derived from $\sigma_{T_y}(x)$ and a short \emph{transition code} $\nu_y(x)$.  The following lemma makes this precise:

\begin{lem}\lemlabel{node-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for each bulk tree sequence $T_1,\ldots,T_h$, each $y\in\{1,\ldots,h-1\}$, and each $z\in V(T_y)\cap V(T_{y+1})$, there exists $\nu_y(z)\in\{0,1\}^*$ with $|\nu_y(z)| = O(k\lg h(T_y))$ such that $B(\sigma_{T_y}(z), \nu_y(z)) = \sigma_{T_{y+1}}(z)$.  
\end{lem}

\begin{proof}
  The transformation of $T_{y}$ into $T_{y+1}$ occurs in three steps: rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion of $D_y$, which takes $T_y''$ onto $T_{y+1}$.  We consider each of these in turn, saving the most difficult for last.
  
  The transition from $T_y''$ to $T_{y+1}$ (bulk deletion) is simple.  By \lemref{deletion-signature}, the effect of each individual deletion on $\sigma_T(z)$ is to remove a suffix.  Therefore, the net effect of all deletions is to remove a suffix.  The length of this suffix can be included in $\nu_y(x)$ using $O(\lg h(T))$ bits.
  
  The transition from $T_y'$ to $T_y''$ (bulk insertion) is even simpler: For every node $z\in V(T_y')\cap V(T_y'')$, $\sigma_{T_y'}(z)=\sigma_{T_y''}(z)$.  A bulk addition does not require any changes to encode.
  
  The most elaborate transition is from $T_y$ to $T_y'$ (rebalancing).  We will show how to obtain $\sigma_{T_y'}(z)$ by starting with $b:=\sigma_{T_y}(z)$ and performing the following operations:
  \begin{enumerate}[($\nu_1$)]
    \item Splitting $b$ into two strings $b^-$ and $b'$ at some index $\theta$ that can be specified using $O(\lg h(T))$ bits.
    \item Deleting a prefix of $b'$ whose length is at most $k$ and can be described using $O(\lg h(T))$ bits.
    \item Repeatedly (up to $k$ times) deleting a prefix of $b'$ and replacing it with a string in the set $\Pi:=\{\varepsilon\}\cup\bigcup_{j=0}^{h(T_y)}\{0^j, 1^j, 0^j1, 1^j0\}$. The length of each deleted prefix and its replacement can be described with $O(\lg h(T))$ bits for a total of $O(k\lg h(T))$ bits.
    \item Adding a specific $O(k)$-bit prefix to $b'$, which can be described with $O(k)$ bits.
    \item Concatenating $b^-$ and $b'$ to obtain $\sigma_{T_y'}(z)$.
  \end{enumerate}
  To verify this we have to dig into the details of the rebalancing operations, which involves a single call to $\mathrm{bulkbalance}(\theta)$ which calls $\textrm{balance}(x)$ on each of the nodes $x\in V(T_y)$ of depth $\theta$.    
  For a node $z\in V(T)$, a call to $\textrm{balance}(x)$ does not affect $\sigma_T(z)$ unless $x$ is an ancestor of $z$ in $T$.  Thus, for each $z\in V(T)$, we can focus on the changes to $\sigma_T(z)$ caused by the at most one call to $\textrm{balance}(x)$ where $x$ is an ancestor of $z$. Note that, if $d_{T_y}(z)<\theta$, then $\sigma_{T_y}(z)=\sigma_{T_y'}(z)$, in which case $\nu(z)$ has $O(1)$ bits indicating that this is the case and parts ($\nu_1(z)$)--($\nu_4(z)$) of $\nu_y(x)$ are empty.
  
  Otherwise, $z$ has some depth-$\theta$ $T_y$-ancestor $x$ on which $\textrm{balance}(x)$ executes. In this case $\nu_{1}(z)=\theta$, indicating that $b$ should be split into $b^-$ and $b'$ at position $\theta$.  
  The $\textrm{balance}(x)$ operation first identifies two sets of nodes $Z$ and $X$ that will eventually form the perfectly balanced tree $T_0$ to which the subtrees $T^@_0,\ldots,T^@_\rho$ are attached.  For each node $z\in Z\cup X$, $\nu_{2}(z):=|b'|$ and $\nu_{4}(z):=\sigma_{T_0}(z)$ indicating that all of $b'$ should be deleted and replaced with $\sigma_{T_0}(z)$.  For these node ($\nu_3(z)$) is empty.
    
  Otherwise, each $z\not\in Z\cup X$ is contained in some tree $T_*$ in the forest $F:=T_y-Z$.  In this case, the $\mathrm{multisplit}(x_1,\ldots,x_c)$ operation may be called on $T_*$.  If this occurs, then $z$ may be involved in at most $1+\log c\le 1+k$ subtrees that are split by calls to $\mathrm{split}(x)$.  Any call to $\mathrm{split}(x)$ on a subtree $A$ that contains $z$ leaves $z$ in one of the two resulting subtrees, say $A_{<x}$.  When this happens $\sigma_{A_{<x}}(z)$ can be obtained from $b':=\sigma_{A}(z)$ by deleting a prefix and replacing it with a string from $\Pi$ (see \figref{split}).  This happens at most $k+1$ times and $|\Pi|= 4(h(T_y)+1)+1$, so all of these changes can be recorded with $O(k\lg h(T_y))$ bits that are included in $\nu_{3}(z)$.
  
  At the end of this process, $z\in V(T^@_j)$ for some $j\in\{1,\ldots,\rho\}$, and $b'=\sigma_{T^@_j}(z)$.  The tree $T^@_j$ is a subtree of $T_y'$.  The final piece of information then is $\nu_4(z):=\sigma_{T_0}(z')$, where $z'$ is the root of $T^@_j$.  This is a bitstring of length $h(T_0)+1\le k+1$.
\end{proof}

\section{Subgraphs of $P\boxtimes P$}
\seclabel{pxp}

Before continuing, we show that using the techniques developed thus far, we can already solve a difficult special case.  In particular, we consider the case in which $G$ is an $n$-vertex subgraph of $P_1\boxtimes P_2$ where $P_1=1,\ldots,m$ and $P_2=1,\ldots,h$ are paths. Each vertex of $G$ is a point $(x,y)\in\{1,\ldots,m\}\times \{1,\ldots,h\}$ in the $m\times h$ grid-with diagonals (see \figref{pxp}).

\begin{figure}
  \begin{center}
    \includegraphics{figs/pxp}
  \end{center}
  \caption{The special case where $G$ is a subgraph of $P_1\boxtimes P_2$.}
  \figlabel{pxp}
\end{figure}


\subsection{The Labels}

For each $y\in\{1,\ldots,h\}$, we let $L_y=\{x\in\{1,\ldots,m\}:(x,y)\in V(G)\}$ and let $L^-_y:=L_y\cup\{x-1:(x,y)\in V(G)\}$.  Observe that $|L^-_y|\le 2|L_y|$, so $\sum_{y=1}^h |L^-_y|\le 2n$.   Apply \lemref{chunked-bulk-trees} to obtain a sequence $T_1,\ldots,T_h$ of binary search trees such that

\begin{enumerate}[(PR1)]
  \item $V(T_y)\supseteq L^-_{y}\cup L^-_{y-1}$;
  \item $h(T_y)=\log|T_y| + O(k+k^{-1}\lg n)$;
  \item $\sum_{y=1}^h|T_y| \le 8n$.
\end{enumerate}

By \lemref{node-transitions}, for each $y\in\{2,\ldots,h\}$ and each $x\in L_{y-1}$, there exists a code $\nu_{y-1}(x)$, $|\nu_y(x)|=O(k\lg\lg n)$ such that $B(\sigma_{T_{y-1}}(x),\nu_{y-1}(x))=\sigma_{T_y}(x)$.

Next, apply \lemref{row-code} using the weight function $w(y):=|T_y|$ to obtain a code $\alpha:\{1,\ldots,h\}\to \{0,1\}^*$ such that $|\alpha(y)|=\log n - \log|T_y| + O(\lg\lg n)$.

Now, in the labelling scheme for $G$, each vertex $z=(x,y)\in V(G)$ receives a label consisting of the following:  
\begin{enumerate}[(GC1)]
  \item $\alpha(y)$;
  \item $\gamma(|\sigma_{T_y}(x)|)$ and $\sigma_{T_y}(x)$;
  \item $\delta_{T_y}(x)$ and $\delta_{T_{y+1}}(x)$;
  \item $\nu_y(x)$; and
  \item an array $a(v)$ of $8$ bits indicating whether each of the edges between $(x,y)$ and $(x\pm 1,y\pm 1)$ are present in $G$.  (Note that some of these 8 vertices may not even be present in $G$ in which case the resulting bit is set to 0 since the edge is not present in $G$.)
\end{enumerate}
The two major components of this label are $\alpha(y)$ (GC1) and $\sigma_{T_y}(x)$ (GC2) which, together have length $\log n + O(\lg\lg n)$.  The remaining components each have size $O(\lg\lg n)$, except for (GC4) which has size $O(k\lg\lg n)$.  Thus, the total length of each label is $\log n+ O(k\lg\lg n + k^{-1}\log n)$.  

\subsection{Adjacency Testing}

Given the labels of $z_1=(x_1,y_1)$ and $z_2=(x_2,y_2)$ we can test if they are adjacent as follows: Using with $\alpha(y_1)$ and $\alpha(y_2)$ (GC1), determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|\ge 2$: In this case we immediately conclude that $z_1$ and $z_2$ are not adjacent since $y_1y_2\not\in E(P_1)$.  
  
  \item $y_1=y_2$: In this case, let $y:=y_1=y_2$, let $T:=T_y$ and lexicographically compare $\sigma_T(x_1)$ and $\sigma_T(x_2)$ to determine (without loss of generality) that $x_1<x_2$.  Using $\sigma_{T}(x_2)$ and $\delta_{T}(x_2)$, compute $\sigma_T(x_2-1)$.  If $\sigma_T(x_2-1)\neq \sigma_T(x_1)$ then immediately conclude that $z_1$ and $z_2$ are not adjacent, since $x_1x_2\not\in E(P_2)$.  Otherwise, we know that $x_1=x_2-1$ and $y_1=y_2$ so use the relevant bit of $a(z_1)$ (or $a(z_2)$) to determine if $z_1$ and $z_2$ are adjacent in $G$.
  
  \item $y_1=y_2-1$: In this case, use $\sigma_{T_{y_1}}(x_1)$ and $\nu_{y_1}(x_1)$ to compute $\sigma_{T_{y_2}}(x_1)$.  Now let $y:=y_2$, let $T:=T_{y}$, and proceed as in the previous case (but consulting a different bit of $a(z_1)$ in the last step.)  Note here that it is important that part (GC3) of the label for $(x_1,y_1)=(x,y-1)$ contains $\delta_{T_{y_1+1}}(x)=\delta_{T_{y}}(x)$.
  
  \item $y_2=y_1-1$: In this case, use $\sigma_{T_{y_2}}(x_2)$ and $\nu_{y_2}(x_2)$ to compute $\sigma_{T_{y_1}}(x_2)$.  Now let $y:=y_1$, $T:=T_{y}$, and proceed as in the previous case (but consulting a different bit of $a(z_1)$ in the last step.)
\end{enumerate}

This establishes our first result:

\begin{thm}\thmlabel{pxp}
  The family $\mathcal{G}$ of graphs $G$ such that $G$ is a subgraph of a strong product $P\boxtimes P$ where $P$ is a path ash a $(1+o(1))\log n$-bit labelling scheme.
\end{thm}

\begin{rem}
  The $o(\log n)$ term in the label length of \thmref{pxp} is $O(k\lg\lg n + k^{-1}\lg n)$.  An asymptotically optimal choice of $k$ is therefore $k=\lceil\sqrt{\lg n\lg\lg n}\rceil$, yielding labels of length $\log n + O(\sqrt{\lg n\lg\lg n})$.
\end{rem}


\section{Subgraphs of $H\boxtimes P$}
\seclabel{hxp}

In this section we build on the result of \secref{pxp} to find labelling schemes for graphs $G$ that are subgraphs of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,2,\ldots,h$ is a path.  Our strategy is similar the approach taken in the previous section.
For each $y\in\{1,\ldots,h\}$ we define $L_y=\{x: (x,y)\in V(G)\}$ and we will build a labelling scheme for the induced graph $H[V_y]$ where $V_y\supseteq L_{y\pm 1}$ that is based on a binary tree $T_y$ and such that the labels in this scheme have length $\log|T_y|+o(\log n)$.  In addition to this, we will use \lemref{row-code} to give each vertex $(x,y)\in V(G)$ a \emph{row label} of length $\log n - \log|T_y|+o(\log n)$.

\subsection{A Labelling Scheme for $t$-Trees}

We begin by describing a labelling scheme for $t$-Trees that, like the labelling scheme for paths, is based on a binary search tree.

\subsubsection{$t$-Trees}

We begin by describing a labelling schemes for $t$-trees. The ideas behind this scheme are not new; this is essentially the labelling scheme for $t$-trees described by Gavoille and Labourel \cite{gavoille.labourel:shorter}.  However, we present these ideas in a manner that makes it natural to generalize the results of \secref{pxp}.

A graph $H$ is a \emph{$t$-tree} if $H$ is a clique on $t$ vertices or if $H$ contains a vertex $v$ of degree $t$ whose neighbours form a clique and $H-v$ is a $t$-tree.  

Note that the recursive definition of $t$-trees implies that there is a vertex ordering $v_1,\ldots,v_{m}$ of $V(H)$ such that $v_1,\ldots,v_t$ form a clique and, for each $i\in\{t+1,\ldots,t_m\}$, $C_H(v_i):=B_H(v_i)\cap \{v_1,\ldots,v_{i}\}$ is a clique of size $t+1$.  We call $C_H(v_i)$ the \emph{family clique} of $v_i$ and $C_H(v_i)\setminus\{v_i\}$ the \emph{parent clique} of $v_i$.  The order $v_1,\ldots,v_m$ is called a \emph{construction order} for $H$.

The order $v_1,\ldots,v_m$ (in particular, the fact that each $v_i$ has at most $t$ neighbours among $v_1,\ldots,v_{i-1}$) implies that $V(H)$ has a proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$.  For each $i\in\{t+1,\ldots,m\}$ and each $j\in\{1,\ldots,t+1\}$ the \emph{$j$-parent} $p_j(v_i)$ of $v_i$ is the unique element $p\in C_H(v_i)$ with $\varphi(p)=j$.  Note that $v_i$ is the $j$-parent of itself for exactly one $j\in\{1,\ldots,t+1\}$.

\subsubsection{Interval Graphs}

For real numbers $a\le b$, let $[a,b]:=\{ x\in\R: a\le x\le b\}$, and let
$\mathbb{I}:=\{[a,b]: a,b\in\R,\, a\le b\}$ denote the set of closed real intervals.  For a finite set $S\subset\mathbb{I}$ of intervals, the \emph{interval intersection graph} $G_S$ is the graph with vertex set $V(G_S):=S$ and in which the edge $vw\in E(I)$ if and only if $v\cap w\neq \emptyset$.  

% The \emph{thickness} $\omega(G_S)$ of $S$ is the size of its largest clique, which (by Helly's Theorem) is equal to $\max_{x\in\R}|\{v\in V(H):x\in v\}|$.  By Dilworth's Theorem (applied to the poset $(V(I),\prec)$ where $[a,b]\prec [c,d]$ iff $b<c$), the chromatic number $\chi(I)$ of $I$ is equal to its thickness, i.e., $\chi(I)=\omega(I)$.  

The following well-known result states that every $n$-vertex $t$-tree is the subgraph of an interval graph with thickness $O(t\log n)$:

\snote{TODO: Use the references David provided}

\begin{lem}\lemlabel{interval-representation}
  For every $n$-vertex $t$-tree $H$, there exists a mapping $f:V(H)\to\mathbb{I}$, such that the interval intersection graph $G_S$ with $S:=\{f(v):v\in V(H)\}$ has thickness at most $\log_{3/2} t\log n$ and, for every $vw\in E(H)$, $f(v)\cap f(w)\neq\emptyset$.  
  
  Furthermore, for every proper $(t+1)$-colouring $\varphi:V(H)\to\{1,\ldots,t+1\}$ of $H$, there exists a proper colouring $\varphi':V(G_S)\to\{1,\ldots,\lceil\log_{3/2} n\rceil\}\times\{1,\ldots,t+1\}$ where, for each $v\in V(H)$, $\varphi'(f(v))=(j,\varphi(v))$ for some $j\in\{1,\ldots,\lceil\log_{3/2} n\rceil\}$.
\end{lem}

In light of \lemref{interval-representation} we will not distinguish between a vertex $v\in V(H)$ and the interval $f(v)$.  That is, we will treat the nodes of every $t$-tree as intervals that satisfy the conditions of \lemref{interval-representation}.

A point $x\in\R$ \emph{stabs} an interval $[a,b]$ if $\{x\}\cap [a,b]=\{x\}$. A finite set $X\subset\R^2$ of points \emph{stabs} a set $S\subset\mathbb{I}$ of intervals if, for every $[a,b]\in S$, at least one point $x\in X$ stabs $[a,b]$, i.e., $X\cap [a,b]\neq\emptyset$.

\begin{lem}\lemlabel{common-ancestor}
  Let $S\subset\mathbb{I}$ be a set of intervals, let $X\subset\R$ be a set of points that stabs $S$, and let $T$ be a binary search tree with $V(T):=X$, let $[a,b]\in S$ and let $x$ be the lowest common ancestor, in $T$, of $X\cap [a,b]$.  Then $x\in [a,b]$.
\end{lem}

\begin{proof}
  Since $x$ is the least common ancestor of $X\cap[a,b]$, either $x\in X\cap[a,b]$, in which case there is nothing prove, or there is some pair $x_1,x_2\in X\cap[a,b]$ such that $x_1$ is in the subtree of $T$ rooted at the left child of $x$ and $x_2$ is in the subtree of $T$ rooted at the right child of $x$.  By the binary search tree property, $x_1<x<x_2$. But $x_1,x_2 \in [a,b]$, so $a\le x_1<x<x_2\le b$, so $x\in [a,b]$.  
\end{proof}

\subsubsection{The Labelling Scheme}
\seclabel{t-tree-labelling}

We can use \lemref{common-ancestor} to create a labelling scheme for a $t$-tree based on any binary search tree containing a stabbing set.  Let $H$ be a $t$-tree whose vertex set $V(H):=S$ consists of the intervals described by \lemref{interval-representation}, let $v_1,\ldots,v_m$ be a construction order for $H$, let $\varphi:V(H)\to\{1,\ldots,t+1\}$ be a proper colouring of $H$, and let $\varphi':V(H)\to\{1,\ldots,\lceil\log_{3/2} n\rceil\}\times\{1,\ldots,t+1\}$ be the extension of $\varphi$ to a proper colouring of $G_S$ described in \lemref{interval-representation}.

Let $X\subset\R$ be any set of points that stab $S$, let $T$ be a binary search tree with $V(T)=X$.
% , and let $\varphi:V(H)\to\{1,2,\ldots,\lfloor t\log n\rfloor\}$ be a proper colouring of the interval graph with vertex set $S$.
For each vertex $v:=[a_v,b_v]\in V(H)$, let $x_T(v)$ denote the lowest-common-ancestor of $X\cap [a_v,b_v]$ in $T$ (see \figref{x}).  For any subset $C\subseteq V(H)$, let $x_T(C):=\{x_T(x):x\in C\}$.  

\begin{figure}
  \begin{center}
    \includegraphics{figs/x}
  \end{center}
  \caption{The definition of $x_T(v)$.}
  \figlabel{x}
\end{figure}

\begin{lem}\lemlabel{one-path}
  For any $v\in V(H)$ with family clique $C_H(v)$, the set of nodes $x_T(C_H(v))$ are all contained a single root-to-leaf path in $T$.
\end{lem}

\begin{proof}
  Suppose for the sake of contradiction that this is not true, so there are $x_1,x_2\in x_T(C_H(v))$ neither of which is an ancestor of the other.  Then consider the lowest common ancestor $x$ of $x_1$ and $x_2$ in $T$.  Assume without loss of generality that $x_1$ is in the subtree of $T$ rooted at $x$'s left child and $v_2$ is in the subtree of $T$ rooted at $x$'s right child, so $x_1<x<x_2$. The node $x_1:=x_T(v_1)$ for some $v_1:=[a_1,b_1]\in C_H(v)$ and $x_2=x_T(v_2)$ for some $v_2:=[a_2,b_2]\in C_H(v)$.  Since $v_1$ and $v_2$ are both in the family clique $C_H(v)$, the edge $v_1v_2\in E(H)$, and therefore $[a_1,b_1]\cap[a_2,b_2]\neq\emptyset$.  This implies that $x\in [a_i,b_i]$ for at least one $i\in\{1,2\}$.  But this is a contradiction since $x_T(v_i)$ is supposed to be the lowest common ancestor of $[a_i,b_i]\cap X$.
\end{proof}

The following observation shows that a vertex $v$ of $H$ is uniquely identified by $x_T(v)$ and $\varphi'(v)$.

\begin{obs}\obslabel{unique-id}
    For any two distinct vertices $v,w\in V(H)$, $x_T(v)\neq x_T(w)$ or $\varphi'(v)\neq\varphi'(w)$.  Consequently, $\sigma_T(x_T(v))\neq \sigma_T(x_T(w))$ or $\varphi'(v)\neq\varphi'(w)$. 
\end{obs}

\begin{proof}
  If $x_T(v)=x_T(w)=x$, the intervals $v=[a_v,b_v]$ and $w=[a_w,b_w]$ each contain $x$, so $vw\in E(G_S)$.  Therefore $\varphi'(v)\neq\varphi'(w)$ since $\varphi'$ is a proper colouring of $G_S$.  The second, equivalent, statement of the observation is immediate from the fact that the $\sigma_T: V(T)\to\{0,1\}^*$ is injective, so $\sigma_T(x)$ uniquely identifies $x$.
\end{proof}

For each node $v\in V(H)$, let $\sigma_T(v)$ denote the path in $T$ that begins at the root of $T$ and ends at the node in $x_T(C_H(v))$ of maximum depth.  By \lemref{one-path}, $\sigma_T(v)$ contains every node in $x_T(C_H(v))$.
The label for a vertex $v\in V(H)$ consists of the following (we ignore any integers, such as $t$, $|\sigma_T(v)|$, and $\lceil\log_{3/2} m\rceil$, that can be encoded using \lemref{elias}):

\begin{enumerate}[(TC1)]
  \item $\sigma_T(v)$;
  \item $d_T(x_T(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$; and
  \item $\varphi'(v)$.
\end{enumerate}

Given the labels of two vertices $v,w\in V(H)$, we test if $v$ and $w$ are adjacent as follows:
\begin{enumerate}[({A}1)]
  \item If the labels of $v$ and $w$ are identical then $v=w$, so return false.
  
  \item (uniquely identify $v$) From (TC4) extract $j:=\varphi(v)$ (which is contained in $\varphi'(v)$).  From (TC2) extract $d:=d_T(x_T(p_j(v)))$. Take the length-$d$ prefix of $\sigma_T(v)$ to get $\sigma_T(x_T(v))$.

  \item (check if $v$ is the $j$-parent of $w$) Extract $d:=d_T(x_T(p_j(w)))$ and take the length-$d$ prefix of $\sigma_T(w)$ to get $\sigma_T(x_T(p_j(w)))$.  If $\sigma_T(x_T(v))=\sigma_T(x_T(p_j(w)))$ then, by \obsref{unique-id}, $v$ is the $j$-parent of $w$ so $vw\in E(H)$, so return true.
  
  \item[(A4,A5)] Repeat (A2) and (A3) with the roles of $v$ and $w$ reversed.
  
  \item[(A6)] Return false
\end{enumerate}

The correctness of this procedure can be seen as follows:
\begin{itemize}
  \item Given the labels of $v$ and $w$ we can recover $\sigma_T(x_T(v))$, $\varphi'(v)$, $\sigma_T(x_T(w))$, and $\varphi'(w)$ so, by \obsref{unique-id}, the label of $v$ and the label of $w$ are identical if and only if $v=w$, so the negative result in (A1) is never incorrect;
  \item from \obsref{unique-id}, positive results in (A3) and (A5) are never incorrect; and 
  \item for every $vw\in E(H)$, there exists a $j\in\{1,\ldots,t+1\}$ such that $v$ is the $j$-parent of $w$ or $w$ is the $j$-parent of $v$, so the negative result in (A6) is never incorrect.    
\end{itemize}
In fact, this labelling scheme proves the slightly stronger result:

\begin{lem}\lemlabel{t-tree-labelling}
  Let $H$, $S$, $X$, and $T$ be defined as above.  There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=h(T) + O(t(\lg t + \lg h(T)))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
  \[
      \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{lem}

\begin{proof}
  Most of the details of this labelling are described above, though we have thus far ignored the length of the labels, which we analyze now.
  
  Part (TC1) of each label has length $|\sigma_T(v)|\le h(T)$.  For each $x\in V(T)$, $d_T(x)\le h(T)$, so Part~(TC2) of each label requires $O(t\lg h(T))$ bits.  Part~(TC3) of each label requires $O(t\log t + t\lg h(T))$ bits.  Part~(TC4) of each label requires $O(\log t + \lg h(T))$ bits.
\end{proof}

Taking $X$ to be a minimal set that stabs $S$ (so $|X|\le |S|=m$) and taking $T$ to be a perfectly balanced binary search tree (so $h(T)\le \log|X|\le\log m$) we obtain the following corollary.

\begin{cor}\corlabel{t-tree-labelling}
  There exists a function $\mathds{T}:(\{0,1\}^*)^2\to \Z\cup\{\perp\}$ such that, for any $m$-vertex $t$-tree $H$ there is a prefix-free code $\tau_H:V(H)\to\{0,1\}^*$ where $|\tau_H(v)|=\log m + O(t(\log t + \lg\lg m))$ for every $v\in V(H)$ and, for every $v,w\in V(H)$, 
  \[
      \mathds{T}(\tau_H(v),\tau_H(w)) = \begin{cases}
      0 & \text{if $v=w$} \\
      -j & \text{if $v$ is the $j$-parent of $w$} \\
      j & \text{if $w$ is the $j$-parent of $v$} \\
      \perp & \text{otherwise.}
    \end{cases}
  \]
\end{cor}

\subsection{Interval Transition Labels}

We point out again that the result in \corref{t-tree-labelling} is not new and the labelling scheme is just a reformulation of the one given by Gavoille and Labourel \cite{gavoille.labourel:shorter} that happens to be convenient for what we are going to do next. Most important for us is that the largest part of the codes come from paths in the binary search tree $T$ that contains the stabbing set $X$.  

What we will do next is to show that the solution presented in \secref{pxp} generalizes to the current setting.  The only additional complication comes from the fact that each node $x$ in the binary search tree $T$ is equipped with a collection $B_x:=\{v\in V(H):x_T(v)=x\}$ of intervals.  Any structural changes that we make to $T$ may result in changes to $B_x$, which result in changes to the labels for the vertices of $H$ that enter or leave $B_x$.  We must show that these changes can be encoded using few bits.  We now proceed.

Let $G$ be an $n$-vertex subgraph of $H\boxtimes P$ where $H$ is a $t$-tree and $P=1,\ldots,h$ is a path. For each $y\in\{1,\ldots,h\}$, let $S_y=\{v\in V(H): (v,y)\in V(G)\}$ \snote{Consistency: $S_y$ was $L_y$ in \secref{pxp}} and let $S^-_y=\bigcup_{j=1}^{t+1}\{p_j(v):v\in S_y\}$.  Note that $|S^-_y|\le t|S_y|$. For each $y\in\{1,\ldots,t+1\}$, let $X_y\subset\R$ be the set of all endpoints of intervals in $S^-_y\cup S^-_{y-1}$.

By \lemref{chunked-bulk-trees} and \lemref{node-transitions} there is a bulk tree sequence $T_1,\ldots,T_h$ where, for each $y\in\{1,\ldots,h\}$, 
\begin{enumerate}[(PR1)]
  \item $V(T_y)\supseteq X_y$;
  \item $h(T_y)\in \log |T_y| + o(\log n)$;
  \item $W:=\sum_{y=1}^h |T_y|\in O(n)$; and
  \item There is a function $B:(\{0,1\}^*)^2\to\{0,1\}^*$ such that, for every $x\in V(T_y)\cap V(T_{y+1})$, there is an $o(\log n)$-bit string $\nu_y(x)$ such that $B(\sigma_{T_y}(x),\nu_y(x))=\sigma_{T_{y+1}(x)}$.
\end{enumerate}

% As before, we can use \lemref{row-code} to assign each vertex $v=(x,y)\in V(G)$ a label $\alpha(v)$ of length $\log n - \log|T_y| + o(\log n)$. For any two nodes $v_1=(x_1,y_1)\in V(G)$ and $v_2=(x_2,y_2)$, $\alpha(v_1)$ and $\alpha(v_2)$ are sufficient to determine if $|y_1-y_2|\le 1$ and, if so, the actual value of $y_1-y_2$.
% 
% Now, for each $y\in\{1,\ldots,h\}$, $V(T_y)$ stabs $S^-_y\cup S^-_{y-1}$, so we can use $T_y$ to create a labelling scheme $\tau_y:(S^-_y\cup S^-_{y-1})\to\{0,1\}^*$ for the induced graph $H[S^-_y\cup S^-_{y-1}]$ as described in \secref{t-tree-labelling} leading to \lemref{t-tree-labelling} where the labels have length $h(T_y) + o(\log n)=\log|T_y|+o(\log n)$.  
% 
% For each $v\in S^-_y$, the label $\tau_y(v)$ has four parts (TC1)--(TC4).  Parts~(TC3) and (TC4) are completely determined by $H$ and $v$ and are independent of $T_y$.  In particular parts (TC3) and (TC4) of $\tau_{y_1}(v)$ and $\tau_{y_2}(v)$ are the same for any $y_1$ and $y_2$ such that $(v,y_1),(v,y_2)\in V(G)$.  
% 
% Part~(TC2) of $\tau_y(v)$, however depends very much on the tree $T_y$.  Luckily, Part~(TC2) is small: It has size $o(\log n)$, so the label of $(v,y)$ can include Part~(TC2) for $\tau_{y}(v)$ and $\tau_{y+1}(v)$.
% 
% The difficulty comes from Part~(TC1) of $\tau_y(v)$.



\begin{lem}\lemlabel{interval-transitions}
  There exists a function $B:(\{0,1\}^*)^2\to \{0,1\}^*$ such that, for any 
  $H$, $G$, $L_1,\ldots,L_h$, $X_1,\ldots,X_h$, $T_1,\ldots,T_h$ defined as above, for each $y\in\{1,\ldots,h-1\}$ and each $v\in L_y$, there exists $\mu_y(v)\in\{0,1\}^*$, $|\mu_y(v)|\in O(k\lg\lg n)$ such that $B(\sigma_{T_y}(v), \mu_y(v))=\sigma_{T_{y+1}}(v)$.
\end{lem}

\begin{proof}
  For we note that, if $v\in L_y\cup L_{y+1}$, then the endpoints of $v$ are in $X_y\subseteq V_(T_y)$ and in $X_{y+1}\subseteq V(T_{y+1})$.
  Like the proof of \lemref{node-transitions}, we must dig into the three bulk tree operations that transform $T_y$ into $T_{y+1}$: rebalancing, which takes $T_y$ onto $T_y'$; bulk insertion of $I_y$, which takes $T_y'$ onto $T_y''$; and bulk deletion, which takes $T_y''$ onto $T_{y+1}$.
  
  The bulk insertion that converts $T_y'$ into $T_y''$ is the simplest to handle.  For any $v\in L_y$, $P_{T_y'}(v)$ is the path from the root of $T_y'$ to the deepest node in $x_{T_y'}(C_H(v))$.  Furthermore, for each $w\in C_H(v)$, $x_{T_y'}(v)$ is the element of $v\cap V(T_y')$ that is closest to the root fo $T_y'$. Since $T_y''$ is a supergraph of $T_y'$ obtained by adding small subtrees at the external nodes of $T_y'$, $x_{T_y''}(w)=x_{T_y'}(w)$ for each $w\in C_H(v)$.  Therefore $P_{T_y''}(w)=P_{T'}(w)$ and $\sigma_{T_y''}(w)=\sigma_{T'}(w)$ for each $w\in C_H(v)$, so $\sigma_{T_y''}(v)=\sigma_{T_y'}(v)$ for each $v\in L_y$.
  
  Next we consider the bulk deletion that converts $T_y''$ into $T_{y+1}$.  A bulk deletion consists of a sequence if individual deletions. Consider one such deletion and let $T$ and $\tilde{T}$ denote the the tree before and after the deletion, respectively.  
  
  \begin{clm}\clmlabel{deletion-ancestor}
    For any $v=[a_v,b_v]\in L_y$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))$ is a prefix of $\sigma_T(x_T(v))$.   
  \end{clm}
  
  \begin{proof}[Proof of \clmref{deletion-ancestor}]  
    See \figref{deletion-t-tree}.  At a global level, the deletion of a value $x$ from $T$ involves finding a sequence of consecutive values $x_0<x_1<\cdots<x_r$ or $x_0>x_1>\cdots>x_r$ where $x=x_0$, $x_r$ is a leaf and $x_{i-1}$ is a $T$-ancestor of $x_{i}$ for each $i\in\{1,\ldots,r\}$.  The leaf containing $x_r$ is deleted and, for each $i\in\{0,\ldots,r-1\}$, the (value in the) node $x_i$ is replaced with (the value in) node $x_{i+1}$.  

    \begin{figure}
      \begin{center}
        \includegraphics{figs/deletion-t-tree-1}\\[1ex]
        $\Downarrow$\\[1ex]   
        \includegraphics{figs/deletion-t-tree-2}   
      \end{center}
      \caption{The effect of a single deletion on $x_T(v)$.}
      \figlabel{deletion-t-tree}
    \end{figure}
    
    If $x_T(v)=x_i$ for $i\in\{1,\ldots,r\}$, then $x_{\tilde{T}}(v)=x_i$ (see the interval $v_1$ in \figref{deletion-t-tree}) and $\sigma_{\tilde{T}}(x_i)=\sigma_{T}(x_{i-1})$.  Since $x_{i-1}$ is a $T$-ancestor of $x_i$, $\sigma_{\tilde{T}}(x_{\tilde{T}}(v))=\sigma_{\tilde{T}}(x_i)$ is a prefix of $\sigma_{T}(x_{T}(x))$, as required.
    
    On the other hand, if $x_T(v)\neq x_i$ and $x_T(v)\neq x_{\tilde{T}}(v)$, then the only possibility is that some node $x_{\tilde{T}}(v)=x_i$ for some $x_i\in [a_v,b_v]$ (see the interval $v_2$ in \figref{deletion-t-tree}).  This can only happen if $x_i$ is not a $T$-ancestor of $x_T(v)$, but $x_i$ is a $\tilde{T}$ ancestor of $x_T(v)$.  By \lemref{common-ancestor}, $x_i$ is a $T$-descendant of $x_T(v)$.  Since $x_i$ is a $\tilde{T}$-ancestor of $x_T(v)$, $x_{i-1}$ is a $T$-ancestor of $x_T(v)$.  Therefore $\sigma_{\tilde{T}}(v)=\sigma_{\tilde{T}}(x_i)=\sigma_T(x_{i-1})$ is a prefix of $\sigma_T(x_T(v))$, as required.  This completes the proof of \clmref{deletion-ancestor}.    
  \end{proof}
  
  Let $a\preceq b$ denote that $a$ is a prefix of $b$.
  Since a bulk deletion is implemented as a sequence of individual deletions,
  \begin{align*}
    \sigma_{T_y''}(v) 
      & = \sigma_{T_y''}(x_{T_y''}(w)) & \text{(for some $w\in C_H(v)$} \\
      & \preceq \sigma_{T_y'}(x_{T_y'}(w)) & \text{(by \clmref{deletion-ancestor})} \\
      & \preceq \sigma_{T_y'}(v) \enspace . & \text{(by \lemref{one-path})}
  \end{align*} 
  Therefore, by including $|\sigma_{T_y''}(v)|$ in $\mu_y(v)$ we can derive $\sigma_{T_y''}(v)$ from $\sigma_{T_y'}(v)$.  This requires only $O(\log h({T_y'}))=O(\lg\lg n)$ bits.
  
  
  
  Finally, we consider the rebalancing operation that takes $T_y$ onto $T_y'$. to $\textrm{bulkbalance}(\theta)$.  The $\mathrm{bulkbalance}(\theta)$ operation calls $\mathrm{balance}(x)$ on each depth-$theta$ node $x$ of $T_y$ to restructure the subtree of $T_y$ rooted at $x$ (refer to \figref{rebalance-t-tree}). Therefore, for any $v\in L_y$, and any $\theta'\in\{0,\ldots,\theta$, the length-$\theta'$ prefix of $\sigma_{T_y}(v)$ and length-$\theta'$ prefix of $\sigma_{T_y'}(v)$ are the same.  By including the value of $\theta$ in $\mu_y(v)$, we then only need to consider the effect of the call to $\mathrm{balance}(x)$ where $x$ is the unique depth-$\theta$ node of $T_y$ contained in $P_{T_y}(v)$.
  
  \begin{figure}
    \begin{center}
      \includegraphics{figs/rebalance-t-tree}
    \end{center}
    \caption{Only the call to $\mathrm{balance}(x)$ on a node $x\in V(P_{T_2}(v))$ affects $\sigma_{T_2'}(v)$.}
    \figlabel{rebalance-t-tree}
  \end{figure}
  
  Let $T_*$ be the subtree of $T_y$ rooted at $x$ and let $T_*'$ be the new tree obtained after calling $\textrm{balance}(x)$ on the root, $x$, of $T_*$. (So $T_*$ is a subtree of $T_y$ and $T_*'$ is a subtree of $T_y'$.)
  The transition code $\mu_y(x)$ will contain enough information to recover $\sigma_{T_*'}(v)$ from $\sigma_{T_*}(v)$. 
  
  Now, $\textrm{balance}(x)$ identifies two special node sets $Z$ and $X$ that it turns into a perfectly balanced binary search tree $T_0$.  Eventually, $T_0$ will become a subgraph of $T_*'$ that contains the root of $T_*'$.   In particular, every node in $V(T_*')$ has  $T_*'$-ancestor in $Z\cup X$.
  
  For any $v\in L_y$ such that $P_{T_*'}(v)$ ends at a vertex $z\in Z\cup X=V(T_0)$, the problem is easy.  We include $\sigma_{T_0}(z)$, which has length at most $h(T_0)\le k$, in $\mu_y(v)$, and this (plus $\theta$) is sufficient to recover $\sigma_{T_y'}(v)$ from $\sigma_{T_y}(v)$.

  Thus, we only need to consider those $v\in L_v$ such that $P_{T_y'}(v)$ ends a vertex $z\not\in Z\cup X$ with $d_{T_y}(z)>\theta$.  By definition,  $z=x_{T_y'}(w)$ for some $w=[a_w,b_w]\in C_H(v)$ and $[a_w,b_w]\cap (Z\cup X)=\emptyset$.    For each such node $v$, $P_{T_y}(v)$ has vertices (including $z$) in common with exactly one tree $T_{*,i}$ in the forest $T_*-Z$.  Then $\mathrm{balance}(x)$ calls $\mathrm{multisplit}(x_1,\ldots,x_c)$ on the subtree $T_{*,i}$ with $\{x_1,\ldots,x_c\}:= X\cap V(T_{*,i})$.  This, in turn results in zero or more calls to $\textrm{split}(x)$ for nodes $x\in v(T_{*,i})$. The following claim explains the effect of one individual call to $\mathrm{split}(x)$:
  
  \begin{clm}\clmlabel{x-switch}
    Let $S$ by a set of intervals, let $T$ be a binary search tree where $V(T)$ stabs $S$, and let $T<x$ and $T>x$ be the two trees resulting from calling $\mathrm{split}(x)$ on $T$ for some $x\in V(T)$.  Then, for each $v=[a_v,b_v]\in S$ exactly one of the following is true:
    \begin{compactenum}
      \item $a_v\le x\le b_v$; or
      \item $x< a_v$, in which case $x_{T_{>x}}(v)=x_T(v)$; or
      \item $b_v < x$, in which case $x_{T_{<x}}(v)=x_T(v)$.
    \end{compactenum}
  \end{clm}

  \begin{proof}
    That exactly one of the three cases applies is obvious.  Case~(1) has no specific requirements and Cases~(2) and (3) are symmetric, so we focus on Case~(2), so $x < a_v\le b_v$.
    
    By \lemref{common-ancestor}, $z=x_T(v)$ is the unique node $z\in V(T)$ such that $P_T(z)$ has exactly one node $z\in [a_v,b_v]$.  Now $P_{T_{>x}}(z)$ is obtained from $P_T(z)$ by deleting all values less than or equal to $x$. Therefore $P_{T_{>x}}(z)$ has exactly one node $z\in[a_v,b_v]$, so $z=x_{T_{>x}}(v)$.  This completes the proof of \clmref{x-switch}.
  \end{proof}
  
  From \clmref{x-switch}, we can conclude that $P_{T_y'}(v)=P_{T_y'}(x_{T_y}(w))$ for some $w\in C_H(v)$.  Indeed, by definition $x_{T_y'}(w)\not\in Z\cup X$. By \clmref{x-switch}, either $x_{T_y'}(w)=x_{T_y}(w)$ or $\mathrm{split}(x)$ is called on some node $x\in[a_w,b_w]$.  But $\mathrm{split}(x)$ is only called on nodes $x\in X$, so if $x\in[a_w,b_w]$, then this would imply that $X$ contains a value in $[a_w,b_w]$ violating the assumption that $x_{T_y'}(w)\not\in Z\cup X$.
  
  Thus, for each $v\in L_y$ such that $x(v)\not\in Z\cup Y$, there exits some $w\in C_H(v)$ with $x_{T_2}(w)=x_{T_2'}(w)$ such that $P_{T_2'}(v)=P_{T_2'}(x_{T_2}(w)$, so $\sigma_{T_2'}(v)=\sigma_{T_2'}(x_{T_2}(w))$.  By \lemref{one-path}, $\sigma_{T_2}(x_{T_2}(w))$ is a prefix of of $\sigma_{T_2}(v)$ and the length of this prefix can be included in $\mu_y(x)$, which makes it possible to recover $\sigma_{T_2}(x_{T_2}(w))$ from $\sigma_{T_2}(v)$ .  By \lemref{node-transitions}, there exists a function $B$ and a string $\nu_y(x_{T_2}(w))$ of length $O(k\log\log n)$ such that $B(\sigma_{T_2}(x_{T_2}(w)), \nu_y(x_{T_2}(w))) = \sigma_{T_2'}(x_{T_2}(w)) = \sigma_{T_2'}(v)$.
  
  Therefore, for any $v\in L_y$ there is a string $\mu_y(x)$ of length $O(k\lg\lg n)$ that satisfies the conditions of the lemma.
\end{proof}
  
\subsection{The Labels}

Summarizing, for any $n$-vertex subgraph $G$ of $H\boxtimes P$, each vertex $z=(v,y)\in V(G)$ has a label that contains the following information:

\begin{enumerate}[(PC1)]
  \item $\alpha(y)$; % of length $\log n-\log|T_y| + O(\lg\lg n)$;
  \item $\sigma_{T_y}(v)$; % of length $\log|T_y| + O(k+k^{-1}\log n)$;
  \item $d_{T_{y+b}}(x_{T_{y+b}}(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$ and $b\in\{-1,0,1\}$; 
  \item $\varphi'(p_j(v))$ for each $j\in\{1,\ldots,t+1\}$;
  \item $\varphi'(v)$;
  \item $\mu_y(v)$;
  \item $a(z)$.
\end{enumerate}
The only one of these quantities not yet defined is $a(z)$, which is a sequence of $3t$ bits that indicate which of the potential edges joining $z$ to elements of $\{(p_j(v),y+b): j\in\{1,\ldots,t+1\},\, b\in\{-1,0,1\}\}$ are actually present in $G$.

\subsection{Adjacency Testing}

Given the labels of $z_1:=(v_1,y_1)$ and $z_2:=(v_2,y_2)$ we test if $z_1z_2\in E(G)$ by first using $\alpha(y_1)$ and $\alpha(y_2)$ to determine which of the following applies:
\begin{enumerate}
  \item $|y_1-y_2|>1$: In this case $y_1\neq y_2$ and $y_1y_2\not\in P$, so $z_1z_2\not\in E(H\boxtimes P)$, so $z_1z_2\not\in E(G)$.

  \item $y_1=y_2$.  Let $y=y_1=y_2$.  In this case (PC2)--(PC4) contains $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ and we use this to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y}(v_1)$ and $\tau_{y}(v_2)$ also tell us that (without loss of generality) $x_1$ is the $j$-parent of $x_2$ in $H$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=1$: Let $y=y_1$ (so that $y_2=y+1$).  We use $\mu_y(v_1)$ and $\sigma_{T_y}(v_1)$ to compute $\sigma_{T_{y+1}}(v_1)$.  Now, $\sigma_{T_{y+1}}(v_1)$ and (PC3)--(PC4) contains $\tau_{y+1}(v_1)$ and (PC2)--(PC4) contains $\tau_{y+1}(v_2)$.  We use these to test if $v_1v_2\in E(H)$.  If not, then $v_1v_2\not\in E(H\boxtimes P)$ so $z_1z_2\not\in E(G)$.  
  
  If $v_1v_2\in E(H)$ then we know that $z_1z_2\in E(H\boxtimes P)$.  In this case $\tau_{y+1}(v_1)$ and $\tau_{y+1}(v_2)$ also tell us that (without loss of generality) $v_1$ is the $j$-parent of $v_2$.  We can now consult the relevant bit of $a(z_1)$ to determine if $z_1z_2\in E(G)$.

  \item $y_2-y_1=-1$:  This case is symmetric to the preceding case, with the roles of $z_1$ and $z_2$ reversed.
\end{enumerate}

This completes the proof of our main result.

\begin{thm}\thmlabel{main-product}
  For every $t\in\N$, the family of all graphs $G$ such that $G$ is a subgraph of $H\boxtimes P$ for some $t$-tree $H$ and some path $P$ has a $(1+o(1))\log n$-bit adjacency labelling scheme.
\end{thm}
% 
% 
%   For every $t\in\N$ and every $t$-tree $H$ and every path $P$, the family of subgraphs of $H\boxtimes P$ has a 
% 
% 
% 
%    subgraphs 
%   There exists an 
%   There exists a function $\mathds{A}:(\{0,1\}^*)^2\to\{0,1\}$ such that for every $t$-tree $H$, every path $P$, and every $n$-vertex subgraph $G$ of $H\boxtimes P$, there is a prefix-free code $\eta:V(G)\to\{0,1\}^*$ such that
%   $|\eta(v)|=\log n + O(\sqrt{\log n\lg\lg n}+t(\log t + \lg\lg n))$ for every $v\in V(G)$ and, for every $v,w\in V(G)$, 
%   \[  \mathds{A}(\eta(v),\eta(w)) = \begin{cases}
%         1 & \text{if $vw\in E(G)$} \\
%         0 & \text{if $vw\not\in E(G)$}
%       \end{cases}
%       \]
% \end{thm}

\section{Conclusion}
\seclabel{conclusion}

Given an $n$-vertex planar graph $G$, finding an 8-tree $H$, a path $P$, and a mapping of $G$ into a subgraph of $H\boxtimes P$ can be done in $O(n^2)$ time \cite{dujmovic.joret.ea:planar}.  The process of computing the labels of $V(G)$ as described in \secref{pxp} and \secref{hxp} is has a straightforward $O(n\log n)$ time implementation.  Thus, the adjacency labels described in \thmref{main} are computable in $O(n^2)$ time for $n$-vertex planar graphs.

The adjacency testing function $\mathds{A}$ is quite simple. Even without using word parallelism, this function is straightforward to implement in $O(tk\log n)$ time.  In the case of planar graphs $t=8$ and $k=O(\sqrt{\log n\lg\lg n})$, so the adjacency testing procedure can be implemented in $O(\log n\sqrt{\log n\lg\lg n})$ time.\snote{If we want to bother, we could probably do this in $O(\log n)$ time.}

\section*{Acknowledgement}

Part of this research was conducted during the Eighth Workshop on Geometry and Graphs, held at the Bellairs Research Institute, January~31--February~7, 2020.  We are grateful to the organizers and participants for providing a stimulating research environment.

  
\bibliographystyle{plainurl}
\bibliography{labelling}


\appendix

\section{Proof of \lemref{fractional}}
\applabel{fractional-proof}


\begin{proof}[Proof of \lemref{fractional}]
  We construct $V_1,\ldots,V_{h}$ incrementally using a recursive subroutine called $\textsc{Add}(x, y)$ using the following procedure:
  
  \noindent$\textsc{BuildV}(S_1,\ldots,S_h)$:
  \begin{algorithmic}[1]
    \STATE{$V_0\gets V_{h+1}\gets\Z$}
    \STATE{$V_y\gets\{0\}$ for each $y\in\{1,\ldots,h\}$}
    \FOR{$x= 1,\ldots,m$}
      \FOR{$y = 1,\ldots,h$}
        \IF{$x\in S_y\setminus V_y$}
          \STATE{$\mathrm{add}(x, y)$}
        \ENDIF
      \ENDFOR
    \ENDFOR
    \STATE{$V_y\gets V_y\setminus \{0\}$ for each $y\in\{1,\ldots,h\}$}
  \end{algorithmic}
  
  \noindent$\textsc{Add}(x, y)$:
  \begin{algorithmic}[1]
    \IF{$y\in\{1,\ldots,h\}$}
      \STATE{$V_y\gets V_y\cup\{x\}$}
      \IF{$|V_y|\ge 5$}      
        \STATE{let $x_{-1}>x_{-2}>\cdots>x_{-5}$ be the 5 largest elements in $V_y$ (so $x_{-1}=x$)}
        \IF{$\{x_{-1},\ldots,x_{-4}\}\cap V_{y-1}=\emptyset$ or
            $\{x_{-1},\ldots,x_{-4}\}\cap V_{y+1}=\emptyset$}
            \STATE{$\textsc{Add}(x,y-1)$}
            \STATE{$\textsc{Add}(x,y+1)$}
        \ENDIF
      \ENDIF
    \ENDIF
  \end{algorithmic}
  
  It is easiest to think of the sets $V_y$ as sequences, sorted in increasing order, so that Line~2 in $\textsc{Add}(x,y)$ appends $x$ to $V_y$.
  
  That the procedure produces sets $V_1,\ldots,V_h$ such that $V_y\supseteq S_y$ for each $y\in\{1,\ldots,h\}$ is obvious.  So the resulting sets $V_1,\ldots,V_h$ satisfy the first condition of the lemma.
  
  The prove that $V_1,\ldots,V_h$ satisfy the second condition, we establish the loop invariant that, outside of $\textsc{Add}(x,y)$, $V_{y-1}$ and $V_{y+1}$ each 3-chunk  $V_y$ for each $y\in\{1,\ldots,h\}$.  Indeed, the only instant at which $V_{y-1}$ fails to 3-chunk $V_y$ is immediately after appending some value $x$ to $V_y$ in Line~2 of $\textsc{Add}(x,y)$.  If this occurs, it is immediately detected in Lines~3--5 and corrected in Line~6.  Similarly, if $V_{y+1}$ fails to $3$-chunk $V_y$ then this is immediately detected and corrected in Line~7.
  
  Finally, we need to argue that $V_1,\ldots,V_h$ satisfy the third condition.  In particular, we must show that $\sum_{y=1}^h |V_y|\le 2\sum_{y=1}^h |S_y|\le 4n$.

  We do this with a credit scheme that maintains the following invariant  during the execution of the algorithm:  For each $V_y$, let $c_y$ be the length the longest suffix $x_{-k},\ldots,x_{-1}$ of $V_y$ that does not intersect $V_{y-1}$ or does not intersect $V_{y+1}$.  Except during the execution of $\textsc{Add}(x,y)$, $c_y\le 3$, since $V_{y-1}$ and $V_{y+1}$ each 3-chunk $V_y$.  We maintain the invariant that $V_{y}$ stores $c_y$ credits at all times.  When we append to the list $V_y$ in Line~2 of $\textsc{Add}(x,y)$ we will pay with one credit that is spent and can never be used again.
  
  To maintain our credit invariant, we will create 2 credits each time $\textsc{BuildV}$ calls $\textsc{Add}(x,y)$ in Line~6.  Line~6 executes at most once for each of the original $2n$ values in $S_1,\ldots,S_h$.  Therefore Line~6 executes at most $2n$ times and at most $4n$ credits are created.  Since each execution of Line~2 in $\textsc{Add}(x,y)$ takes away one credit, this means that the total number of times we append to lists in $V_1,\ldots,V_h$ is at most $4n$.
  Therefore, $\sum_{y=1}^h |V_y|\le 4n$.
   
  To manage these credits, we will pass two credits into each invocation of $\textsc{Add}(x,y)$, including the recursive invocations.  For the invocations of $\textsc{Add}(x,y)$ in Line~6 of \textsc{BuildV}, the two credits passed in are the two newly-created credits.
  
  When $\textsc{Add}(x,y)$ executes, one of the two credits passed to itis used to pay for the execution of Line~2, and this credit disappears forever, leaving one extra credit that we add to $V_y$ since the newly-added value $x\in V_y$ may have increased $c_y$ by 1. Thus far the credit invariant is maintained.  
  
  If no further recursive invocation of $\textsc{Add}(x,y)$ are made, then there is nothing further to do, so we consider the case where the two recursive invocations in Lines~6 and 7 are made.  In this case, $c_y=4$ before these recursive invocations are made.  Afterwards, $c_y=0$ since these invocations add $x$ to $V_{y-1}$ and $V_{y+1}$.  This frees 4 credits.  We pass 2 of these free credits into the recursive invocation of $\textsc{Add}(x,y-1)$ and the other 2 free credits into the recursive invocation of $\textsc{Add}(x,y+1)$. 
\end{proof}

\end{document}
